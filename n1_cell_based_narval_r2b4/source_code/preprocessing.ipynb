{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "<!-- Was used to generate: <br>\n",
    "*preprocessed_data/cloud_cover_all_days_input_train_1.npy <br>\n",
    "preprocessed_data/cloud_cover_all_days_input_valid_1.npy <br>\n",
    "preprocessed_data/cloud_cover_all_days_output_train_1.npy <br>\n",
    "preprocessed_data/cloud_cover_all_days_output_valid_1.npy* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "base_path = '/pf/b/b309170'\n",
    "path = base_path + '/my_work/NARVAL/data_var_vertinterp/'\n",
    "output_path = base_path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_v3/based_on_var_interpolated_data'\n",
    "model_path = \"/pf/b/b309170/workspace_icon-ml/cloud_cover_parameterization/grid_cell_based_v3/saved_models\"\n",
    "# Add path with my_classes to sys.path\n",
    "sys.path.insert(0, base_path + '/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "from my_classes import write_infofile\n",
    "from my_classes import load_data\n",
    "\n",
    "NUM = 1\n",
    "np.random.seed(NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "### Input:\n",
    "- fr_land: Fraction of land\n",
    "- zg: Geometric height at full levels\n",
    "- qv: Specific water vapor content\n",
    "- qi: Specific cloud ice content\n",
    "- temp: Temperature\n",
    "- pres: Pressure\n",
    "\n",
    "### Output:\n",
    "- clc: Cloud Cover\n",
    "\n",
    "Be careful with the NARVAL file-naming convention when it comes to timestamps when adding 2D-variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the NARVAL data into the data_dict dictionary\n",
    "order_of_vars = ['qv', 'qi', 'temp', 'pres', 'zg', 'fr_land', 'clc']\n",
    "data_dict = load_data(source='narval', days='all', vert_interp=True, order_of_vars=order_of_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping into nd-arrays of equaling shapes (have timesteps x vert x hor)\n",
    "data_dict['zg'] = np.repeat(np.expand_dims(data_dict['zg'], 0), data_dict['qv'].shape[0], axis=0)\n",
    "data_dict['fr_land'] = np.repeat(np.expand_dims(data_dict['fr_land'], 0), data_dict['qv'].shape[0], axis=0)\n",
    "data_dict['fr_land'] = np.repeat(np.expand_dims(data_dict['fr_land'], 1), data_dict['qv'].shape[1], axis=1)\n",
    "\n",
    "assert data_dict['fr_land'].shape == data_dict['qv'].shape == data_dict['zg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['qv', 'qi', 'temp', 'pres', 'zg', 'fr_land', 'clc'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qv</th>\n",
       "      <th>qi</th>\n",
       "      <th>temp</th>\n",
       "      <th>pres</th>\n",
       "      <th>zg</th>\n",
       "      <th>fr_land</th>\n",
       "      <th>clc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.366128</td>\n",
       "      <td>1530.231208</td>\n",
       "      <td>28193.783559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.968134</td>\n",
       "      <td>1528.399878</td>\n",
       "      <td>28193.783559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.825919</td>\n",
       "      <td>1528.486878</td>\n",
       "      <td>28193.783559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.243447</td>\n",
       "      <td>1521.956216</td>\n",
       "      <td>28193.783559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.072678</td>\n",
       "      <td>1525.309351</td>\n",
       "      <td>28193.783559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         qv   qi        temp         pres            zg  fr_land  clc\n",
       "0  0.000002  0.0  226.366128  1530.231208  28193.783559      1.0  0.0\n",
       "1  0.000002  0.0  227.968134  1528.399878  28193.783559      1.0  0.0\n",
       "2  0.000002  0.0  226.825919  1528.486878  28193.783559      1.0  0.0\n",
       "3  0.000002  0.0  228.243447  1521.956216  28193.783559      1.0  0.0\n",
       "4  0.000002  0.0  228.072678  1525.309351  28193.783559      1.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping into 1D-arrays and converting dict into a DataFrame-object (the following is based on Aurelien Geron)\n",
    "for key in ['qv', 'qi', 'temp', 'pres', 'zg', 'fr_land', 'clc']:\n",
    "    data_dict[key] = np.reshape(data_dict[key], -1) \n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampling the data (minority class: clc = 0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20784.62706137544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(df.loc[df['clc']>0])['zg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['zg'] < 21000] # There are days with clc > 0 at 20500 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26814085"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noclc = df.loc[df['clc']==0]\n",
    "len(df_noclc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68584831442132\n"
     ]
    }
   ],
   "source": [
    "# We ensure that clc != 0 and clc = 0 have the same size\n",
    "downsample_ratio = (len(df) - len(df_noclc))/len(df_noclc)\n",
    "print(downsample_ratio)\n",
    "shuffled_indices = np.random.permutation(len(df_noclc))\n",
    "set_size = int(len(df_noclc)*downsample_ratio)\n",
    "downsample_indices = shuffled_indices[:set_size] \n",
    "df = pd.concat([df_noclc.iloc[downsample_indices],df.loc[df['clc']!=0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into a learning and a test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29424632 training samples,  7356158 test samples\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into a learning and a test set\n",
    "\n",
    "#Should we use StratifiedShuffleSplit instead to make sure that the test set is representative of the whole dataset?\n",
    "#E.g. define categories of specific water vapor and make sure those categories are present in the test set as well\n",
    "#-> Geron, p.69\n",
    "\n",
    "def split_train_test(df, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    test_set_size = int(len(df)*test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return df.iloc[train_indices], df.iloc[test_indices]\n",
    "    \n",
    "learning_set, test_set = split_train_test(df, 0.2)\n",
    "print(len(learning_set), 'training samples, ', len(test_set), 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training set/learning set into a training set and a validation set and rescale\n",
    "\n",
    "train_set, valid_set = split_train_test(learning_set, 0.1)\n",
    "if 'clc' in valid_set.columns:\n",
    "    output_valid = valid_set['clc']\n",
    "    del valid_set['clc']\n",
    "if 'clc' in train_set.columns:\n",
    "    output_train = train_set['clc']\n",
    "    del train_set['clc']\n",
    "scaler.fit(train_set)\n",
    "input_train = scaler.transform(train_set)\n",
    "input_valid = scaler.transform(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and scale the test set as well\n",
    "if 'clc' in test_set.columns:\n",
    "    output_test = test_set['clc']\n",
    "    del test_set['clc']\n",
    "input_test = scaler.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "np.save(output_path + '/cloud_cover_all_days_input_train_%d.npy'%NUM, input_train)\n",
    "np.save(output_path + '/cloud_cover_all_days_input_valid_%d.npy'%NUM, input_valid)\n",
    "np.save(output_path + '/cloud_cover_all_days_output_train_%d.npy'%NUM, output_train)\n",
    "np.save(output_path + '/cloud_cover_all_days_output_valid_%d.npy'%NUM, output_valid)\n",
    "np.save(output_path + '/cloud_cover_all_days_input_test_%d.npy'%NUM, input_test)\n",
    "np.save(output_path + '/cloud_cover_all_days_output_test_%d.npy'%NUM, output_test)\n",
    "with open(model_path+'/scaler_%d.txt'%NUM, 'w') as file:\n",
    "    file.write('Standard Scaler mean values:\\n')\n",
    "    file.write(str(scaler.mean_))\n",
    "    file.write('\\nStandard Scaler standard deviation:\\n')\n",
    "    file.write(str(np.sqrt(scaler.var_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the accompanying info-file\n",
    "with open(model_path + '/model_grid_cell_based_v3_final_%d.txt'%NUM, 'w') as file:\n",
    "    write_infofile(file, str(learning_set.columns), str(np.array(np.delete(learning_set.columns, 6))), \n",
    "                   model_path, output_path, NUM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds113_kernel",
   "language": "python",
   "name": "clouds113_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
