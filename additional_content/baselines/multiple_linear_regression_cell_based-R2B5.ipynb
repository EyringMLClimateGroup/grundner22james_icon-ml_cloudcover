{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression\n",
    "\n",
    "**For Table 3 of the paper**\n",
    "\n",
    "Cell-based QUBICC R2B5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import tensorflow as tf\n",
    "import tensorflow.nn as nn\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Import sklearn before tensorflow (static Thread-local storage)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "path = '/pf/b/b309170'\n",
    "path_data = path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_QUBICC_R02B05/based_on_var_interpolated_data'\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "sys.path.insert(0, path + '/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "import my_classes\n",
    "importlib.reload(my_classes)\n",
    "from my_classes import simple_sundqvist_scheme\n",
    "from my_classes import write_infofile\n",
    "from my_classes import load_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "NUM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents crashes of the code\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the growth of memory Tensorflow allocates (limits memory usage overall)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is not yet normalized\n",
    "input_data = np.load(path_data + '/cloud_cover_input_qubicc.npy', mmap_mode='r')\n",
    "output_data = np.load(path_data + '/cloud_cover_output_qubicc.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(samples_total, no_of_features) = input_data.shape\n",
    "assert no_of_features < samples_total # Making sure there's no mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input data = (samples_total, no_of_features)\n",
    "scaler.fit(input_data)\n",
    "assert len(scaler.mean_) == no_of_features # Every feature has its own mean and std and we scale accordingly\n",
    "input_data_scaled = scaler.transform(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the multiple linear model on the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.00159311294556\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# The optimal multiple linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(input_data_scaled, output_data)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error of the linear model is 401.47.\n"
     ]
    }
   ],
   "source": [
    "# Loss of this optimal multiple linear regression model\n",
    "clc_predictions = lin_reg.predict(input_data_scaled)\n",
    "lin_mse = mean_squared_error(output_data, clc_predictions)\n",
    "print('The mean squared error of the linear model is %.2f.'%lin_mse) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923.9371442759749"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(output_data**2, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684.5114016334184"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(output_data, dtype=np.float64)\n",
    "np.mean((output_data-mean)**2, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly initialized neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(units=64, activation='tanh', input_dim=no_of_features, \n",
    "                kernel_regularizer=l1_l2(l1=0.004749, l2=0.008732)))\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(Dense(units=64, activation=nn.leaky_relu, kernel_regularizer=l1_l2(l1=0.004749, l2=0.008732)))\n",
    "# model.add(Dropout(0.221)) # We drop 18% of the hidden nodes\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Third hidden layer\n",
    "model.add(Dense(units=64, activation='tanh', kernel_regularizer=l1_l2(l1=0.004749, l2=0.008732)))\n",
    "# model.add(Dropout(0.221)) # We drop 18% of the hidden nodes\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='linear', kernel_regularizer=l1_l2(l1=0.004749, l2=0.008732)))\n",
    "model.compile(loss='mse', optimizer=Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fold_3 is implemented in ICON-A\n",
    "batch_size = 2**20\n",
    "\n",
    "for i in range(1 + input_data_scaled.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        clc_predictions = model.predict_on_batch(input_data_scaled[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        clc_predictions = np.concatenate((clc_predictions, model.predict_on_batch(input_data_scaled[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error of the randomly initialized neural network is 913.91.\n"
     ]
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(output_data, clc_predictions[:, 0])\n",
    "print('The mean squared error of the randomly initialized neural network is %.2f.'%lin_mse) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Sundqvist function\n",
    "\n",
    "input_data is unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qv = input_data[:, 0]\n",
    "temp = input_data[:, 3]\n",
    "pres = input_data[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367.98427391052246"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# 0.001% of the data\n",
    "ind = np.random.randint(0, samples_total, samples_total//10**5)\n",
    "\n",
    "# Entries will be in [0, 1]\n",
    "sundqvist = []\n",
    "for i in ind:\n",
    "    sundqvist.append(simple_sundqvist_scheme(qv[i], temp[i], pres[i], ps=101325))\n",
    "    \n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773.5590553245462"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((output_data[ind] - 100*np.array(sundqvist))**2, dtype=np.float64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds113_kernel",
   "language": "python",
   "name": "clouds113_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
