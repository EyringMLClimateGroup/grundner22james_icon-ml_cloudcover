{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression\n",
    "\n",
    "**For Table 3 of the paper**\n",
    "\n",
    "Neighborhood-based NARVAL R2B4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "base_path = '/pf/b/b309170'\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "sys.path.insert(0, base_path + '/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "import my_classes\n",
    "importlib.reload(my_classes)\n",
    "from my_classes import write_infofile\n",
    "from my_classes import load_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "NUM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/pf/b/b309170'\n",
    "data_path = os.path.join(root_path,\n",
    "                         'my_work/icon-ml_data/cloud_cover_parameterization/region_based/based_on_var_interpolated_data')\n",
    "model_path = os.path.join(root_path,\n",
    "                          'workspace_icon-ml/cloud_cover_parameterization/region_based/saved_models')\n",
    "info_file = os.path.join(root_path, \n",
    "                        'workspace_icon-ml/cloud_cover_parameterization/region_based/saved_models/model_region_based_final_1.txt')\n",
    "\n",
    "n_layers = 27 # Is also the number of NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data (Data is already normalized w.r.t. training data)\n",
    "input_train = np.load(os.path.join(data_path, 'cloud_cover_input_train_1.npy'))\n",
    "output_train = np.load(os.path.join(data_path, 'cloud_cover_output_train_1.npy'))\n",
    "input_valid = np.load(os.path.join(data_path, 'cloud_cover_input_valid_1.npy'))\n",
    "output_valid = np.load(os.path.join(data_path, 'cloud_cover_output_valid_1.npy'))\n",
    "input_test = np.load(os.path.join(data_path, 'cloud_cover_input_test_1.npy')) \n",
    "output_test = np.load(os.path.join(data_path, 'cloud_cover_output_test_1.npy')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data pertaining to a specific NN\n",
    "n_train_samples = output_train.shape[0]\n",
    "n_valid_samples = output_valid.shape[0]\n",
    "n_test_samples = output_test.shape[0]\n",
    "n_features = input_train.shape[1]\n",
    "\n",
    "# Load the data into dictionaries. Can't use 3D tensors here as some features will be removed depending on the NN.\n",
    "input_train_NN = {}\n",
    "for i in range(n_layers):\n",
    "    input_train_NN[i] = np.zeros((n_train_samples//n_layers, n_features))\n",
    "    \n",
    "output_train_NN = {}\n",
    "for i in range(n_layers):\n",
    "    output_train_NN[i] = np.zeros((n_train_samples//n_layers))\n",
    "    \n",
    "input_valid_NN = {}\n",
    "for i in range(n_layers):\n",
    "    input_valid_NN[i] = np.zeros((n_valid_samples//n_layers, n_features))\n",
    "    \n",
    "output_valid_NN = {}\n",
    "for i in range(n_layers):\n",
    "    output_valid_NN[i] = np.zeros((n_valid_samples//n_layers))\n",
    "    \n",
    "input_test_NN = {}\n",
    "for i in range(n_layers):\n",
    "    input_test_NN[i] = np.zeros((n_test_samples//n_layers, n_features))\n",
    "    \n",
    "output_test_NN = {}\n",
    "for i in range(n_layers):\n",
    "    output_test_NN[i] = np.zeros((n_test_samples//n_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_layers):\n",
    "    start_ind_train = (n_train_samples//27)*i\n",
    "    end_ind_train = (n_train_samples//27)*(i+1)\n",
    "    start_ind_valid = (n_valid_samples//27)*i\n",
    "    end_ind_valid = (n_valid_samples//27)*(i+1)\n",
    "    start_ind_test = (n_test_samples//27)*i\n",
    "    end_ind_test = (n_test_samples//27)*(i+1) \n",
    "\n",
    "    input_train_NN[i] = input_train[start_ind_train:end_ind_train]\n",
    "    output_train_NN[i] = output_train[start_ind_train:end_ind_train]\n",
    "    input_valid_NN[i] = input_valid[start_ind_valid:end_ind_valid]\n",
    "    output_valid_NN[i] = output_valid[start_ind_valid:end_ind_valid]\n",
    "    input_test_NN[i] = input_test[start_ind_test:end_ind_test]  \n",
    "    output_test_NN[i] = output_test[start_ind_test:end_ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the input variables with zero variance. We compute the resulting input dimension for the NN.\n",
    "input_dim = n_features\n",
    "for i in range(n_layers):\n",
    "    vars_to_remove = []\n",
    "    for j in range(n_features):\n",
    "        if np.var(input_train_NN[i][:, j]) == 0 or np.isnan(np.var(input_train_NN[i][:, j])):\n",
    "            input_dim -= 1\n",
    "            vars_to_remove.append(j)\n",
    "    input_train_NN[i] = np.delete(input_train_NN[i], vars_to_remove, axis=1)\n",
    "    input_valid_NN[i] = np.delete(input_valid_NN[i], vars_to_remove, axis=1)\n",
    "    input_test_NN[i] = np.delete(input_test_NN[i], vars_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking standardization:\n",
    "thresh = 1e-5\n",
    "[np.abs(np.mean(input_train_NN[0][:, j]))<thresh and np.abs(np.var(input_train_NN[0][:, j])-1)<thresh for j in range(input_train_NN[0].shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the multiple linear model on the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "for i in range(n_layers):\n",
    "    input_data.append(np.concatenate((input_train_NN[i], input_valid_NN[i], input_test_NN[i]), \n",
    "                                     axis=0))\n",
    "    output_data.append(np.concatenate((output_train_NN[i], output_valid_NN[i], output_test_NN[i]), \n",
    "                                      axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error of the linear model is 0.16.\n",
      "The mean squared error of the linear model is 2.30.\n",
      "The mean squared error of the linear model is 9.69.\n",
      "The mean squared error of the linear model is 17.96.\n",
      "The mean squared error of the linear model is 16.33.\n",
      "The mean squared error of the linear model is 10.57.\n",
      "The mean squared error of the linear model is 6.03.\n",
      "The mean squared error of the linear model is 4.76.\n",
      "The mean squared error of the linear model is 3.25.\n",
      "The mean squared error of the linear model is 2.45.\n",
      "The mean squared error of the linear model is 2.36.\n",
      "The mean squared error of the linear model is 2.48.\n",
      "The mean squared error of the linear model is 1.94.\n",
      "The mean squared error of the linear model is 1.37.\n",
      "The mean squared error of the linear model is 1.54.\n",
      "The mean squared error of the linear model is 2.15.\n",
      "The mean squared error of the linear model is 3.14.\n",
      "The mean squared error of the linear model is 5.06.\n",
      "The mean squared error of the linear model is 7.67.\n",
      "The mean squared error of the linear model is 8.67.\n",
      "The mean squared error of the linear model is 5.96.\n",
      "The mean squared error of the linear model is 2.43.\n",
      "The mean squared error of the linear model is 0.96.\n",
      "The mean squared error of the linear model is 0.37.\n",
      "The mean squared error of the linear model is 0.19.\n",
      "33.34947490692139\n",
      "The overall mean MSE is: 4.792\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "mean_lin_mse = 0\n",
    "\n",
    "# Leave out the two upper-most layers\n",
    "for i in range(2, n_layers):\n",
    "    # The optimal multiple linear regression models\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(input_data[i], output_data[i])\n",
    "    \n",
    "    # Loss of this optimal multiple linear regression model\n",
    "    clc_predictions = lin_reg.predict(input_data[i])\n",
    "    lin_mse = mean_squared_error(output_data[i], clc_predictions)\n",
    "    print('The mean squared error of the linear model is %.2f.'%lin_mse) \n",
    "    \n",
    "    mean_lin_mse += lin_mse\n",
    "\n",
    "print(time.time() - t0)\n",
    "print('The overall mean MSE is: %.3f'%(mean_lin_mse/(n_layers-2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.37236371975237\n"
     ]
    }
   ],
   "source": [
    "mean_zero_output = 0\n",
    "\n",
    "for i in range(2, n_layers):\n",
    "    zero_output_mse = np.mean(output_data[i]**2, dtype=np.float64)\n",
    "    mean_zero_output += zero_output_mse\n",
    "    \n",
    "print(mean_zero_output/(n_layers-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.48432970951315\n"
     ]
    }
   ],
   "source": [
    "mean_constant_output = 0\n",
    "\n",
    "for i in range(2, n_layers):\n",
    "    mean = np.mean(output_data[i], dtype=np.float64)\n",
    "    constant_output_mse = np.mean((output_data[i]-mean)**2, dtype=np.float64)\n",
    "    mean_constant_output += constant_output_mse\n",
    "    \n",
    "print(mean_constant_output/(n_layers-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly initialized neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error of the randomly initialized neural network is 1.19.\n",
      "The mean squared error of the randomly initialized neural network is 27.70.\n",
      "The mean squared error of the randomly initialized neural network is 129.42.\n",
      "The mean squared error of the randomly initialized neural network is 268.78.\n",
      "The mean squared error of the randomly initialized neural network is 282.07.\n",
      "The mean squared error of the randomly initialized neural network is 196.40.\n",
      "The mean squared error of the randomly initialized neural network is 127.86.\n",
      "The mean squared error of the randomly initialized neural network is 103.37.\n",
      "The mean squared error of the randomly initialized neural network is 67.30.\n",
      "The mean squared error of the randomly initialized neural network is 52.54.\n",
      "The mean squared error of the randomly initialized neural network is 60.23.\n",
      "The mean squared error of the randomly initialized neural network is 68.45.\n",
      "The mean squared error of the randomly initialized neural network is 52.17.\n",
      "The mean squared error of the randomly initialized neural network is 35.05.\n",
      "The mean squared error of the randomly initialized neural network is 38.73.\n",
      "The mean squared error of the randomly initialized neural network is 53.87.\n",
      "The mean squared error of the randomly initialized neural network is 87.97.\n",
      "The mean squared error of the randomly initialized neural network is 157.50.\n",
      "The mean squared error of the randomly initialized neural network is 269.23.\n",
      "The mean squared error of the randomly initialized neural network is 362.68.\n",
      "The mean squared error of the randomly initialized neural network is 282.13.\n",
      "The mean squared error of the randomly initialized neural network is 82.14.\n",
      "The mean squared error of the randomly initialized neural network is 18.79.\n",
      "The mean squared error of the randomly initialized neural network is 5.40.\n",
      "The mean squared error of the randomly initialized neural network is 2.50.\n",
      "The overall mean is 113.338\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "mean_nn_mse = 0\n",
    "\n",
    "for i in range(2, n_layers):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_dim = input_data[i].shape[1]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=Nadam())\n",
    "    \n",
    "    # model_fold_3 is implemented in ICON-A\n",
    "    batch_size = 2**20\n",
    "\n",
    "    for j in range(1 + input_data[i].shape[0]//batch_size):\n",
    "        if j == 0:\n",
    "            clc_predictions = model.predict_on_batch(input_data[i][j*batch_size:(j+1)*batch_size])\n",
    "        else:\n",
    "            clc_predictions = np.concatenate((clc_predictions, model.predict_on_batch(input_data[i][j*batch_size:(j+1)*batch_size])), axis=0)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "    nn_mse = mean_squared_error(output_data[i], clc_predictions[:, 0])\n",
    "    print('The mean squared error of the randomly initialized neural network is %.2f.'%nn_mse)\n",
    "    \n",
    "    mean_nn_mse += nn_mse\n",
    "    \n",
    "print('The overall mean is %.3f'%(mean_nn_mse/(n_layers-2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds113_kernel",
   "language": "python",
   "name": "clouds113_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
