{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "**For Table 3 of the paper**\n",
    "\n",
    "Column-based QUBICC R2B5 model\n",
    "\n",
    "Requires more than 8 hours for n_estimators = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import tensorflow.nn as nn\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents crashes of the code\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the growth of memory Tensorflow allocates (limits memory usage overall)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/b/b309170'\n",
    "path_data = path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_column_based_QUBICC_R02B05/based_on_var_interpolated_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = np.transpose(np.load(path_data + '/cloud_cover_input_qubicc.npy', mmap_mode='r'))\n",
    "# output_data = np.transpose(np.load(path_data + '/cloud_cover_output_qubicc.npy', mmap_mode='r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (samples_total, no_of_features) = input_data.shape\n",
    "# assert no_of_features == 163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that are constant in at least one of the training folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # These features correspond to qc_4, qc_5, qc_6, qc_7, qc_8, qc_9, zg_4, zg_5, zg_6\n",
    "# remove_fields = [27, 28, 29, 30, 31, 32, 135, 136, 137]\n",
    "# input_data = np.delete(input_data, remove_fields, axis=1)\n",
    "# no_of_features = no_of_features - len(remove_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_folds = []\n",
    "# validation_folds = []\n",
    "# two_week_incr = samples_total//6\n",
    "\n",
    "# for i in range(3):\n",
    "#     # Note that this is a temporal split since time was the first dimension in the original tensor\n",
    "#     first_incr = np.arange(samples_total//6*i, samples_total//6*(i+1))\n",
    "#     second_incr = np.arange(samples_total//6*(i+3), samples_total//6*(i+4))\n",
    "\n",
    "#     validation_folds.append(np.append(first_incr, second_incr))\n",
    "#     training_folds.append(np.arange(samples_total))\n",
    "#     training_folds[i] = np.delete(training_folds[i], validation_folds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Need the second split\n",
    "\n",
    "# #Standardize according to the fold\n",
    "# scaler.fit(input_data[training_folds[1],:])\n",
    "\n",
    "# #Load the data for the respective fold and convert it to tf data\n",
    "# input_train = scaler.transform(input_data[training_folds[1]])\n",
    "# input_valid = scaler.transform(input_data[validation_folds[1]])\n",
    "# output_train = output_data[training_folds[1]]\n",
    "# output_valid = output_data[validation_folds[1]]\n",
    "\n",
    "# np.save('RFs/column_based_R2B5_input_train.npy', input_train)\n",
    "# np.save('RFs/column_based_R2B5_input_valid.npy', input_valid)\n",
    "# np.save('RFs/column_based_R2B5_output_train.npy', output_train)\n",
    "# np.save('RFs/column_based_R2B5_output_valid.npy', output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/column_based_R2B5_input_train.npy')\n",
    "input_valid = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/column_based_R2B5_input_valid.npy')\n",
    "output_train = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/column_based_R2B5_output_train.npy')\n",
    "output_valid = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/column_based_R2B5_output_valid.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Timing (on Mistral)\n",
    "\n",
    "# n_estimators = 1, max_depth = 1: 4040s\n",
    "# n_estimators = 5, max_depth = 6: 4040*30s is close to 34 hrs\n",
    "\n",
    "# Using n_estimators = 5, max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = 5 didn't finish\n",
    "# max_depth = 2 should theoretically finish in 8 hours\n",
    "# max_depth = 3 should theoretically finish in 10 hours, it finished in 12 hours\n",
    "# max_depth = 5 should theoretically finish in 16 hours\n",
    "rf = RandomForestRegressor(n_estimators = 5, max_depth = 5, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(input_train, output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf, \"/home/b/b309170/scratch/column_based_R2B5_uncompressed_md_5.joblib\", compress=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = joblib.load(\"/home/b/b309170/scratch/column_based_R2B5_uncompressed_md_5.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fold_3 is implemented in ICON-A\n",
    "batch_size = 2**20\n",
    "\n",
    "for i in range(1 + input_valid.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        clc_predictions = rf.predict(input_valid[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        clc_predictions = np.concatenate((clc_predictions, rf.predict(input_valid[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_rf = mean_squared_error(output_valid, clc_predictions)\n",
    "\n",
    "with open('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/RF_results.txt', 'a') as file:\n",
    "    file.write('The MSE on the validation set of the column-based R2B5 RF is %.2f.\\n'%mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds_kernel",
   "language": "python",
   "name": "clouds_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
