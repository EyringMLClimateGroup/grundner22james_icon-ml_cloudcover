{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "**For Table 3 of the paper**\n",
    "\n",
    "Cell-based QUBICC R2B5 model\n",
    "\n",
    "n_estimator = 1 takes 6h 36s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import tensorflow as tf\n",
    "import tensorflow.nn as nn\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "#Import sklearn before tensorflow (static Thread-local storage)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "path = '/home/b/b309170'\n",
    "path_data = path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_QUBICC_R02B05/based_on_var_interpolated_data'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "NUM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents crashes of the code\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the growth of memory Tensorflow allocates (limits memory usage overall)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data is not yet normalized\n",
    "# input_data = np.load(path_data + '/cloud_cover_input_qubicc.npy', mmap_mode='r')\n",
    "# output_data = np.load(path_data + '/cloud_cover_output_qubicc.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (samples_total, no_of_features) = input_data.shape\n",
    "# assert no_of_features < samples_total # Making sure there's no mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into training and validation (need split 2)\n",
    "# training_folds = []\n",
    "# validation_folds = []\n",
    "# two_week_incr = samples_total//6\n",
    "\n",
    "# for i in range(3):\n",
    "#     # Note that this is a temporal split since time was the first dimension in the original tensor\n",
    "#     first_incr = np.arange(samples_total//6*i, samples_total//6*(i+1))\n",
    "#     second_incr = np.arange(samples_total//6*(i+3), samples_total//6*(i+4))\n",
    "\n",
    "#     validation_folds.append(np.append(first_incr, second_incr))\n",
    "#     training_folds.append(np.arange(samples_total))\n",
    "#     training_folds[i] = np.delete(training_folds[i], validation_folds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Need the second split\n",
    "\n",
    "# #Standardize according to the fold\n",
    "# scaler.fit(input_data[training_folds[1]])\n",
    "\n",
    "# #Load the data for the respective fold and convert it to tf data\n",
    "# input_train = scaler.transform(input_data[training_folds[1]])\n",
    "# input_valid = scaler.transform(input_data[validation_folds[1]]) \n",
    "# output_train = output_data[training_folds[1]]\n",
    "# output_valid = output_data[validation_folds[1]]\n",
    "\n",
    "# np.save('RFs/cell_based_R2B5_input_train.npy', input_train)\n",
    "# np.save('RFs/cell_based_R2B5_input_valid.npy', input_valid)\n",
    "# np.save('RFs/cell_based_R2B5_output_train.npy', output_train)\n",
    "# np.save('RFs/cell_based_R2B5_output_valid.npy', output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/cell_based_R2B5_input_train.npy')\n",
    "input_valid = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/cell_based_R2B5_input_valid.npy')\n",
    "output_train = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/cell_based_R2B5_output_train.npy')\n",
    "output_valid = np.load('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/cell_based_R2B5_output_valid.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 5\n",
    "md = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size on disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for k in range(md):\n",
    "    s += 2**(7+k)\n",
    "    \n",
    "# Expected/maximal size on disk\n",
    "1186 + n_est*322 + n_est*s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=8, n_estimators=5, random_state=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = n_est, max_depth = md, random_state = 10)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(input_train, output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/b/b309170/scratch/cell_based_R2B5_uncompressed_smaller_md_8.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf, \"/home/b/b309170/scratch/cell_based_R2B5_uncompressed_smaller_md_8.joblib\", compress=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166238"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be around 159000\n",
    "os.path.getsize('/home/b/b309170/scratch/cell_based_R2B5_uncompressed_smaller_md_8.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 8]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tree.tree_.max_depth for tree in rf.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fold_3 is implemented in ICON-A\n",
    "batch_size = 2**20\n",
    "\n",
    "for i in range(1 + input_valid.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        clc_predictions = rf.predict(input_valid[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        clc_predictions = np.concatenate((clc_predictions, rf.predict(input_valid[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_rf = mean_squared_error(output_valid, clc_predictions)\n",
    "\n",
    "with open('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/RF_results.txt', 'a') as file:\n",
    "    file.write('The MSE on the validation set of the smaller cell-based R2B5 RF with md of 8 is %.2f.\\n'%mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
