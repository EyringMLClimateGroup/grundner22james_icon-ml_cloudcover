{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "**For Table 3 of the paper**\n",
    "\n",
    "Cell-based NARVAL R2B4 RF\n",
    "\n",
    "We can quickly estimate the required time to train a RF by training a RF with n_estimators = 1, dividing that time by 36 and interpreting the result in hours.\n",
    "\n",
    "--> Would need at least **10 hours** to train it on Mistral with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "base_path = '/home/b/b309170'\n",
    "path_data = base_path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_v3/based_on_var_interpolated_data'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "NUM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is already normalized (w.r.t. training data)\n",
    "input_train = np.load(path_data + '/cloud_cover_all_days_input_train_%d.npy'%NUM, mmap_mode='r')\n",
    "input_valid = np.load(path_data + '/cloud_cover_all_days_input_valid_%d.npy'%NUM)\n",
    "input_test = np.load(path_data + '/cloud_cover_all_days_input_test_%d.npy'%NUM)\n",
    "output_train = np.load(path_data + '/cloud_cover_all_days_output_train_%d.npy'%NUM)\n",
    "output_valid = np.load(path_data + '/cloud_cover_all_days_output_valid_%d.npy'%NUM)\n",
    "output_test = np.load(path_data + '/cloud_cover_all_days_output_test_%d.npy'%NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26482169, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The hyperparameters that influence computational time heavily are *n_estimators, max_depth, max_samples*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Timing (on Mistral)\n",
    "\n",
    "# n_estimators = 1, max_depth = 1, min_samples_split = 6, max_leaf_nodes = 2, max_samples = 1: 0.8s\n",
    "# n_estimators = 1, max_depth = 1, min_samples_split = 6, max_leaf_nodes = 2:                  16s\n",
    "# n_estimators = 1, max_depth = 1, min_samples_split = 6, max_samples = 1:                     0.8s\n",
    "# n_estimators = 1, max_depth = 1, max_samples = 1:                                            0.8s\n",
    "\n",
    "# n_estimators = 1, max_depth = 1:                                                             16s\n",
    "# n_estimators = 1, max_depth = 2:                                                             33s\n",
    "# n_estimators = 1, max_depth = 3:                                                             46s\n",
    "# n_estimators = 1, max_depth = 10:                                                            140s\n",
    "\n",
    "# n_estimators = 2, max_depth = 1:                                                             33s\n",
    "# n_estimators = 3, max_depth = 1:                                                             48s\n",
    "# n_estimators = 5, max_depth = 1:                                                             81s\n",
    "# n_estimators = 10, max_depth = 1:                                                            160s\n",
    "\n",
    "# n_estimators = 1:                                                                            356s\n",
    "# n_estimators = 2:                                                                            721s\n",
    "# n_estimators = 3:                                                                            1101s\n",
    "# n_estimators = 4:                                                                            1469s\n",
    "# n_estimators = 5:                                                                            1813s\n",
    "# n_estimators = 10:                                                                           3636s\n",
    "# --> Increases linearly!\n",
    "\n",
    "# a = [1,2,3,4,5,10]\n",
    "# t_a = [356, 721, 1101, 1469, 1813, 3636]\n",
    "# print('The trend is very linear: %s'%str(np.array(t_a)/np.array(a)))\n",
    "# print('I thus expect that to train the default setting of n_estimators = 100 we need %d hours'%(100*363.6/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=2, random_state=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 340, random_state = 10)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(input_train, output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/b/b309170/scratch/RF_compressed.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf, \"/home/b/b309170/scratch/cell_based_R2B4_uncompressed.joblib\", compress=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fold_3 is implemented in ICON-A\n",
    "batch_size = 2**20\n",
    "\n",
    "for i in range(1 + input_test.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        clc_predictions = rf.predict(input_test[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        clc_predictions = np.concatenate((clc_predictions, rf.predict(input_test[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_mse = mean_squared_error(output_test, clc_predictions)\n",
    "\n",
    "with open('/home/b/b309170/workspace_icon-ml/iconml_clc/additional_content/baselines/RFs/RF_results.txt', 'a') as file:\n",
    "    file.write('The MSE on the test set of the cell-based R2B4 RF is %.2f.\\n'%lin_mse) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction timing RF vs NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = np.load(path_data + '/cloud_cover_all_days_input_test_%d.npy'%NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = joblib.load(\"/home/b/b309170/scratch/cell_based_R2B4_uncompressed.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = load_model(\"/home/b/b309170/workspace_icon-ml/iconml_clc/n1_cell_based_narval_r2b4/saved_models/model_grid_cell_based_v3_final_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 2**20\n",
    "\n",
    "for i in range(1 + input_test.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        clc_predictions = rf.predict(input_test[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        clc_predictions = np.concatenate((clc_predictions, rf.predict(input_test[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 42s, sys: 23 s, total: 5min 5s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 2**20\n",
    "\n",
    "for i in range(1 + input_test.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        clc_predictions = nn.predict(input_test[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        clc_predictions = np.concatenate((clc_predictions, nn.predict(input_test[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds_kernel",
   "language": "python",
   "name": "clouds_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
