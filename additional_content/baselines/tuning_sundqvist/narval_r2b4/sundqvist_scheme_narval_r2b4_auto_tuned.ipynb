{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sundqvist Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we fit the Sundqvist model where we fit the tuning parameters to the data? <br>\n",
    "We let the parameters depend on whether they are taken over land or over the sea.\n",
    "\n",
    "In this version, we find the optimal set of hyperparameters automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 samples, grid_spacing of 0.2: 12 seconds\n",
    "# 1000 samples, grid_spacing of 0.1: 130 seconds\n",
    "\n",
    "# 100.000 samples, grid_spacing of 0.2: 850 seconds\n",
    "# 100.000 samples, grid_spacing of 0.1: Should take 2-3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 10:45:54.757621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "sys.path.insert(0, '/home/b/b309170/workspace_icon-ml/symbolic_regression/')\n",
    "from functions import evaluate_sundqvist\n",
    "\n",
    "# Added to the PDF name\n",
    "ran = np.random.randint(10**3)\n",
    "print(ran)\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load columns of data\n",
    "folder_data = '/home/b/b309170/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_v3/based_on_var_interpolated_data'\n",
    "\n",
    "input_train = np.load(os.path.join(folder_data, 'cloud_cover_all_days_input_train_1.npy'))\n",
    "input_valid = np.load(os.path.join(folder_data, 'cloud_cover_all_days_input_valid_1.npy'))\n",
    "output_train = np.load(os.path.join(folder_data, 'cloud_cover_all_days_output_train_1.npy'))\n",
    "output_valid = np.load(os.path.join(folder_data, 'cloud_cover_all_days_output_valid_1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscale the data\n",
    "mean = [5.37518440e-03, 4.65389731e-07, 2.59635412e+02, 5.52329389e+04, 6.79260772e+03, 2.58097095e-01]\n",
    "std = [6.01943993e-03, 3.95009930e-06, 3.55940285e+01, 3.26642242e+04, 6.20726361e+03, 4.28313535e-01]\n",
    "\n",
    "input_train = input_train*std + mean\n",
    "input_valid = input_valid*std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load surface pressure\n",
    "ps_train = np.load(os.path.join(folder_data, 'ps_unscaled_input_train_1.npy'))\n",
    "ps_valid = np.load(os.path.join(folder_data, 'ps_unscaled_input_valid_1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = np.concatenate((input_train, np.expand_dims(ps_train, 1)), axis=1)\n",
    "input_valid = np.concatenate((input_valid, np.expand_dims(ps_valid, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26482169, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features\n",
    "new_features = ['qv', 'qi', 'temp', 'pres', 'zg', 'fr_land', 'ps']\n",
    "\n",
    "# To locate variables\n",
    "loc = {}\n",
    "for i in range(len(new_features)):\n",
    "    loc[new_features[i]] = i\n",
    "    \n",
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relative humidity\n",
    "pres_train = input_train[:, loc['pres']]\n",
    "qv = input_train[:, loc['qv']]\n",
    "temp = input_train[:, loc['temp']]\n",
    "\n",
    "T0 = 273.15\n",
    "r = 0.00263*pres_train*qv*np.exp((17.67*(temp-T0))/(temp-29.65))**(-1)\n",
    "\n",
    "new_features.append('rh')\n",
    "input_train = np.append(input_train, np.expand_dims(r, -1), axis=1)\n",
    "\n",
    "# The same for input_valid\n",
    "pres_valid = input_valid[:, loc['pres']]\n",
    "qv = input_valid[:, loc['qv']]\n",
    "temp = input_valid[:, loc['temp']]\n",
    "\n",
    "T0 = 273.15\n",
    "r = 0.00263*pres_valid*qv*np.exp((17.67*(temp-T0))/(temp-29.65))**(-1)\n",
    "\n",
    "input_valid = np.append(input_valid, np.expand_dims(r, -1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26482169, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating loc\n",
    "loc = {}\n",
    "for i in range(len(new_features)):\n",
    "    loc[new_features[i]] = i\n",
    "    \n",
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the training data into cells over land vs sea\n",
    "land_ind = np.where(input_train[:, loc['fr_land']] > 0.5)[0]\n",
    "sea_ind = np.where(input_train[:, loc['fr_land']] <= 0.5)[0]\n",
    "\n",
    "input_land = input_train[land_ind]\n",
    "output_land = output_train[land_ind]\n",
    "input_sea = input_train[sea_ind]\n",
    "output_sea = output_train[sea_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.260109660957152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(land_ind)/input_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting hyperparameters\n",
    "Original ones: $r_{sat} = 1, r_{0, top} = 0.8, r_{0, surf} = 0.968, n = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sundq_Layer(tf.keras.layers.Layer):\n",
    "\n",
    "    # These are the output units\n",
    "    def __init__(self, units=1):\n",
    "        super(Sundq_Layer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        \n",
    "        # Initializing with the original values\n",
    "        # rsat must always be greater than r0_top and r0_surf! How could we enforce this? (*)\n",
    "        rsat_init = tf.constant_initializer(1)\n",
    "        r0_top_init = tf.constant_initializer(0.8)\n",
    "        r0_surf_init = tf.constant_initializer(0.968)\n",
    "        n_init = tf.constant_initializer(2)  \n",
    "    \n",
    "        self.rsat = tf.Variable(name='rsat', initial_value=rsat_init(shape=(1, self.units), dtype='float32'), trainable=True)\n",
    "        self.r0_top = tf.Variable(name='r0_top', initial_value=r0_top_init(shape=(1, self.units), dtype='float32'), trainable=True)\n",
    "        self.r0_surf = tf.Variable(name='r0_surf', initial_value=r0_surf_init(shape=(1, self.units), dtype='float32'), trainable=True)\n",
    "        self.n = tf.Variable(name='n', initial_value=n_init(shape=(1, self.units), dtype='float32'), trainable=True)\n",
    "\n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        ps = inputs[:, 0]\n",
    "        p = inputs[:, 1]\n",
    "        rh = inputs[:, 2]\n",
    "        \n",
    "        r0 = self.r0_top + (self.r0_surf - self.r0_top)*tf.exp(1-(ps/p)**self.n)\n",
    "        \n",
    "        # div < 0, only if rsat < r0. But this goes against (*)\n",
    "        div = (tf.minimum(rh, self.rsat) - self.rsat)/(r0 - self.rsat)\n",
    "        \n",
    "        # tf.sqrt is tricky, because its gradient in 0 is infinite!\n",
    "        c = 1 - tf.sqrt(tf.maximum(div, 1e-9)) # in [0,1]\n",
    "        \n",
    "        # If rh > r0 we return c, otherwise we set it to 0\n",
    "        c_out = tf.maximum(tf.sign(rh - r0), 0)*c\n",
    "        \n",
    "        return 100*tf.transpose(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Land**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from the hyperparameter search\n",
    "epochs_opt = 10\n",
    "batchsize_opt = 32\n",
    "optimizer_opt = tf.keras.optimizers.Adagrad\n",
    "lr_opt = 0.0523026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 10:51:10.681549: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-16 10:51:10.682286: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-16 10:51:10.682297: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-16 10:51:10.682320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (l40148.atos.local): /proc/driver/nvidia/version does not exist\n",
      "2022-04-16 10:51:10.683741: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-16 10:51:10.692182: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "sundq_layer = Sundq_Layer()\n",
    "model = tf.keras.models.Sequential(sundq_layer)\n",
    "model.compile(optimizer=optimizer_opt(learning_rate=lr_opt), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 10:51:18.221779: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-16 10:51:18.237321: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2450085000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING: AutoGraph could not transform <bound method Sundq_Layer.call of <__main__.Sundq_Layer object at 0x7ffb35d1a430>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215259/215259 [==============================] - 79s 365us/step - loss: 123.8615\n",
      "[array([[2.422234]], dtype=float32), array([[0.00693164]], dtype=float32), array([[0.59241045]], dtype=float32), array([[0.91213924]], dtype=float32)]\n",
      "Epoch 2/10\n",
      "215259/215259 [==============================] - 76s 352us/step - loss: 108.0200\n",
      "[array([[2.497706]], dtype=float32), array([[-0.00656802]], dtype=float32), array([[0.5860639]], dtype=float32), array([[0.9103264]], dtype=float32)]\n",
      "Epoch 3/10\n",
      "215259/215259 [==============================] - 74s 344us/step - loss: 107.9200\n",
      "[array([[2.5178297]], dtype=float32), array([[-0.00787538]], dtype=float32), array([[0.5867613]], dtype=float32), array([[0.9091117]], dtype=float32)]\n",
      "Epoch 4/10\n",
      "215259/215259 [==============================] - 75s 350us/step - loss: 107.6992\n",
      "[array([[2.5222697]], dtype=float32), array([[-0.00882611]], dtype=float32), array([[0.5864485]], dtype=float32), array([[0.9115208]], dtype=float32)]\n",
      "Epoch 5/10\n",
      "215259/215259 [==============================] - 78s 361us/step - loss: 108.0620\n",
      "[array([[2.5235522]], dtype=float32), array([[-0.00989761]], dtype=float32), array([[0.5850912]], dtype=float32), array([[0.9149365]], dtype=float32)]\n",
      "Epoch 6/10\n",
      "215259/215259 [==============================] - 77s 358us/step - loss: 107.8374\n",
      "[array([[2.5239205]], dtype=float32), array([[-0.00789214]], dtype=float32), array([[0.5860523]], dtype=float32), array([[0.91432315]], dtype=float32)]\n",
      "Epoch 7/10\n",
      "215259/215259 [==============================] - 76s 353us/step - loss: 107.8960\n",
      "[array([[2.523299]], dtype=float32), array([[-0.01017929]], dtype=float32), array([[0.58672917]], dtype=float32), array([[0.91310143]], dtype=float32)]\n",
      "Epoch 8/10\n",
      "215259/215259 [==============================] - 76s 353us/step - loss: 108.1492\n",
      "[array([[2.5237143]], dtype=float32), array([[-0.00863434]], dtype=float32), array([[0.5851522]], dtype=float32), array([[0.91515195]], dtype=float32)]\n",
      "Epoch 9/10\n",
      "215259/215259 [==============================] - 77s 356us/step - loss: 107.5902\n",
      "[array([[2.5232718]], dtype=float32), array([[-0.00820426]], dtype=float32), array([[0.5855998]], dtype=float32), array([[0.91195416]], dtype=float32)]\n",
      "Epoch 10/10\n",
      "215259/215259 [==============================] - 78s 363us/step - loss: 107.9020\n",
      "[array([[2.5241508]], dtype=float32), array([[-0.0085735]], dtype=float32), array([[0.58564645]], dtype=float32), array([[0.91154075]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "\n",
    "history = model.fit(input_land[:, [loc['ps'], loc['pres'], loc['rh']]], output_land, epochs=epochs_opt, batch_size=batchsize_opt, \\\n",
    "                   callbacks = [print_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sundq__layer/rsat:0' shape=(1, 1) dtype=float32, numpy=array([[2.5241508]], dtype=float32)>,\n",
       " <tf.Variable 'sundq__layer/r0_top:0' shape=(1, 1) dtype=float32, numpy=array([[-0.0085735]], dtype=float32)>,\n",
       " <tf.Variable 'sundq__layer/r0_surf:0' shape=(1, 1) dtype=float32, numpy=array([[0.58564645]], dtype=float32)>,\n",
       " <tf.Variable 'sundq__layer/n:0' shape=(1, 1) dtype=float32, numpy=array([[0.91154075]], dtype=float32)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sundq_layer = Sundq_Layer()\n",
    "model = tf.keras.models.Sequential(sundq_layer)\n",
    "model.compile(optimizer=optimizer_opt(learning_rate=lr_opt), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "612310/612310 [==============================] - 222s 361us/step - loss: 73.2702\n",
      "[array([[2.1460562]], dtype=float32), array([[0.161563]], dtype=float32), array([[0.71197987]], dtype=float32), array([[1.9643687]], dtype=float32)]\n",
      "Epoch 2/10\n",
      "612310/612310 [==============================] - 223s 364us/step - loss: 68.2994\n",
      "[array([[2.1514924]], dtype=float32), array([[0.16027173]], dtype=float32), array([[0.7098121]], dtype=float32), array([[1.9705592]], dtype=float32)]\n",
      "Epoch 3/10\n",
      "612310/612310 [==============================] - 221s 361us/step - loss: 68.4589\n",
      "[array([[2.1540356]], dtype=float32), array([[0.16258417]], dtype=float32), array([[0.71022373]], dtype=float32), array([[1.9732347]], dtype=float32)]\n",
      "Epoch 4/10\n",
      "612310/612310 [==============================] - 223s 364us/step - loss: 68.3171\n",
      "[array([[2.1542845]], dtype=float32), array([[0.16122918]], dtype=float32), array([[0.7102008]], dtype=float32), array([[1.965485]], dtype=float32)]\n",
      "Epoch 5/10\n",
      "612310/612310 [==============================] - 222s 363us/step - loss: 68.4343\n",
      "[array([[2.154482]], dtype=float32), array([[0.16281338]], dtype=float32), array([[0.71025336]], dtype=float32), array([[1.9722037]], dtype=float32)]\n",
      "Epoch 6/10\n",
      "612310/612310 [==============================] - 222s 362us/step - loss: 68.4430\n",
      "[array([[2.1532142]], dtype=float32), array([[0.16189957]], dtype=float32), array([[0.709507]], dtype=float32), array([[1.9689981]], dtype=float32)]\n",
      "Epoch 7/10\n",
      "612310/612310 [==============================] - 221s 362us/step - loss: 68.3767\n",
      "[array([[2.153082]], dtype=float32), array([[0.16102327]], dtype=float32), array([[0.7095338]], dtype=float32), array([[1.9659759]], dtype=float32)]\n",
      "Epoch 8/10\n",
      "612310/612310 [==============================] - 227s 371us/step - loss: 68.2901\n",
      "[array([[2.1514478]], dtype=float32), array([[0.16106082]], dtype=float32), array([[0.71061337]], dtype=float32), array([[1.9665585]], dtype=float32)]\n",
      "Epoch 9/10\n",
      "612310/612310 [==============================] - 219s 358us/step - loss: 68.3818\n",
      "[array([[2.1512766]], dtype=float32), array([[0.16034634]], dtype=float32), array([[0.71043414]], dtype=float32), array([[1.9708682]], dtype=float32)]\n",
      "Epoch 10/10\n",
      "612310/612310 [==============================] - 224s 366us/step - loss: 68.3652\n",
      "[array([[2.1525826]], dtype=float32), array([[0.16084777]], dtype=float32), array([[0.7102102]], dtype=float32), array([[1.968784]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "\n",
    "history = model.fit(input_sea[:, [loc['ps'], loc['pres'], loc['rh']]], output_sea, epochs=epochs_opt, batch_size=batchsize_opt, \\\n",
    "                   callbacks = [print_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sundq__layer_1/rsat:0' shape=(1, 1) dtype=float32, numpy=array([[2.1525826]], dtype=float32)>,\n",
       " <tf.Variable 'sundq__layer_1/r0_top:0' shape=(1, 1) dtype=float32, numpy=array([[0.16084777]], dtype=float32)>,\n",
       " <tf.Variable 'sundq__layer_1/r0_surf:0' shape=(1, 1) dtype=float32, numpy=array([[0.7102102]], dtype=float32)>,\n",
       " <tf.Variable 'sundq__layer_1/n:0' shape=(1, 1) dtype=float32, numpy=array([[1.968784]], dtype=float32)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance with the best hyperparameter setting (To run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally: $r_{sat} = 1, r_{0, top} = 0.8, r_{0, surf} = 0.968, n = 2$ <br> \n",
    "Manually tuned over land:\n",
    "$r_{sat} = 1.12, r_{0, top} = 0.3, r_{0, surf} = 0.92, n = 0.8$ <br> \n",
    "Manually tuned over sea:\n",
    "$r_{sat} = 1.07, r_{0, top} = 0.42, r_{0, surf} = 0.9, n = 1.1$ <br> \n",
    "Automatically tuned over land:\n",
    "$r_{sat} = 2.52, r_{0, top} = 0, r_{0, surf} = 0.59, n = 0.91$ <br> \n",
    "Automatically tuned over sea:\n",
    "$r_{sat} = 2.15, r_{0, top} = 0.16, r_{0, surf} = 0.71, n = 1.97$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiate between original, manually and automatically tuned!\n",
    "mse_train, r2_train = evaluate_sundqvist(flattened_input_train, flattened_output_train, loc, tuned='automatically')\n",
    "mse_train_land, r2_train_land = evaluate_sundqvist(input_land, output_land, loc, tuned='automatically')\n",
    "mse_train_sea, r2_train_sea = evaluate_sundqvist(input_sea, output_sea, loc, tuned='automatically')\n",
    "mse_valid, r2_valid = evaluate_sundqvist(flattened_input_valid, flattened_output_valid, loc, tuned='automatically')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to JSON\n",
    "\n",
    "results = {}\n",
    "results['Training MSE'] = mse_train\n",
    "results['Training R2'] = r2_train\n",
    "results['Land MSE'] = mse_train_land\n",
    "results['Land R2'] = r2_train_land\n",
    "results['Sea MSE'] = mse_train_sea\n",
    "results['Sea R2'] = r2_train_sea\n",
    "results['Validation MSE'] = mse_valid\n",
    "results['Validation R2'] = r2_valid\n",
    "\n",
    "with open('/home/b/b309170/workspace_icon-ml/symbolic_regression/baselines/sundqvist_results/results.json', 'w') as file:\n",
    "    json.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cloud Cover distributions')"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlSElEQVR4nO3deXwUVbr/8c9DBBlRUHEFBOKGCIGoYfEqCioOO24I6KjI/ERRxHHcUK9eHB1XRsEZ1AF0wBkUGEYdo6ioiOAOwSA7osZLLoiIgiwjBHl+f1TRNiFJd0hCJ5Xv+/XiZffpqlPnVMenTz91+pS5OyIiEi01Ut0AEREpfwruIiIRpOAuIhJBCu4iIhGk4C4iEkEK7iIiEaTgLrsxs+Fm9o8KqtvN7NiKqHtvij9HZtbYzDaZWVo51f2Umd0VPu5oZvnlUW9YXwczW1Ze9UnlpeBeTZnZJWY2NwxKq83sNTM7vRK069dmNsvMNprZWjN718x6pbpdJXH3/3X3/d3955K2M7MBZvZeEvVd4+73lkfbCn+Yuvtsd29WHnVL5abgXg2Z2e+BkcD9wOFAY+AJoHcKm4WZXQT8E3gWaETQtruBnnu5HeUyAq9qx5ZoUXCvZsysHvAH4Dp3f8HdN7t7gbtnu/stxezTy8wWmdl6M5tpZs3jXttlZGhm483svrjnt4TfDFaZ2cAS2mXAo8C97j7O3Te4+w53f9fdrwq3qWFm/21mX5vZt2b2bNgfzOx1MxtSqM75ZnZB+PgEM3vTzL43s2VmdnGhNj9pZtPMbDPQqYj2pYffIjaa2ZvAIXGvNQ3Pwz7h8wFm9mW47Vdmdml4zp4CTg2/La0v7tiFz2G43R1m9p2Z5ZnZpXHlM83s/8U9j307MLNZYfH88Jh9C6d5zKx5WMf68D3uFffaeDMbbWavhn352MyO2fl+mdlj4fuwwcw+M7OWxb2/svcpuFc/pwK1gReT2djMjgeeB34HHApMA7LNrFYS+3YBbgY6A8cB55SweTPgKGBqCdsMCP91Ao4G9gf+Er72HNA/7tgnAk2AV82sDvBmuM1h4XZPmFmLuLovAf4IHAAUlTp5DsghCOr3AlcU1cDwWI8DXd39AOC/gFx3XwJcA3wYpnAOLMWxjwiP2zA87hgzS5hacfczwoetw2NOLtTWmkA2MJ3gvFwPTCxUd3/gHuAgYEXYToBzgTOA44EDgb7AukRtkr1Hwb36qQ985+7bk9y+L/Cqu7/p7gXACOBXBEErkYuBv7n7QnffDAxP0C6A1SVscynwqLt/6e6bgNuBfuGI+UUg08yaxG37grtvBXoAee7+N3ff7u7zgH8BF8XV/W93fz/8tvBT/EHNrDHQBrjL3be6+yyCoFicHUBLM/uVu69290UlbFvisePsPPa7wKsE57as2hN8QD7o7tvcfQbwCnEfkgTn8JPw72UikBmWFxB8GJ0AmLsvcfeS3jvZyxTcq591wCE7UwhJaAB8vfOJu+8AVhKMIpPZd2Xc86+L25BfRn1HJtuW8PE+wOHuvpEg6PULX+tHEIwgGMG3C1MP68OUyKUEI+Kd4ttZ1HF/CD+gSuxLuE1fglH66jClcUIJdSc6NsUcu0GCfZLRAFgZvqfxdce/t9/EPd5C8GFA+EHwF2A0sMbMxphZ3XJok5QTBffq50PgJ+C8JLdfRRAcgVhu/Cjg/8KiLcB+cdvHB8zV4bY7NS7hOMsIgtyFybYlrG87sCZ8/jzQ38xOJfh28U5YvhJ4190PjPu3v7sPjqurpOVRVwMHhSmXhH1x9zfcvTPBB9VSYGyCYyRamrWoY68KH2+m+POfyCrgKDOLjwON+eW9LZG7P+7upwAtCNIzRV6zkdRQcK9m3H0DwQyU0WZ2npntZ2Y1zayrmT1cxC5TgO5mdnaYo70J2Ap8EL6eC1xiZmlhjv3MQvsOMLMTzWw/4H9KaJcDvwfuMrMrzaxueAH1dDMbE272PHBjeHFzf4LZPpPjUkzTCIL/H8LynSPSV4DjzeyysK81zayNxV0YTnDOvgbmAveYWS0LpowWOYPHzA634AJ0nfA8bQJ2TpFcAzRK5npFEXYeuwNBmumfYXkucEH4Ph4L/LbQfmsIrk8U5WOCD4dbw3PSMezXpESNCc9fu/BvYjPBgKHEqaCydym4V0Pu/ihBIP1vYC3ByHYI8FIR2y4DfgP8GfiO4H/+nu6+LdzkhrBsPUGq46W4fV8jmHI5g+Bi3IwE7ZpKkNIYSDCqXAPcB/w73OQZ4O/ALOArgoByfdz+W4EXCC7cPhdXvpHgAmC/sN5vgIeAfUtqTyGXAO2A7wk+pJ4tZrsaBB+Aq8JtzwSuDV+bASwCvjGz70px7G+AH8I6JwLXuPvS8LXHgG0E52oCv6SidhoOTAjTUbvk6cP3sBfQleC9fQK4PK7uktQl+EbyA0EqZx3B9RipJEw36xARiR6N3EVEIkjBXUQkghTcRUQiKNm5zkkLp1XdS3DBZa67TyjvY4iISMmSCu5m9gzB9Ktv3b1lXHkXYBSQBoxz9wcJFp9qSDBTIKmlSg855BBv2rRp6VouIlLN5eTkfOfuhxb1WrIj9/EEv0aLTf+yYPW60QTrhuQDc8zsZYI1Qj5097+a2VTg7USVN23alLlz5ybZFBERATCzYn/1nVTOPVxL4/tCxW2BFeE6H9sIfvjQmyDQ/xBuU+yPGsxskAXric9du3ZtMs0QEZEkleWCakN2XRMjPyx7Afi1mf2Z4McmRXL3Me6e5e5Zhx5a5LcKERHZQ2W5oGpFlLm7b2H3n0AXXYFZT6DnscdW+buuiYhUKmUJ7vnsuihUI35ZzCgp7p4NZGdlZV1VhnaI7LGCggLy8/P56afiVtoVSb3atWvTqFEjatasmfQ+ZQnuc4DjzCydYBW5fgTrb4hUGfn5+RxwwAE0bdqUYMFLkcrF3Vm3bh35+fmkp6cnvV9SOXcze55gqdhmZpZvZr8NV+IbArwBLAGmJHFTgsL19jSzMRs2bCjNbiLl5qeffqJ+/foK7FJpmRn169cv9bfLpEbu7t6/mPJpBMus7hGlZaQyUGCXym5P/kZTuvyARu4iIhWj3JcfKI1yGbkPr5fgdX1wSPKaDnu1XOvLe7B7ia+vW7eOs88+G4BvvvmGtLQ0dk4N/uSTT6hVq/j7eqxfv57nnnuOa68NloufOXMmI0aM4JVXXilVG1966SXuvvtutm3bxj777MPw4cO56KLg9rIdO3ZkxIgRZGVlBf3Jy6NHjx4sXLiQmTNn0rt3b9LT09mxYweHHXYYzz33HIcddhjjx49n7ty5/OUvwf3Ln332WR5++GHcHXdn4MCB3HzzzQCMGDGCcePGsc8++5CWlsZNN93E5ZdfXqo+lIfCbS6L4cOHs//++8f6mApaOEwkherXr09ubi65ublcc8013HjjjbHntWrVYvv24u9jvn79ep544okyHX/+/PncfPPN/Pvf/2bp0qVkZ2dz2223kZOTk9T+HTp0IDc3l88++4w2bdowevTo3bZ57bXXGDlyJNOnT2fRokXMmzePevWCQdlTTz3Fm2++ySeffMLChQuZNWsWe+seEyWd2yhQWkakkhkwYAC///3v6dSpE7fddhvDhw9nxIhfbnLUsmVL8vLyGDZsGF988QWZmZnccktw+9JNmzZx0UUXccIJJ3DppZcmDJQjRozgjjvuiM3CSE9P54477uBPf/pTqdrs7mzcuJGDDjpot9ceeOABRowYQYMGwT29a9euzVVXBV/W77//fp544gnq1g3urV2vXj2uuOKK3erIzc2lffv2tGrVivPPP58ffviBJUuW0LZt29g2eXl5tGrVCoCcnBzOPPNMTjnlFH7961+zevVqIPgmcscdd3DmmWcyatSoYvuTnZ1Nu3btOOmkkzjnnHNYsya4Te/w4cMZOHAgHTt25Oijj+bxxx+P7fPHP/6RZs2acc4557Bs2bJSnb+KkNLg7u7Z7j5o56e4iASWL1/OW2+9VWKQffDBBznmmGPIzc3lkUceAeDTTz9l5MiRLF68mC+//JL3338fgLvvvpuXX355tzoWLVrEKaecsktZVlYWixcvTqqds2fPJjMzk8aNG/PWW28xcODA3bZZuHDhbscA2LhxIxs3buSYY45JeJzLL7+chx56iM8++4yMjAzuuecemjdvzrZt2/jyyy8BmDx5MhdffDEFBQVcf/31TJ06lZycHAYOHMidd94Zq2v9+vW8++673HTTTcUe7/TTT+ejjz7i008/pV+/fjz88C+3F166dClvvPEGn3zyCffccw8FBQXk5OQwadIkPv30U1544QXmzJmTsE8VLaU5dxEpWp8+fUhLSyv1fm3btqVRo0YAZGZmkpeXx+mnn84f/vCHIrd3991mYsSP9ouapRFf1qFDh1iO/6GHHuLWW2/lqaeeSqqtRR27KBs2bGD9+vWceWZw7/UrrriCPn36AHDxxRczZcoUhg0bxuTJk5k8eTLLli1j4cKFdO7cGYCff/6ZI488MlZf3759Ex4zPz+fvn37snr1arZt27bL/PLu3buz7777su+++3LYYYexZs0aZs+ezfnnn89+++0HQK9evZI6BxVJOXeRSqhOnTqxx/vssw87duyIPS9pvvO++/5yz++0tLSEeeUWLVrstiLrvHnzYhdQ69evzw8//BB77fvvv+eQQw4psq5evXoxa9buy0m1aNGiyBx+3bp1qVOnTmzkvSf69u3LlClTWL58OWbGcccdh7vTokWL2LWLBQsWMH369Ng+8ee2ONdffz1DhgxhwYIF/PWvf93lnBd3jivblFrl3EUquaZNmzJv3jwgCLxfffUVAAcccAAbN24sU90333wzDzzwAHl5eUCQtx45cmQsh9+xY0f+8Y9/xEbzEyZMoFOnTkXW9d577xWZYrn99tu59dZb+eabbwDYunVrLFd9++23c9111/Hjjz8C8OOPPzJmzJhd9q9Xrx4HHXQQs2fPBuDvf/97bBR/zDHHkJaWxr333hsbkTdr1oy1a9fy4YcfAsESE4sWler3lWzYsIGGDRvG+pzIGWecwYsvvsh//vMfNm7cSHZ2dqmOVxGq/lRIkXKUaOpiKlx44YU8++yzZGZm0qZNG44//nggGFWfdtpptGzZkq5du9K9e/Ftv/vuu8nKytotXZCZmclDDz1Ez5492bp1K3l5ebzzzjs0a9YMgEGDBrF06VJat26NmZGVlcUDDzwQ239nzt3dqVevHuPGjdvt2N26dWPNmjWcc845sVTMztz84MGD2bRpE23atKFmzZrUrFmzyFz4hAkTuOaaa9iyZQtHH300f/vb32Kv9e3bl1tuuSX2oVerVi2mTp3K0KFD2bBhA9u3b+d3v/sdLVq0SPaUM3z4cPr06UPDhg1p3759rO7inHzyyfTt25fMzEyaNGlChw4dkj5WRbG9Ne2oJFlZWb7HN+vQPHcpgyVLltC8efNUN6PSGDZsGB9//DFvvPFGiXPsZe8r6m/VzHLcPauo7XVBVURiHnzwwVQ3QcqJcu4iIhGkee4iIhGkqZAiIhGk4C4iEkEK7iIiEZTS2TK6QbZUOomm1pa6vsSTBfLz87nuuutYvHgxO3bsoEePHjzyyCNFTkVctWoVQ4cOZerUqSXW2a1bN5577jkOPPDA0je5mOVqly1bxtVXX8369evZunUrHTp02O0HR3tq//33Z9OmTXu0b6K+jhw5kkGDBsWWBoj3yiuvcNddd7Fjxw4KCgq44YYbuPrqq4usJ36546pAF1RFUsjdueCCCzjvvPP4/PPPWb58OZs2bdploaudtm/fToMGDRIGdoBp06btUWAvydChQ2NLEi9ZsoTrr7++XOvfU4n6OnLkSLZs2bJbeUFBAYMGDSI7O5v58+fz6aef0rFjx4pr6F6mtIxICs2YMYPatWtz5ZVXAsFaJY899hjPPPMMW7ZsYfz48fTp04eePXty7rnnkpeXR8uWLQHYsmULF198Ma1ataJv3760a9cutk5M06ZN+e6778jLy6N58+ZcddVVtGjRgnPPPZf//Oc/AIwdO5Y2bdrQunVrLrzwwiIDYLzVq1fHFiUDyMjIAIKbXAwZMiRW3qNHD2bOnAkEI/I777yT1q1b0759+9jSuV999RWnnnoqbdq04a677ort6+4MGTKEE088ke7du9OtWzemTp3Ka6+9xsUXXxzbbubMmfTs2XOXvm7evJnu3bvTunVrWrZsyeTJk3n88cdZtWoVnTp12m3ZhI0bN7J9+3bq168PBGvG7Pxl7po1azj//PNp3bo1rVu35oMPPgCCRciKOpdffPEFXbp04ZRTTqFDhw4sXboUCJZvHjx4MJ06deLoo4/m3XffZeDAgTRv3pwBAwbE2jJ9+nROPfVUTj75ZPr06bPH32LiKbiLpFBRS+7WrVuXxo0bs2LFCgA+/PBDJkyYwIwZM3bZ7oknnuCggw7is88+46677ir2Bhuff/451113HYsWLeLAAw/kX//6FwAXXHABc+bMYf78+TRv3pynn366xLbeeOONnHXWWXTt2pXHHnuM9evXJ+zf5s2bad++PfPnz+eMM85g7NixANxwww0MHjyYOXPmcMQRR8S2f/HFF1m2bBkLFixg7NixsaDauXNnPvroIzZv3gwEy/sWXt3x9ddfp0GDBsyfP5+FCxfSpUsXhg4dSoMGDXjnnXd45513dtn+4IMPplevXjRp0oT+/fszceLE2AJtQ4cO5cwzz2T+/PnMmzcvtnRBcedy0KBB/PnPfyYnJ4cRI0bE7o4F8MMPPzBjxgwee+wxevbsyY033siiRYtYsGABubm5fPfdd9x333289dZbsUXbHn300YTnNhEFd5EUKm7Z2/jyzp07c/DBB++2zXvvvUe/fv2A4AYeO29UUVh6ejqZmZkAnHLKKbFFwhYuXEiHDh3IyMhg4sSJCRfXuvLKK1myZAl9+vRh5syZtG/fnq1bt5a4T61atejRo8dux37//ffp378/AJdddlls+1mzZtG/f3/S0tJo0KABZ511FhCsjNmlSxeys7PZvn07r776Kr17997lWBkZGbz11lvcdtttzJ49m2TSvePGjePtt9+mbdu2jBgxIrbmzYwZMxg8eDAQfJvaWVdR53LTpk188MEH9OnTh8zMTK6++urYzUEAevbsiZmRkZHB4YcfTkZGBjVq1KBFixbk5eXx0UcfsXjxYk477TQyMzOZMGECX3/9dcK2J6LlB0RSqEWLFrHR304//vgjK1eu5JhjjiEnJ6fYJWqTXReq8BK1O1MJAwYM4KWXXqJ169aMHz8+lkopSYMGDRg4cCADBw6kZcuWLFy4sMQliWvWrBn7kCq8BHFxS+QWV963b19Gjx7NwQcfTJs2bTjggAN2ef34448nJyeHadOmcfvtt3Puuedy9913J+xTRkYGGRkZXHbZZaSnpzN+/Phity3qXO7YsYMDDzyQ3NzcEvepUaPGLvvXqFGD7du3k5aWRufOnXn++ecTtrU0NHIXSaGzzz6bLVu28OyzzwJBTvemm25iwIABRc7uiHf66aczZcoUABYvXsyCBQtKdeyNGzdy5JFHUlBQwMSJExNu//rrr1NQUAAEN/Net24dDRs2pGnTpuTm5rJjxw5WrlzJJ598krCu0047jUmTJgHscuwzzjiDSZMm8fPPP7N69epdUikdO3Zk3rx5jB07tsgbbqxatYr99tuP3/zmN9x8882xZZKLWxp506ZNu3yg5ebm0qRJEyB4X5588kkgeE92LklclLp165Kens4///lPIPjQnT9/fsJzsFP79u15//33Y2m4LVu2sHz58qT3L45G7iLx9vIqombGiy++yLXXXsu9997Ljh076NatG/fff3/Cfa+99lquuOIKWrVqxUknnUSrVq2SSkXsdO+999KuXTuaNGlCRkZGwrXhp0+fzg033EDt2rUBeOSRRzjiiCM4/PDDSU9PJyMjg5YtW3LyyScnPPaoUaO45JJLGDVqFBdeeGGs/Pzzz2fGjBlkZGRw/PHHx9Zth2Ck3KNHD8aPH1/kGusLFizglltuoUaNGtSsWTMWnAcNGkTXrl058sgjd/mwcHcefvhhrr76an71q19Rp06d2Kh91KhRDBo0iKeffpq0tDSefPLJXe7mVNjEiRMZPHgw9913HwUFBfTr14/WrVsnPA8Ahx56KOPHj6d///6xNNd9990XW9p5T6V0yd+4ee5Xff7553tWiZb8lTKoykv+/vzzzxQUFFC7dm2++OILzj77bJYvXx6ppXoHDBhAjx49uOiii1LdlJSrUkv+6mYdIntuy5YtdOrUiYKCAtydJ598MlKBXcpGaRmRKuqAAw7Y7f6nUVPSxU0pmS6oSrVXGe5GJlKSPfkbVXCXaq127dqsW7dOAV4qLXdn3bp1sQvZyVJaRqq1Ro0akZ+fz9q1a1PdFJFi1a5de5elH5Kh4C7VWs2aNUlPT091M0TKndIyIiIRpOAuIhJBCu4iIhFU7sHdzDqa2Wwze8rMOpZ3/SIiklhSwd3MnjGzb81sYaHyLma2zMxWmNmwsNiBTUBtIL98mysiIslIduQ+HugSX2BmacBooCtwItDfzE4EZrt7V+A24J7ya6qIiCQrqeDu7rOA7wsVtwVWuPuX7r4NmAT0dvedCzv/AOxLMcxskJnNNbO5mmMsIlK+ypJzbwisjHueDzQ0swvM7K/A34G/FLezu49x9yx3zzr00EPL0AwRESmsLD9iKup2Ke7uLwAvJFXBL0v+lqEZIiJSWFlG7vnAUXHPGwGrSlOBu2e7+6DS3GBAREQSK0twnwMcZ2bpZlYL6Ae8XJoKzKynmY3ZsEE31BARKU/JToV8HvgQaGZm+Wb2W3ffDgwB3gCWAFPcveTbpxeikbuISMVIKufu7v2LKZ8GTNvTgyvnLiJSMVK6/IBG7iIiFUNry4iIRFBKg7suqIqIVAylZUREIkhpGRGRCFJwFxGJIOXcRUQiSDl3EZEIUlpGRCSCFNxFRCJIOXcRkQhSzl1EJIKUlhERiSAFdxGRCFJwFxGJIF1QFRGJIF1QFRGJIKVlREQiSMFdRCSCFNxFRCIoqRtkV2VNh71a7Gt5D3bfiy0REdl7NHIXEYkgBXcRkQjSPHcRkQjSPHcRkQhSWkZEJIIU3EVEIijyUyFLUtI0SdBUSRGpujRyFxGJIAV3EZEIUnAXEYmgap1zT0Q5eRGpqjRyFxGJoAoJ7mZWx8xyzKxHRdQvIiIlSyq4m9kzZvatmS0sVN7FzJaZ2QozGxb30m3AlPJsqIiIJC/ZnPt44C/AszsLzCwNGA10BvKBOWb2MtAAWAzULteWiohUQam6dpdUcHf3WWbWtFBxW2CFu38JYGaTgN7A/kAd4ETgP2Y2zd13FK7TzAYBgwAaN268xx1IJa0VLyKVVVlmyzQEVsY9zwfaufsQADMbAHxXVGAHcPcxwBiArKwsL0M7RESkkLIEdyuiLBak3X18wgrMegI9jz322DI0o3LSNEoRSaWyzJbJB46Ke94IWFWaCrTkr4hIxShLcJ8DHGdm6WZWC+gHvFyaCnSzDhGRipFUWsbMngc6AoeYWT7wP+7+tJkNAd4A0oBn3H1RaQ7u7tlAdlZW1lWla3bVp7SNiFSkZGfL9C+mfBowrVxbJCIiZZbStWWifEG1rDTNUkTKQvdQFRGJIC0cJiISQUrLVEG6GCsiiSgtIyISQbpZRwTpYqyIKC1TzSilI1I9pDS4V+cfMVVWCv4i0aDZMiIiEaScu5SK8vkiVYNy7lJulNIRqTyUc5e9RqN+kb1HOXcRkQhSzl0qBaV0RMpX5IN7Xu1Lin2t6U/P7cWWSFko+IuUTuSDu1QPiYJ/SfTBIGVRlr+9ilStZ8uUNKoHjeyrC30wSBRptoxIGShdVD1U1tF5SZSWKUGikX1JNOoXqLigoA8NSUTBXaQK0jeG0quKo++yUHCvIMrnSypV1kCW6EOnsra7LBJnADZUyHEV3EVkr4li8K6sFNxTRCN7EalI1XoqZGWmH1+JSFnoHqoiIhGktEwVpJSOiCSi4B5BSumIiJb8FRGJII3cqxmldESqBwV32YWCv0g0KLhLqSifL1I1KOcuIhJBGrlLuVFKR6TyKPeRu5k1N7OnzGyqmQ0u7/pFRCSxpEbuZvYM0AP41t1bxpV3AUYBacA4d3/Q3ZcA15hZDWBsBbRZqqiyrI+fiL4ViOwq2ZH7eKBLfIGZpQGjga7AiUB/MzsxfK0X8B7wdrm1VEREkpZUcHf3WcD3hYrbAivc/Ut33wZMAnqH27/s7v8FXFpcnWY2yMzmmtnctWvX7lnrRUSkSGW5oNoQWBn3PB9oZ2YdgQuAfYFpxe3s7mOAMQBZWVlehnaIiEghZQnuVkSZu/tMYGZSFWjJXyknmn8vsquyzJbJB46Ke94IWFWaCrTkr4hIxSjLyH0OcJyZpQP/B/QDKm46hMge0vx7qY6SGrmb2fPAh0AzM8s3s9+6+3ZgCPAGsASY4u6LSnNwM+tpZmM2bKiYG8SKiFRXSY3c3b1/MeXTKOGiaRL1ZgPZWVlZV+1pHSJlpXy9RFFK15bRyF1EpGKkdG0ZjdylslO+XqoqLRwmUgYK/lJZKS0jIhJBKQ3umucuIlIxlJYRqUCaiSOpktLgruUHpDpTvl4qktIyIiIRpHuoiohEkHLuIpWU8vVSFhq5i4hEkOa5i4hEkJYfEKmCNNNGElFaRkQkghTcRUQiSMFdRCSC9AtVkQhSTl70C1URkQjSj5hEqiH9QCr6FNxFZBdK6USDLqiKiESQgruISAQpuIuIRJCCu4hIBGmeu4iUii64Vg2a5y4iEkFKy4iIRJCCu4hIBCm4i4hEkH6hKiLlSksbVA4K7iKy12imzd6jtIyISAQpuIuIRFCFpGXM7DygO3AYMNrdp1fEcUQkWpSvLz9Jj9zN7Bkz+9bMFhYq72Jmy8xshZkNA3D3l9z9KmAA0LdcWywiIgmVJi0zHugSX2BmacBooCtwItDfzE6M2+S/w9dFRGQvSjq4u/ss4PtCxW2BFe7+pbtvAyYBvS3wEPCau88rv+aKiEgyyppzbwisjHueD7QDrgfOAeqZ2bHu/lThHc1sEDAIoHHjxmVshohEnaZRlk5Zg7sVUebu/jjweEk7uvsYYAxAVlaWl7EdIiISp6zBPR84Ku55I2BVsjtryV8RKS8a2e+qrPPc5wDHmVm6mdUC+gEvJ7uzlvwVEakYpZkK+TzwIdDMzPLN7Lfuvh0YArwBLAGmuPuiUtTZ08zGbNiwobTtFhGREiSdlnH3/sWUTwOm7cnB3T0byM7KyrpqT/YXEZGipXT5AY3cRUQqhm6zJyISQVo4TEQkgpSWERGJIKVlREQiSGkZEZEI0m32RKRaqG5rxSvnLiISQcq5i4hEkHLuIiIRpOAuIhJByrmLiESQcu4iIhGktIyISARpnruIVHtRvIuTRu4iIhGkC6oiIhGkC6oiIhGktIyISATpgqqISAJVcdExjdxFRCJIwV1EJIIU3EVEIkjBXUQkgjTPXUQkgjTPXUQkgjQVUkSkDBKtS5MqyrmLiESQgruISAQpuIuIRJCCu4hIBCm4i4hEkIK7iEgEKbiLiESQgruISAQpuIuIRJC5e6rbgJmtBb7ew90PAb4rx+ZUBepz9aA+Vw9l6XMTdz+0qBcqRXAvCzOb6+5ZqW7H3qQ+Vw/qc/VQUX1WWkZEJIIU3EVEIigKwX1MqhuQAupz9aA+Vw8V0ucqn3MXEZHdRWHkLiIihSi4i4hEUJUO7mbWxcyWmdkKMxuW6vZUBDM7yszeMbMlZrbIzG4Iyw82szfN7PPwvweluq3lyczSzOxTM3slfB71/h5oZlPNbGn4Xp9aDfp8Y/g3vdDMnjez2lHrs5k9Y2bfmtnCuLJi+2hmt4fxbJmZ/bosx66ywd3M0oDRQFfgRKC/mZ2Y2lZViO3ATe7eHGgPXBf2cxjwtrsfB7wdPo+SG4Alcc+j3t9RwOvufgLQmqDvke2zmTUEhgJZ7t4SSAP6Eb0+jwe6FCorso/h/9f9gBbhPk+EcW6PVNngDrQFVrj7l+6+DZgE9E5xm8qdu69293nh440E/9M3JOjrhHCzCcB5KWlgBTCzRkB3YFxccZT7Wxc4A3gawN23uft6Itzn0D7Ar8xsH2A/YBUR67O7zwK+L1RcXB97A5Pcfau7fwWsIIhze6QqB/eGwMq45/lhWWSZWVPgJOBj4HB3Xw3BBwBwWAqbVt5GArcCO+LKotzfo4G1wN/CVNQ4M6tDhPvs7v8HjAD+F1gNbHD36US4z3GK62O5xrSqHNytiLLIzus0s/2BfwG/c/cfU92eimJmPYBv3T0n1W3Zi/YBTgaedPeTgM1U/XREicI8c28gHWgA1DGz36S2VSlXrjGtKgf3fOCouOeNCL7WRY6Z1SQI7BPd/YWweI2ZHRm+fiTwbaraV85OA3qZWR5Bqu0sM/sH0e0vBH/L+e7+cfh8KkGwj3KfzwG+cve17l4AvAD8F9Hu807F9bFcY1pVDu5zgOPMLN3MahFciHg5xW0qd2ZmBLnYJe7+aNxLLwNXhI+vAP69t9tWEdz9dndv5O5NCd7TGe7+GyLaXwB3/wZYaWbNwqKzgcVEuM8E6Zj2ZrZf+Dd+NsH1pCj3eafi+vgy0M/M9jWzdOA44JM9Poq7V9l/QDdgOfAFcGeq21NBfTyd4KvZZ0Bu+K8bUJ/gSvvn4X8PTnVbK6DvHYFXwseR7i+QCcwN3+eXgIOqQZ/vAZYCC4G/A/tGrc/A8wTXFAoIRua/LamPwJ1hPFsGdC3LsbX8gIhIBFXltIyIiBRDwV1EJIIU3EVEIkjBXUQkghTcRUQiSMFdRCSCFNxFRCLo/wOYOpAD92/CtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(output_land, bins=40, log=True)\n",
    "plt.hist(predictions, bins=40, log = True)\n",
    "plt.legend(['Truth: QUBICC over land', 'Original Sundqvist Scheme'])\n",
    "plt.title('Cloud Cover distributions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
