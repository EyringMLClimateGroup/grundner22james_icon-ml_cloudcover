{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN parameterization of cloud cover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import sherpa\n",
    "import pandas as pd\n",
    "import os\n",
    "import importlib\n",
    "import for_preprocessing\n",
    "\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "importlib.reload(for_preprocessing)\n",
    "# importlib.reload(my_classes)\n",
    "from for_preprocessing import load_day\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "sys.path.insert(0, '/pf/b/b309170/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "from my_classes import write_infofile\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "path = \"/pf/b/b309170/my_work/NARVAL/data_var_vertinterp/\"\n",
    "output_path = \"/pf/b/b309170/my_work/icon-ml_data/cloud_cover_parameterization/region_based/based_on_var_interpolated_data\"\n",
    "model_path = \"/pf/b/b309170/workspace_icon-ml/cloud_cover_parameterization/region_based/saved_models\"\n",
    "\n",
    "NUM = 1\n",
    "VERT_LAYERS = 31\n",
    "no_NNs = 27\n",
    "\n",
    "np.random.seed(NUM)\n",
    "%config Completer.use_jedi = False # Faster autocompletion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading the data\n",
    "\n",
    "We train one NN for every vertical layer i\n",
    "### Input:\n",
    "- fr_lake: Fraction of open water in a grid box, for seas and lakes\n",
    "- zf[i-2], zf[i-1], zf[i], zf[i+1], zf[i+2]: Geometric height at full levels (3D)\n",
    "- qv[i-2], qv[i-1], qv[i], qv[i+1], qv[i+2]: Specific water vapor content (3D)\n",
    "- qc[i-2], qc[i-1], qc[i], qc[i+1], qc[i+2]: Specific cloud water content (3D)\n",
    "- qi[i-2], qi[i-1], qi[i], qi[i+1], qi[i+2]: Specific cloud ice content (3D)\n",
    "- temp[i-2], temp[i-1], temp[i], temp[i+1], temp[i+2]: Temperature (3D)\n",
    "- pres[i-2], pres[i-1], pres[i], pres[i+1], pres[i+2]: Pressure (3D)\n",
    "- rho[i-2], rho[i-1], rho[i], rho[i+1], rho[i+2]: Air density (3D)\n",
    "\n",
    "Additionally, we'll use clc[i] from the previous time step. <br>\n",
    "$37$ $( = 5\\cdot 7+1+1$) input nodes\n",
    "\n",
    "### Output:\n",
    "- clc[i]: Cloud Cover\n",
    "\n",
    "$1$ output node\n",
    "\n",
    "=> Train 27 NNs (no need to train uppermost layers) with 37 input and 1 output node each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to take a different approach to load the data as clc from the previous time step is in the input\n",
    "# We load the data day by day, not utilizing consecutive days\n",
    "# (since the simulations were only run for around a day and in general we don't have consecutive days!)\n",
    "\n",
    "# 1) Load a day\n",
    "# 2) Create one dataset for each layer (below 21km)\n",
    "# 3) Put data into corresponding dataset\n",
    "# 4) Do 1)-3) for all days\n",
    "# 5) Split dataset into train/valid/test\n",
    "# 6) Combine test-datasets => save\n",
    "#            training-datasets => save\n",
    "#            validation-datasets => save\n",
    "\n",
    "# Get all days\n",
    "ls = os.listdir(os.path.join(path, 'temp')) #Temperature as an arbitrary variable\n",
    "days = set()\n",
    "for j in range(len(ls)):\n",
    "    day = ls[j].split(sep='_')[5] #Days\n",
    "    days.add(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all days in an array of dataframes (each row is a training sample for the NN)\n",
    "dfs = load_day(days.pop(), no_NNs, path)\n",
    "while len(days) > 0: #while len(days) > 0 to load all days\n",
    "    tmp = load_day(days.pop(), no_NNs, path)\n",
    "    for i in range(no_NNs):\n",
    "        dfs[i] = dfs[i].append(tmp[i], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For every vertical layer up to no_NNs many we have one dataframe, i.e. 27 in total\n",
      "There are 38 input + output variables\n",
      "Removing the first timestep from 67 days, with 1699 timesteps in total and 1131 horizontal entries:\n",
      "(1699-67)*1024 = 1671168\n",
      "The shapes of all dataframes are equal.\n"
     ]
    }
   ],
   "source": [
    "# Is the data loaded correctly?\n",
    "# Yes, we have:\n",
    "# 1)\n",
    "print('For every vertical layer up to no_NNs many we have one dataframe, i.e. %d in total'%len(dfs))\n",
    "assert len(dfs) == no_NNs\n",
    "# 2)\n",
    "print('There are %d input + output variables'%dfs[0].shape[1])\n",
    "assert dfs[0].shape[1] == 38\n",
    "print('Removing the first timestep from 67 days, with 1699 timesteps in total and 1131 horizontal entries:')\n",
    "print('(1699-67)*1024 = %d'%dfs[0].shape[0])\n",
    "assert dfs[0].shape[0] == (1699-67)*1024 \n",
    "# 3)\n",
    "for i in range(len(dfs)):\n",
    "    for j in range(len(dfs)):\n",
    "        assert dfs[i].shape == dfs[j].shape\n",
    "print('The shapes of all dataframes are equal.')\n",
    "# 4) Checking some arbitrary data sample\n",
    "# dfs[16].values[664103] matches\n",
    "# day: 2016072800, vertical layer: 20, horizontal index (after removing nans): 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1671168 entries, 0 to 1671167\n",
      "Data columns (total 38 columns):\n",
      " #   Column    Non-Null Count    Dtype  \n",
      "---  ------    --------------    -----  \n",
      " 0   qv_i-2    1671168 non-null  float64\n",
      " 1   qv_i-1    1671168 non-null  float64\n",
      " 2   qv_i      1671168 non-null  float64\n",
      " 3   qv_i+1    1671168 non-null  float64\n",
      " 4   qv_i+2    1671168 non-null  float64\n",
      " 5   qc_i-2    1671168 non-null  float64\n",
      " 6   qc_i-1    1671168 non-null  float64\n",
      " 7   qc_i      1671168 non-null  float64\n",
      " 8   qc_i+1    1671168 non-null  float64\n",
      " 9   qc_i+2    1671168 non-null  float64\n",
      " 10  qi_i-2    1671168 non-null  float64\n",
      " 11  qi_i-1    1671168 non-null  float64\n",
      " 12  qi_i      1671168 non-null  float64\n",
      " 13  qi_i+1    1671168 non-null  float64\n",
      " 14  qi_i+2    1671168 non-null  float64\n",
      " 15  temp_i-2  1671168 non-null  float64\n",
      " 16  temp_i-1  1671168 non-null  float64\n",
      " 17  temp_i    1671168 non-null  float64\n",
      " 18  temp_i+1  1671168 non-null  float64\n",
      " 19  temp_i+2  1671168 non-null  float64\n",
      " 20  pres_i-2  1671168 non-null  float64\n",
      " 21  pres_i-1  1671168 non-null  float64\n",
      " 22  pres_i    1671168 non-null  float64\n",
      " 23  pres_i+1  1671168 non-null  float64\n",
      " 24  pres_i+2  1671168 non-null  float64\n",
      " 25  rho_i-2   1671168 non-null  float64\n",
      " 26  rho_i-1   1671168 non-null  float64\n",
      " 27  rho_i     1671168 non-null  float64\n",
      " 28  rho_i+1   1671168 non-null  float64\n",
      " 29  rho_i+2   1671168 non-null  float64\n",
      " 30  zg_i-2    1671168 non-null  float64\n",
      " 31  zg_i-1    1671168 non-null  float64\n",
      " 32  zg_i      1671168 non-null  float64\n",
      " 33  zg_i+1    1671168 non-null  float64\n",
      " 34  zg_i+2    1671168 non-null  float64\n",
      " 35  fr_lake   1671168 non-null  float32\n",
      " 36  clc_prev  1671168 non-null  float64\n",
      " 37  clc       1671168 non-null  float64\n",
      "dtypes: float32(1), float64(37)\n",
      "memory usage: 478.1 MB\n"
     ]
    }
   ],
   "source": [
    "dfs[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qv_i-2</th>\n",
       "      <th>qv_i-1</th>\n",
       "      <th>qv_i</th>\n",
       "      <th>qv_i+1</th>\n",
       "      <th>qv_i+2</th>\n",
       "      <th>qc_i-2</th>\n",
       "      <th>qc_i-1</th>\n",
       "      <th>qc_i</th>\n",
       "      <th>qc_i+1</th>\n",
       "      <th>qc_i+2</th>\n",
       "      <th>...</th>\n",
       "      <th>rho_i+1</th>\n",
       "      <th>rho_i+2</th>\n",
       "      <th>zg_i-2</th>\n",
       "      <th>zg_i-1</th>\n",
       "      <th>zg_i</th>\n",
       "      <th>zg_i+1</th>\n",
       "      <th>zg_i+2</th>\n",
       "      <th>fr_lake</th>\n",
       "      <th>clc_prev</th>\n",
       "      <th>clc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "      <td>1.67117e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00737286</td>\n",
       "      <td>0.00888582</td>\n",
       "      <td>0.0105352</td>\n",
       "      <td>0.0120102</td>\n",
       "      <td>0.0132247</td>\n",
       "      <td>1.62484e-05</td>\n",
       "      <td>2.54916e-05</td>\n",
       "      <td>3.59945e-05</td>\n",
       "      <td>3.26906e-05</td>\n",
       "      <td>1.48808e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06726</td>\n",
       "      <td>1.09814</td>\n",
       "      <td>2217.44</td>\n",
       "      <td>1764.81</td>\n",
       "      <td>1365.57</td>\n",
       "      <td>1019.29</td>\n",
       "      <td>725.788</td>\n",
       "      <td>0.00250321</td>\n",
       "      <td>10.8091</td>\n",
       "      <td>10.7657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00278859</td>\n",
       "      <td>0.00296276</td>\n",
       "      <td>0.00297614</td>\n",
       "      <td>0.00287546</td>\n",
       "      <td>0.00289272</td>\n",
       "      <td>3.80472e-05</td>\n",
       "      <td>4.96917e-05</td>\n",
       "      <td>6.64943e-05</td>\n",
       "      <td>6.32496e-05</td>\n",
       "      <td>4.01862e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0207723</td>\n",
       "      <td>0.0228537</td>\n",
       "      <td>93.7835</td>\n",
       "      <td>107.026</td>\n",
       "      <td>119.739</td>\n",
       "      <td>131.405</td>\n",
       "      <td>141.547</td>\n",
       "      <td>0.0110212</td>\n",
       "      <td>12.5613</td>\n",
       "      <td>12.5311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000104811</td>\n",
       "      <td>0.00013219</td>\n",
       "      <td>0.000259667</td>\n",
       "      <td>0.000370459</td>\n",
       "      <td>0.000555851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955472</td>\n",
       "      <td>0.978894</td>\n",
       "      <td>2168.33</td>\n",
       "      <td>1710</td>\n",
       "      <td>1305.51</td>\n",
       "      <td>954.582</td>\n",
       "      <td>657.176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00517002</td>\n",
       "      <td>0.00688104</td>\n",
       "      <td>0.00927526</td>\n",
       "      <td>0.0110916</td>\n",
       "      <td>0.0123455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.47803e-26</td>\n",
       "      <td>1.4492e-07</td>\n",
       "      <td>1.34621e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06185</td>\n",
       "      <td>1.09398</td>\n",
       "      <td>2168.38</td>\n",
       "      <td>1710.04</td>\n",
       "      <td>1305.55</td>\n",
       "      <td>954.611</td>\n",
       "      <td>657.196</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0942267</td>\n",
       "      <td>0.101541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0077521</td>\n",
       "      <td>0.00958351</td>\n",
       "      <td>0.0113457</td>\n",
       "      <td>0.0127074</td>\n",
       "      <td>0.0138855</td>\n",
       "      <td>1.60923e-12</td>\n",
       "      <td>3.77945e-06</td>\n",
       "      <td>1.20674e-05</td>\n",
       "      <td>9.50654e-06</td>\n",
       "      <td>9.84288e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.07252</td>\n",
       "      <td>1.10405</td>\n",
       "      <td>2170.5</td>\n",
       "      <td>1711.94</td>\n",
       "      <td>1307.12</td>\n",
       "      <td>955.819</td>\n",
       "      <td>658.041</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0439</td>\n",
       "      <td>7.00473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00978913</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>0.0127262</td>\n",
       "      <td>0.013973</td>\n",
       "      <td>0.0151277</td>\n",
       "      <td>1.38625e-05</td>\n",
       "      <td>3.10972e-05</td>\n",
       "      <td>4.23167e-05</td>\n",
       "      <td>3.49793e-05</td>\n",
       "      <td>1.05947e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08016</td>\n",
       "      <td>1.11236</td>\n",
       "      <td>2210.53</td>\n",
       "      <td>1752.73</td>\n",
       "      <td>1348.08</td>\n",
       "      <td>997.056</td>\n",
       "      <td>698.658</td>\n",
       "      <td>1.59524e-06</td>\n",
       "      <td>17.0376</td>\n",
       "      <td>16.9344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0135576</td>\n",
       "      <td>0.0150132</td>\n",
       "      <td>0.0165432</td>\n",
       "      <td>0.0178242</td>\n",
       "      <td>0.0185974</td>\n",
       "      <td>0.0010945</td>\n",
       "      <td>0.00116312</td>\n",
       "      <td>0.00118059</td>\n",
       "      <td>0.000990079</td>\n",
       "      <td>0.000873018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11864</td>\n",
       "      <td>1.14857</td>\n",
       "      <td>2805.78</td>\n",
       "      <td>2445.79</td>\n",
       "      <td>2136.51</td>\n",
       "      <td>1873.51</td>\n",
       "      <td>1652.89</td>\n",
       "      <td>0.151835</td>\n",
       "      <td>98.9596</td>\n",
       "      <td>98.9596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           qv_i-2      qv_i-1        qv_i      qv_i+1      qv_i+2      qc_i-2  \\\n",
       "count 1.67117e+06 1.67117e+06 1.67117e+06 1.67117e+06 1.67117e+06 1.67117e+06   \n",
       "mean   0.00737286  0.00888582   0.0105352   0.0120102   0.0132247 1.62484e-05   \n",
       "std    0.00278859  0.00296276  0.00297614  0.00287546  0.00289272 3.80472e-05   \n",
       "min   0.000104811  0.00013219 0.000259667 0.000370459 0.000555851           0   \n",
       "25%    0.00517002  0.00688104  0.00927526   0.0110916   0.0123455           0   \n",
       "50%     0.0077521  0.00958351   0.0113457   0.0127074   0.0138855 1.60923e-12   \n",
       "75%    0.00978913    0.011327   0.0127262    0.013973   0.0151277 1.38625e-05   \n",
       "max     0.0135576   0.0150132   0.0165432   0.0178242   0.0185974   0.0010945   \n",
       "\n",
       "           qc_i-1        qc_i      qc_i+1      qc_i+2  ...     rho_i+1  \\\n",
       "count 1.67117e+06 1.67117e+06 1.67117e+06 1.67117e+06  ... 1.67117e+06   \n",
       "mean  2.54916e-05 3.59945e-05 3.26906e-05 1.48808e-05  ...     1.06726   \n",
       "std   4.96917e-05 6.64943e-05 6.32496e-05 4.01862e-05  ...   0.0207723   \n",
       "min             0           0           0           0  ...    0.955472   \n",
       "25%             0 1.47803e-26  1.4492e-07 1.34621e-09  ...     1.06185   \n",
       "50%   3.77945e-06 1.20674e-05 9.50654e-06 9.84288e-07  ...     1.07252   \n",
       "75%   3.10972e-05 4.23167e-05 3.49793e-05 1.05947e-05  ...     1.08016   \n",
       "max    0.00116312  0.00118059 0.000990079 0.000873018  ...     1.11864   \n",
       "\n",
       "          rho_i+2      zg_i-2      zg_i-1        zg_i      zg_i+1      zg_i+2  \\\n",
       "count 1.67117e+06 1.67117e+06 1.67117e+06 1.67117e+06 1.67117e+06 1.67117e+06   \n",
       "mean      1.09814     2217.44     1764.81     1365.57     1019.29     725.788   \n",
       "std     0.0228537     93.7835     107.026     119.739     131.405     141.547   \n",
       "min      0.978894     2168.33        1710     1305.51     954.582     657.176   \n",
       "25%       1.09398     2168.38     1710.04     1305.55     954.611     657.196   \n",
       "50%       1.10405      2170.5     1711.94     1307.12     955.819     658.041   \n",
       "75%       1.11236     2210.53     1752.73     1348.08     997.056     698.658   \n",
       "max       1.14857     2805.78     2445.79     2136.51     1873.51     1652.89   \n",
       "\n",
       "          fr_lake    clc_prev         clc  \n",
       "count 1.67117e+06 1.67117e+06 1.67117e+06  \n",
       "mean   0.00250321     10.8091     10.7657  \n",
       "std     0.0110212     12.5613     12.5311  \n",
       "min             0           0           0  \n",
       "25%             0   0.0942267    0.101541  \n",
       "50%             0      7.0439     7.00473  \n",
       "75%   1.59524e-06     17.0376     16.9344  \n",
       "max      0.151835     98.9596     98.9596  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%g' % x)\n",
    "dfs[20].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into a learning and a test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336935 training samples,  334233 test samples\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into a learning and a test set\n",
    "\n",
    "#Should we use StratifiedShuffleSplit instead to make sure that the test set is representative of the whole dataset?\n",
    "#E.g. define categories of specific water vapor and make sure those categories are present in the test set as well\n",
    "#-> Geron, p.69\n",
    "\n",
    "def split_train_test(df, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    test_set_size = int(len(df)*test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return df.iloc[train_indices], df.iloc[test_indices]\n",
    "    \n",
    "learning_sets = []\n",
    "test_sets = []\n",
    "for i in range(no_NNs):\n",
    "    a, b = split_train_test(dfs[i], 0.2)\n",
    "    learning_sets.append(a)\n",
    "    test_sets.append(b)\n",
    "print(len(learning_sets[0]), 'training samples, ', len(test_sets[0]), 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training sets[i]/learning sets[i] into a training sets[i] and a validation sets[i] and rescale\n",
    "train_sets = []\n",
    "valid_sets = []\n",
    "input_train_sets = []\n",
    "input_valid_sets = []\n",
    "input_test_sets = []\n",
    "output_valid_sets = []\n",
    "output_train_sets = []\n",
    "output_test_sets = []\n",
    "\n",
    "for i in range(no_NNs):\n",
    "    a, b = split_train_test(learning_sets[i], 0.1)\n",
    "    train_sets.append(a)\n",
    "    valid_sets.append(b)\n",
    "    output_valid_sets.append(valid_sets[i]['clc'])\n",
    "    del valid_sets[i]['clc']\n",
    "    output_train_sets.append(train_sets[i]['clc'])\n",
    "    del train_sets[i]['clc']\n",
    "    # Save and scale the test set as well\n",
    "    output_test_sets.append(test_sets[i]['clc'])\n",
    "    del test_sets[i]['clc']\n",
    "    scaler.fit(train_sets[i])\n",
    "    input_train_sets.append(scaler.transform(train_sets[i]))\n",
    "    input_valid_sets.append(scaler.transform(valid_sets[i]))\n",
    "    input_test_sets.append(scaler.transform(test_sets[i]))\n",
    "    with open(model_path + '/scaler_%d.txt'%NUM, 'a') as file:\n",
    "        file.write('The mean values of the %d-th Standard Scaler: \\n %s'%(i, str(scaler.mean_)))\n",
    "        file.write('\\nThe standard deviation values of the %d-th Standard Scaler: \\n %s \\n'\n",
    "                   %(i,str(np.sqrt(scaler.var_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce the number of saved files by concatenating\n",
    "input_train = np.concatenate(([input_train_sets[i] for i in range(no_NNs)]))\n",
    "input_valid = np.concatenate(([input_valid_sets[i] for i in range(no_NNs)]))\n",
    "input_test = np.concatenate(([input_test_sets[i] for i in range(no_NNs)]))\n",
    "output_train = np.concatenate(([output_train_sets[i] for i in range(no_NNs)]))\n",
    "output_valid = np.concatenate(([output_valid_sets[i] for i in range(no_NNs)]))\n",
    "output_test = np.concatenate(([output_test_sets[i] for i in range(no_NNs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Save the data\n",
    "np.save(output_path + '/cloud_cover_input_train_%d.npy'%NUM, input_train)\n",
    "np.save(output_path + '/cloud_cover_input_valid_%d.npy'%NUM, input_valid)\n",
    "np.save(output_path + '/cloud_cover_output_train_%d.npy'%NUM, output_train)\n",
    "np.save(output_path + '/cloud_cover_output_valid_%d.npy'%NUM, output_valid)\n",
    "np.save(output_path + '/cloud_cover_input_test_%d.npy'%NUM, input_test)\n",
    "np.save(output_path + '/cloud_cover_output_test_%d.npy'%NUM, output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Write the accompanying info-file\n",
    "with open(model_path + '/model_region_based_final_%d.txt'%NUM, 'w') as file:\n",
    "    write_infofile(file, str(learning_sets[0].columns), str(learning_sets[0].columns[:-1]), \n",
    "                   model_path, output_path, NUM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds_kernel",
   "language": "python",
   "name": "clouds_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
