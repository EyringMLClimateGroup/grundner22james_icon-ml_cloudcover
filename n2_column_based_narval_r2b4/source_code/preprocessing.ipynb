{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "<!-- Was used to generate: <br>\n",
    "*preprocessed_data/cloud_cover_all_days_input_train.npy <br>\n",
    "preprocessed_data/cloud_cover_all_days_input_valid.npy <br>\n",
    "preprocessed_data/cloud_cover_all_days_output_train.npy <br>\n",
    "preprocessed_data/cloud_cover_all_days_output_valid.npy* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "# import importlib\n",
    "# importlib.reload(my_classes)\n",
    "\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "base_path = '/pf/b/b309170'\n",
    "path = base_path + '/my_work/NARVAL/data_var_vertinterp/'\n",
    "output_path = base_path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_column_based/based_on_var_interpolated_data'\n",
    "model_path = \"/pf/b/b309170/workspace_icon-ml/cloud_cover_parameterization/grid_column_based/saved_models\"\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "sys.path.insert(0, base_path + '/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "from my_classes import write_infofile\n",
    "from my_classes import load_data\n",
    "\n",
    "NUM = 1\n",
    "VERT_LAYERS = 31\n",
    "\n",
    "np.random.seed(NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading the data\n",
    "### Input:\n",
    "- fr_lake: Fraction of open water in a grid box, for seas and lakes\n",
    "- zg: Geometric height at full levels (3D)\n",
    "- qv: Specific water vapor content (3D)\n",
    "- qc: Specific cloud water content (3D)\n",
    "- qi: Specific cloud ice content (3D)\n",
    "- temp: Temperature (3D)\n",
    "- pres: Pressure (3D)\n",
    "- rho: Air density (3D)\n",
    "\n",
    "$186$ $( = 1+24[zg]+26[q_c]+27\\cdot 5$) input nodes\n",
    "\n",
    "### Output:\n",
    "- clc: Cloud Cover\n",
    "\n",
    "$27$ output nodes\n",
    "\n",
    "The data above 21km is capped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the NARVAL data into the data_dict dictionary\n",
    "order_of_vars = ['qv', 'qc', 'qi', 'temp', 'pres', 'rho', 'zg', 'fr_lake', 'fr_land', 'clc']\n",
    "data_dict = load_data(source='narval', days='all', vert_interp=True, order_of_vars=order_of_vars)\n",
    "    \n",
    "del data_dict['fr_land']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping into nd-arrays of equaling shapes\n",
    "data_dict['zg'] = np.repeat(np.expand_dims(data_dict['zg'], 0), 1635, axis=0)\n",
    "data_dict['fr_lake'] = np.repeat(np.expand_dims(data_dict['fr_lake'], 0), 1635, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One sample should contain a column of information\n",
    "data_dict_reshaped = {}\n",
    "for key in data_dict.keys():\n",
    "    if data_dict[key].shape[1] == VERT_LAYERS:  \n",
    "        for i in range(4, VERT_LAYERS):\n",
    "            new_key = '{}{}{:d}'.format(key,'_',i)\n",
    "            data_dict_reshaped[new_key] = np.reshape(data_dict[key][:,i,:], -1)\n",
    "    else:\n",
    "        data_dict_reshaped[key] = np.reshape(data_dict[key], -1)\n",
    "\n",
    "# Remove constant fields\n",
    "del data_dict_reshaped['zg_4']\n",
    "del data_dict_reshaped['zg_5']\n",
    "del data_dict_reshaped['zg_6']\n",
    "del data_dict_reshaped['qc_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qv_4</th>\n",
       "      <th>qv_5</th>\n",
       "      <th>qv_6</th>\n",
       "      <th>qv_7</th>\n",
       "      <th>qv_8</th>\n",
       "      <th>qv_9</th>\n",
       "      <th>qv_10</th>\n",
       "      <th>qv_11</th>\n",
       "      <th>qv_12</th>\n",
       "      <th>qv_13</th>\n",
       "      <th>...</th>\n",
       "      <th>clc_21</th>\n",
       "      <th>clc_22</th>\n",
       "      <th>clc_23</th>\n",
       "      <th>clc_24</th>\n",
       "      <th>clc_25</th>\n",
       "      <th>clc_26</th>\n",
       "      <th>clc_27</th>\n",
       "      <th>clc_28</th>\n",
       "      <th>clc_29</th>\n",
       "      <th>clc_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       qv_4      qv_5      qv_6      qv_7      qv_8      qv_9     qv_10  \\\n",
       "0  0.000003  0.000003  0.000003  0.000003  0.000005  0.000010  0.000028   \n",
       "1  0.000003  0.000003  0.000003  0.000003  0.000005  0.000010  0.000033   \n",
       "2  0.000003  0.000003  0.000003  0.000003  0.000004  0.000011  0.000037   \n",
       "3  0.000003  0.000003  0.000003  0.000003  0.000005  0.000009  0.000033   \n",
       "4  0.000003  0.000003  0.000003  0.000003  0.000006  0.000011  0.000016   \n",
       "\n",
       "      qv_11     qv_12     qv_13  ...  clc_21  clc_22  clc_23  clc_24  clc_25  \\\n",
       "0  0.000086  0.000101  0.000112  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "1  0.000110  0.000138  0.000232  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "2  0.000093  0.000118  0.000195  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "3  0.000131  0.000177  0.000299  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "4  0.000056  0.000084  0.000090  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   clc_26  clc_27  clc_28  clc_29  clc_30  \n",
       "0     0.0     0.0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 213 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting dict into a DataFrame-object \n",
    "df = pd.DataFrame.from_dict(data_dict_reshaped)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into a learning and a test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1339392 training samples,  334848 test samples\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into a learning and a test set\n",
    "\n",
    "#Should we use StratifiedShuffleSplit instead to make sure that the test set is representative of the whole dataset?\n",
    "#E.g. define categories of specific water vapor and make sure those categories are present in the test set as well\n",
    "#-> Geron, p.69\n",
    "\n",
    "def split_train_test(df, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    test_set_size = int(len(df)*test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return df.iloc[train_indices], df.iloc[test_indices]\n",
    "    \n",
    "learning_set, test_set = split_train_test(df, 0.2)\n",
    "print(len(learning_set), 'training samples, ', len(test_set), 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training set/learning set into a training set and a validation set and rescale\n",
    "\n",
    "train_set, valid_set = split_train_test(learning_set, 0.1)\n",
    "output_valid = pd.DataFrame()\n",
    "for i in range(4, VERT_LAYERS):\n",
    "    output_valid['clc_%d'%i] = valid_set['clc_%d'%i]\n",
    "    del valid_set['clc_%d'%i]\n",
    "output_train = pd.DataFrame()\n",
    "for i in range(4, VERT_LAYERS):\n",
    "    output_train['clc_%d'%i] = train_set['clc_%d'%i]\n",
    "    del train_set['clc_%d'%i]\n",
    "scaler.fit(train_set)\n",
    "input_train = scaler.transform(train_set)\n",
    "input_valid = scaler.transform(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and scale the test set as well\n",
    "output_test = pd.DataFrame()\n",
    "for i in range(4, VERT_LAYERS):\n",
    "    output_test['clc_%d'%i] = test_set['clc_%d'%i]\n",
    "    del test_set['clc_%d'%i]\n",
    "input_test = scaler.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "np.save(output_path + '/cloud_cover_input_train_%d.npy'%NUM, input_train)\n",
    "np.save(output_path + '/cloud_cover_input_valid_%d.npy'%NUM, input_valid)\n",
    "np.save(output_path + '/cloud_cover_output_train_%d.npy'%NUM, output_train)\n",
    "np.save(output_path + '/cloud_cover_output_valid_%d.npy'%NUM, output_valid)\n",
    "np.save(output_path + '/cloud_cover_input_test_%d.npy'%NUM, input_test)\n",
    "np.save(output_path + '/cloud_cover_output_test_%d.npy'%NUM, output_test)\n",
    "with open(model_path+'/scaler_%d.txt'%NUM, 'w') as file:\n",
    "    file.write('Standard Scaler mean values:\\n')\n",
    "    file.write(str(scaler.mean_))\n",
    "    file.write('\\nStandard Scaler standard deviation:\\n')\n",
    "    file.write(str(np.sqrt(scaler.var_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the accompanying info-file\n",
    "with open(model_path + '/model_capped_grid_column_based_final_%d.txt'%NUM, 'w') as file:\n",
    "    write_infofile(file, str(learning_set.columns), str(np.array(learning_set.columns[:-27])), \n",
    "                   model_path, output_path, NUM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
