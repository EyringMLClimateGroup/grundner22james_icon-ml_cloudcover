{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the cross-validation models\n",
    "\n",
    "Compared to cross_validation_evaluate.ipynb in the column-based model it sufficed to <br>\n",
    "i) Change the names from column to cell, <br>\n",
    "ii) add leaky_relu, <br>\n",
    "iii) load layers_data and adapt the function mean_clc_per_vertical_layer accordingly\n",
    "\n",
    "I called model_all_data model_final before. Note that final_model does not mean it is the one that will be used in practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 16:04:29.387951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import importlib\n",
    "\n",
    "#Import sklearn before tensorflow (static Thread-local storage)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "path = '/home/b/b309170'\n",
    "sys.path.insert(0, path + '/workspace_icon-ml/iconml_clc/')\n",
    "\n",
    "import my_classes\n",
    "importlib.reload(my_classes)\n",
    "from my_classes import write_infofile\n",
    "from my_classes import read_mean_and_std\n",
    "\n",
    "# For Leaky_ReLU:\n",
    "import tensorflow as tf\n",
    "from tensorflow import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set these parameters!\n",
    "\n",
    "# Cloud Cover or Cloud Area?\n",
    "output_var = 'clc' # Set output_var to one of {'clc', 'cl_area'}\n",
    "# QUBICC only or QUBICC+NARVAL training data? Always set to True for the paper\n",
    "qubicc_only = True\n",
    "# Do we evaluate a model trained on all data? Always set to False for the paper\n",
    "all_data_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = os.path.join(path, 'workspace_icon-ml/cloud_cover_parameterization/grid_cell_based_QUBICC_R02B05')\n",
    "path_data = os.path.join(path, 'my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_QUBICC_R02B05/based_on_var_interpolated_data')\n",
    "\n",
    "if output_var == 'clc':\n",
    "    full_output_var_name = 'cloud_cover'\n",
    "elif output_var == 'cl_area':\n",
    "    full_output_var_name = 'cloud_area'\n",
    "    \n",
    "if qubicc_only:\n",
    "    output_folder = '%s_R2B5_QUBICC'%full_output_var_name\n",
    "else:\n",
    "    output_folder = '%s_R2B5_QUBICC+NARVAL'%full_output_var_name\n",
    "path_model = os.path.join(path_base, 'saved_models', output_folder)\n",
    "path_figures = os.path.join(path_base, 'figures', output_folder)\n",
    "narval_output_file = '%s_output_narval.npy'%full_output_var_name\n",
    "qubicc_output_file = '%s_output_qubicc.npy'%full_output_var_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m physical_devices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset_visible_devices(\u001b[43mphysical_devices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lrelu(x):\n",
    "#     return nn.leaky_relu(x, alpha=0.01)\n",
    "\n",
    "custom_objects = {}\n",
    "custom_objects['leaky_relu'] = nn.leaky_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_1 = 'cross_validation_cell_based_fold_1.h5'\n",
    "fold_2 = 'cross_validation_cell_based_fold_2.h5'\n",
    "fold_3 = 'cross_validation_cell_based_fold_3.h5'\n",
    "\n",
    "model_fold_1 = load_model(os.path.join(path_model, fold_1), custom_objects)\n",
    "model_fold_2 = load_model(os.path.join(path_model, fold_2), custom_objects)\n",
    "model_fold_3 = load_model(os.path.join(path_model, fold_3), custom_objects)\n",
    "\n",
    "if all_data_model:\n",
    "    all_data = 'cell_based_all_data_seed_10.h5'\n",
    "    model_all_data = load_model(os.path.join(path_model, all_data), custom_objects)\n",
    "\n",
    "# model_fold_1 = load_model(os.path.join(path_model, fold_1))\n",
    "# model_fold_2 = load_model(os.path.join(path_model, fold_2))\n",
    "# model_fold_3 = load_model(os.path.join(path_model, fold_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloud_area_output_qubicc.npy',\n",
       " 'cloud_cover_input_qubicc.npy',\n",
       " 'cloud_cover_output_qubicc.npy',\n",
       " 'samples_vertical_layers_qubicc.npy',\n",
       " 'cloud_cover_input_narval.npy',\n",
       " 'cloud_area_output_narval.npy',\n",
       " 'cloud_cover_output_narval.npy',\n",
       " 'ps_input_qubicc.npy',\n",
       " 'samples_vertical_layers_narval.npy']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.concatenate((np.load(path_data + '/cloud_cover_input_narval.npy'), \n",
    "                             np.load(path_data + '/cloud_cover_input_qubicc.npy')), axis=0)\n",
    "output_data = np.concatenate((np.load(os.path.join(path_data, narval_output_file)), \n",
    "                              np.load(os.path.join(path_data, qubicc_output_file))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_data = np.concatenate((np.load(path_data + '/samples_vertical_layers_narval.npy'), \n",
    "                              np.load(path_data + '/samples_vertical_layers_qubicc.npy')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_narval = np.load(os.path.join(path_data, narval_output_file)).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(samples_total, no_of_features) = input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define cross-validation folds to recreate training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[568092977 568092978 568092979 ... 715172741 715172742 715172743]\n",
      "[715172744 715172745 715172746 ... 862252508 862252509 862252510]\n",
      "[ 862252511  862252512  862252513 ... 1009332275 1009332276 1009332277]\n"
     ]
    }
   ],
   "source": [
    "def set_training_validation_folds(samples_total, samples_narval):\n",
    "    training_folds = []\n",
    "    validation_folds = []\n",
    "    two_week_incr = (samples_total-samples_narval)//6\n",
    "\n",
    "    for i in range(3):\n",
    "        # Note that this is a temporal split since time was the first dimension in the original tensor\n",
    "        first_incr = np.arange(samples_narval+two_week_incr*i, samples_narval+two_week_incr*(i+1))\n",
    "        second_incr = np.arange(samples_narval+two_week_incr*(i+3), samples_narval+two_week_incr*(i+4))\n",
    "        \n",
    "        print(second_incr)\n",
    "\n",
    "        validation_folds.append(np.append(first_incr, second_incr))\n",
    "        training_folds.append(np.arange(samples_narval, samples_total))\n",
    "        training_folds[i] = np.setdiff1d(training_folds[i], validation_folds[i])\n",
    "        \n",
    "    return training_folds, validation_folds\n",
    "\n",
    "if qubicc_only:\n",
    "    # We have to skip the NARVAL data if we do qubicc_only\n",
    "    training_folds, validation_folds = set_training_validation_folds(samples_total, samples_narval)\n",
    "else:\n",
    "    training_folds, validation_folds = set_training_validation_folds(samples_total, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data will need to be scaled according to the training folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Useful functions to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_clc_per_vertical_layer(model, input_data, output_data, layers_data, batch_size=2**20):\n",
    "    '''\n",
    "        Input: \n",
    "            model: neural network\n",
    "            input_data: Usually the validation data\n",
    "            output_data: The ground truth output\n",
    "            layers_data: Vector that tells us the vertical layer of a given sample\n",
    "            \n",
    "        Model prediction and the Ground Truth means per vertical layer\n",
    "    '''\n",
    "    # Predicted cloud cover means\n",
    "    # Curiously it works best if we use predict_on_batch on small subsets of the data instead of predict(..., batch_size=...) \n",
    "    for i in range(1 + input_data.shape[0]//batch_size):\n",
    "        if i == 0:\n",
    "            a = model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])\n",
    "        else:\n",
    "            a = np.concatenate((a, model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "    pred_adj = np.minimum(np.maximum(a, 0), 100) \n",
    "    \n",
    "    # Computing means with the help of layers_data\n",
    "    clc_pred_mean = []; clc_data_mean = [];\n",
    "    for i in range(5, 32):\n",
    "        ind = np.where(layers_data == i)\n",
    "        clc_data_mean.append(np.mean(output_data[ind], dtype=np.float64))\n",
    "        clc_pred_mean.append(np.mean(pred_adj[ind], dtype=np.float64))\n",
    "    \n",
    "    return clc_pred_mean, clc_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figure(fig_name, fig_title, model_predictions, valid_means=None, all_data_model=False):\n",
    "    '''\n",
    "        Note that this figure truly is a different performance measure than the validation error.\n",
    "        The reason is that the mean can in principle be good even when the model is really bad.\n",
    "        \n",
    "        model_predictions: Array of length 3 or 4, covers predictions from all three folds for a given TL setup\n",
    "        valid_means: Array of length 3 or 4, covers validation means from all three folds for a given TL setup\n",
    "    '''\n",
    "#     assert len(model_biases) == 3\n",
    "    \n",
    "    # Vertical layers\n",
    "    a = np.linspace(5, 31, 27)\n",
    "    fig = plt.figure(figsize=(11,7))\n",
    "    # For model\n",
    "    ax = fig.add_subplot(111, xlabel='Mean %s'%output_var, ylabel='Vertical layer', title=fig_title)\n",
    "    \n",
    "    if all_data_model:\n",
    "        if not valid_means[0] == valid_means[1] == valid_means[2] == valid_means[3]:\n",
    "            colors = ['g', 'b', 'r']\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a, colors[i])\n",
    "                if valid_means != None:\n",
    "                    ax.plot(valid_means[i], a, '%s--'%colors[i])\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Fold 1 Truth', 'Model Fold 2 Predictions', 'Fold 2 Truth', \n",
    "                       'Model Fold 3 Predictions', 'Fold 3 Truth', 'Model All Data Predictions', 'Truth'])\n",
    "        else:\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a)\n",
    "            ax.plot(valid_means[0], a, 'black')\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Model Fold 2 Predictions', 'Model Fold 3 Predictions', \n",
    "                       'Model All Data Predictions', 'Truth'])\n",
    "    else:\n",
    "        if not valid_means[0] == valid_means[1] == valid_means[2]:\n",
    "            colors = ['g', 'b', 'r']\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a, colors[i])\n",
    "                if valid_means != None:\n",
    "                    ax.plot(valid_means[i], a, '%s--'%colors[i])\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Fold 1 Truth', 'Model Fold 2 Predictions', 'Fold 2 Truth', \n",
    "                       'Model Fold 3 Predictions', 'Fold 3 Truth'])\n",
    "        else:\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a)\n",
    "            ax.plot(valid_means[0], a, 'black')\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Model Fold 2 Predictions', 'Model Fold 3 Predictions', \n",
    "                       'Truth'])\n",
    "\n",
    "    fig.savefig(os.path.join(path_figures, fig_name+'.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Evaluate the models on the data\n",
    "\n",
    "Add training and validation losses to the text files. <br>\n",
    "Print results per vertical layer (respective validation set/NARVAL/QUBICC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5884/5884 - 43s - loss: 33.4026\n",
      "2942/2942 - 22s - loss: 33.7873\n",
      "5884/5884 - 46s - loss: 33.2210\n",
      "2942/2942 - 22s - loss: 32.7654\n",
      "5884/5884 - 45s - loss: 39.6006\n",
      "2942/2942 - 21s - loss: 40.9376\n"
     ]
    }
   ],
   "source": [
    "train_losses = [] ; valid_losses = [] ; valid_means = [] ; valid_model_predictions = [] ;\n",
    "narval_means = [] ; narval_model_predictions = [] ; qubicc_means = [] ; qubicc_model_predictions = [] ;\n",
    "qubicc_month_0 = [] ; qubicc_model_pred_month_0 = [] ; qubicc_month_1 = [] ; qubicc_model_pred_month_1 = [] ;\n",
    "qubicc_month_2 = [] ; qubicc_model_pred_month_2 = [] ;\n",
    "\n",
    "for i in range(3): \n",
    "    filename = 'cross_validation_cell_based_fold_%d'%(i+1)\n",
    "    # Choose appropriate model for this fold\n",
    "    if i == 0: model = model_fold_1\n",
    "    if i == 1: model = model_fold_2\n",
    "    if i == 2: model = model_fold_3\n",
    "    \n",
    "    #Standardize according to the fold\n",
    "    scaler.fit(input_data[training_folds[i]])\n",
    "    \n",
    "    #Load the data for the respective fold\n",
    "    input_train = scaler.transform(input_data[training_folds[i]])\n",
    "    input_valid = scaler.transform(input_data[validation_folds[i]])\n",
    "    output_train = output_data[training_folds[i]]\n",
    "    output_valid = output_data[validation_folds[i]]\n",
    "    \n",
    "    ## Training and validation losses\n",
    "    train_loss = model.evaluate(input_train, output_train, verbose=2, batch_size=10**5)\n",
    "    valid_loss = model.evaluate(input_valid, output_valid, verbose=2, batch_size=10**5)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_train, output_train\n",
    "    gc.collect()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "        file.write('Unbounded training loss: %.4f\\n'%(train_loss))\n",
    "        file.write('Unbounded validation loss: %.4f\\n'%(valid_loss))\n",
    "        \n",
    "    ## Compute mean cloud cover per vertical layer\n",
    "    # On the respective validation sets (QUBICC and NARVAL)\n",
    "    try:\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_valid, output_valid, \n",
    "                                                                   layers_data[validation_folds[i]])\n",
    "    except(ResourceExhaustedError):\n",
    "        print('Resource Exhausted Qubicc')\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_valid, output_valid, \n",
    "                                                                   layers_data[validation_folds[i]], batch_size=2**15)\n",
    "    valid_means.append(clc_data_mean)\n",
    "    valid_model_predictions.append(clc_pred_mean)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_valid, output_valid\n",
    "    gc.collect()\n",
    "    \n",
    "    # For NARVAL\n",
    "    input_narval = scaler.transform(input_data[:samples_narval])\n",
    "    output_narval = output_data[:samples_narval]\n",
    "    try:\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_narval, output_narval,\n",
    "                                                                  layers_data[:samples_narval])\n",
    "    except(ResourceExhaustedError):\n",
    "        print('Resource Exhausted Narval')\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_narval, output_narval, \n",
    "                                                                   layers_data[:samples_narval], \n",
    "                                                                   batch_size=2**15)\n",
    "    narval_means.append(clc_data_mean)\n",
    "    narval_model_predictions.append(clc_pred_mean)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_narval, output_narval\n",
    "    gc.collect()\n",
    "    \n",
    "    # For QUBICC  \n",
    "    input_qubicc = scaler.transform(input_data[samples_narval:])\n",
    "    output_qubicc = output_data[samples_narval:]\n",
    "    try:\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc,\n",
    "                                                                  layers_data[samples_narval:])\n",
    "    except(ResourceExhaustedError):\n",
    "        print('Resource Exhausted Qubicc')\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc, \n",
    "                                                                   layers_data[samples_narval:], \n",
    "                                                                   batch_size=2**15)\n",
    "    qubicc_means.append(clc_data_mean)\n",
    "    qubicc_model_predictions.append(clc_pred_mean)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_qubicc, output_qubicc\n",
    "    gc.collect()\n",
    "    \n",
    "    # QUBICC months\n",
    "    qubicc_month = (samples_total - samples_narval)//3\n",
    "    for month in range(3):\n",
    "        first_ind = samples_narval + month*qubicc_month\n",
    "        last_ind = samples_narval + (month+1)*qubicc_month\n",
    "        input_qubicc = scaler.transform(input_data[first_ind:last_ind])\n",
    "        output_qubicc = output_data[first_ind:last_ind]\n",
    "        try:\n",
    "            clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc,\n",
    "                                                                      layers_data[first_ind:last_ind])\n",
    "        except(ResourceExhaustedError):\n",
    "            print('Resource Exhausted Qubicc')\n",
    "            clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc, \n",
    "                                                                       layers_data[first_ind:last_ind],\n",
    "                                                                       batch_size=2**15)\n",
    "        if month==0: \n",
    "            qubicc_month_0.append(clc_data_mean)\n",
    "            qubicc_model_pred_month_0.append(clc_pred_mean)\n",
    "        if month==1:\n",
    "            qubicc_month_1.append(clc_data_mean)\n",
    "            qubicc_model_pred_month_1.append(clc_pred_mean)\n",
    "        if month==2:\n",
    "            qubicc_month_2.append(clc_data_mean)\n",
    "            qubicc_model_pred_month_2.append(clc_pred_mean)\n",
    "\n",
    "    # Clear up some memory\n",
    "    del input_qubicc, output_qubicc\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all_data_model:\n",
    "#     filename = 'cell_based_all_data_seed_10'\n",
    "#     model = model_all_data\n",
    "\n",
    "#     #Standardize according to the fold\n",
    "#     scaler.fit(input_data)\n",
    "\n",
    "#     #Load the data for the respective fold\n",
    "#     input_train = scaler.transform(input_data)\n",
    "#     output_train = output_data\n",
    "\n",
    "#     ## Training loss\n",
    "#     train_loss = model.evaluate(input_train, output_train, verbose=2, batch_size=10**5)\n",
    "\n",
    "#     # Clear up some memory\n",
    "#     del input_train, output_train\n",
    "#     gc.collect()\n",
    "\n",
    "#     train_losses.append(train_loss)\n",
    "\n",
    "#     with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "#         file.write('Unbounded training loss: %.4f\\n'%(train_loss))\n",
    "\n",
    "#     ## For NARVAL\n",
    "#     input_narval = scaler.transform(input_data[:samples_narval])\n",
    "#     output_narval = output_data[:samples_narval]\n",
    "#     try:\n",
    "#         clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_narval, output_narval,\n",
    "#                                                                   layers_data[:samples_narval])\n",
    "#     except(ResourceExhaustedError):\n",
    "#         print('Resource Exhausted Narval')\n",
    "#         clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_narval, output_narval, \n",
    "#                                                                    layers_data[:samples_narval], \n",
    "#                                                                    batch_size=2**15)\n",
    "#     narval_means.append(clc_data_mean)\n",
    "#     narval_model_predictions.append(clc_pred_mean)\n",
    "\n",
    "#     # Clear up some memory\n",
    "#     del input_narval, output_narval\n",
    "#     gc.collect()\n",
    "\n",
    "#     ## For QUBICC  \n",
    "#     input_qubicc = scaler.transform(input_data[samples_narval:])\n",
    "#     output_qubicc = output_data[samples_narval:]\n",
    "#     try:\n",
    "#         clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc,\n",
    "#                                                                   layers_data[samples_narval:])\n",
    "#     except(ResourceExhaustedError):\n",
    "#         print('Resource Exhausted Qubicc')\n",
    "#         clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc, \n",
    "#                                                                    layers_data[samples_narval:], \n",
    "#                                                                    batch_size=2**15)\n",
    "#     qubicc_means.append(clc_data_mean)\n",
    "#     qubicc_model_predictions.append(clc_pred_mean)\n",
    "\n",
    "#     # Clear up some memory\n",
    "#     del input_qubicc, output_qubicc\n",
    "#     gc.collect()\n",
    "\n",
    "#     ## QUBICC months\n",
    "#     qubicc_month = (samples_total - samples_narval)//3\n",
    "#     for month in range(3):\n",
    "#         first_ind = samples_narval + month*qubicc_month\n",
    "#         last_ind = samples_narval + (month+1)*qubicc_month\n",
    "#         input_qubicc = scaler.transform(input_data[first_ind:last_ind])\n",
    "#         output_qubicc = output_data[first_ind:last_ind]\n",
    "#         try:\n",
    "#             clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc,\n",
    "#                                                                       layers_data[first_ind:last_ind])\n",
    "#         except(ResourceExhaustedError):\n",
    "#             print('Resource Exhausted Qubicc')\n",
    "#             clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc, \n",
    "#                                                                        layers_data[first_ind:last_ind],\n",
    "#                                                                        batch_size=2**15)\n",
    "#         if month==0: \n",
    "#             qubicc_month_0.append(clc_data_mean)\n",
    "#             qubicc_model_pred_month_0.append(clc_pred_mean)\n",
    "#         if month==1:\n",
    "#             qubicc_month_1.append(clc_data_mean)\n",
    "#             qubicc_model_pred_month_1.append(clc_pred_mean)\n",
    "#         if month==2:\n",
    "#             qubicc_month_2.append(clc_data_mean)\n",
    "#             qubicc_model_pred_month_2.append(clc_pred_mean)\n",
    "\n",
    "#     # Clear up some memory\n",
    "#     del input_qubicc, output_qubicc\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Plot results\n",
    "# save_figure('cross_validation_validation_means', 'Cell-based models on the respective validation sets', \n",
    "#             valid_model_predictions, valid_means, all_data_model)\n",
    "# save_figure('cross_validation_narval', 'Cell-based models on the NARVAL data', \n",
    "#             narval_model_predictions, narval_means, all_data_model)\n",
    "# save_figure('cross_validation_qubicc', 'Cell-based models on the QUBICC data', \n",
    "#             qubicc_model_predictions, qubicc_means, all_data_model)\n",
    "# # Qubicc months\n",
    "# save_figure('cross_validation_qubicc_hc2', 'Cell-based models on the QUBICC data, November 2004', \n",
    "#             qubicc_model_pred_month_0, qubicc_month_0, all_data_model)\n",
    "# save_figure('cross_validation_qubicc_hc3', 'Cell-based models on the QUBICC data, April 2005', \n",
    "#             qubicc_model_pred_month_1, qubicc_month_1, all_data_model)\n",
    "# save_figure('cross_validation_qubicc_hc4', 'Cell-based models on the QUBICC data, November 2005', \n",
    "#             qubicc_model_pred_month_2, qubicc_month_2, all_data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we want to reproduce the plots without running everything again:\n",
    "with open(os.path.join(path_figures, 'values_for_figures.txt'), 'w') as file:\n",
    "    file.write('On validation sets\\n')\n",
    "    file.write(str(valid_means))\n",
    "    file.write(str(valid_model_predictions))\n",
    "    file.write('\\n\\nNARVAL data\\n')\n",
    "    file.write(str(narval_means))\n",
    "    file.write(str(narval_model_predictions))\n",
    "    file.write('\\n\\nQubicc data\\n')\n",
    "    file.write(str(qubicc_means))\n",
    "    file.write(str(qubicc_model_predictions))\n",
    "    file.write('\\n\\nQubicc data, November 2004\\n')\n",
    "    file.write(str(qubicc_month_0))\n",
    "    file.write(str(qubicc_model_pred_month_0))\n",
    "    file.write('\\n\\nQubicc data, April 2005\\n')\n",
    "    file.write(str(qubicc_month_1))\n",
    "    file.write(str(qubicc_model_pred_month_1))\n",
    "    file.write('\\n\\nQubicc data, November 2005\\n')\n",
    "    file.write(str(qubicc_month_2))\n",
    "    file.write(str(qubicc_model_pred_month_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compute bounded losses\n",
    "\n",
    "We also save the scaling parameters for the fold-based models as we haven't done that yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bounded_loss(model, input_data, output_data, batch_size=2**20):\n",
    "    for i in range(1 + input_data.shape[0]//batch_size):\n",
    "        if i == 0:\n",
    "            a = model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])\n",
    "        else:\n",
    "            a = np.concatenate((a, model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "    # Bounded output!\n",
    "    pred_adj = np.minimum(np.maximum(a[:,0], 0), 100) \n",
    "    \n",
    "    # Mean Squared Error\n",
    "    return np.mean((pred_adj - output_data)**2, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "\n",
    "for i in range(3): #for i in range(3):\n",
    "    filename = 'cross_validation_cell_based_fold_%d'%(i+1)\n",
    "    # Choose appropriate model for this fold\n",
    "    if i == 0: model = model_fold_1\n",
    "    if i == 1: model = model_fold_2\n",
    "    if i == 2: model = model_fold_3\n",
    "        \n",
    "    #Standardize according to the fold\n",
    "    scaler.fit(input_data[training_folds[i]])\n",
    "    \n",
    "    # We save the scaling parameters in a file [only once]\n",
    "#     seed_i = int(str(seed) + str(i))\n",
    "#     with open(path_model+'/scaler_%d.txt'%seed_i, 'a') as file:\n",
    "#         file.write('Standard Scaler mean values:\\n')\n",
    "#         file.write(str(scaler.mean_))\n",
    "#         file.write('\\nStandard Scaler standard deviation:\\n')\n",
    "#         file.write(str(np.sqrt(scaler.var_)))\n",
    "\n",
    "    # Taken from preprocessing_narval\n",
    "    in_and_out_variables = np.array(['qv', 'qc', 'qi', 'temp', 'pres', 'u', 'v', 'zg', 'coriolis', 'fr_land', output_var])\n",
    "    input_variables = np.array(['qv', 'qc', 'qi', 'temp', 'pres', 'u', 'v', 'zg', 'coriolis', 'fr_land'])\n",
    "\n",
    "#     # Write the accompanying info-file [only once]\n",
    "#     with open(os.path.join(path_model, filename + '.txt'), 'a') as file:\n",
    "#         write_infofile(file, str(in_and_out_variables), str(input_variables), path_model, path_data, seed_i)\n",
    "    \n",
    "    #Load the data for the respective fold\n",
    "    input_train = scaler.transform(input_data[training_folds[i]])\n",
    "    input_valid = scaler.transform(input_data[validation_folds[i]])\n",
    "    output_train = output_data[training_folds[i]]\n",
    "    output_valid = output_data[validation_folds[i]]\n",
    "    \n",
    "    train_loss = compute_bounded_loss(model, input_train, output_train, batch_size=2**15)\n",
    "    valid_loss = compute_bounded_loss(model, input_valid, output_valid, batch_size=2**15)\n",
    "        \n",
    "    with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "        file.write('Bounded training loss: %.4f\\n'%(train_loss))\n",
    "        file.write('Bounded validation loss: %.4f\\n'%(valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all_data_model:\n",
    "#     filename = 'cell_based_all_data_seed_10'\n",
    "#     model = model_all_data\n",
    "\n",
    "#     #Standardize according to the fold\n",
    "#     scaler.fit(input_data)\n",
    "\n",
    "#     #Load the data for the respective fold\n",
    "#     input_train = scaler.transform(input_data)\n",
    "#     output_train = output_data\n",
    "\n",
    "#     train_loss = compute_bounded_loss(model, input_train, output_train, batch_size=2**15)\n",
    "\n",
    "#     with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "#         file.write('Bounded training loss: %.4f\\n'%(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Range of possible output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the input data. Why did we look at fold 3 here, if the second one is the best one??\n",
    "mean, std = read_mean_and_std(os.path.join(path_model, \n",
    "                                               'cross_validation_cell_based_fold_3.txt'))\n",
    "input_train = (input_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fold_3 is implemented in ICON-A\n",
    "batch_size = 2**20\n",
    "\n",
    "for i in range(1 + input_train.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        image = model_fold_3.predict_on_batch(input_train[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        image = np.concatenate((image, model_fold_3.predict_on_batch(input_train[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009332282, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.9592514], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107.00978], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(image, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### How often are the predictions of the model from split 2 outside [0, 100]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_fold_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the input data.\n",
    "mean, std = read_mean_and_std(os.path.join(path_model, \n",
    "                                               'cross_validation_cell_based_fold_2.txt'))\n",
    "\n",
    "input_train = (input_data[training_folds[1]] - mean)/std\n",
    "input_valid = (input_data[validation_folds[1]] - mean)/std\n",
    "output_train = output_data[training_folds[1]]\n",
    "output_valid = output_data[validation_folds[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need 170GB in total\n",
    "batch_size = 2**26\n",
    "\n",
    "for i in range(1 + input_valid.shape[0]//batch_size): ## 1 + input_valid.shape[0]//batch_size\n",
    "    if i == 0:\n",
    "        image_valid = model.predict_on_batch(input_valid[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        image_valid = np.concatenate((image_valid, model.predict_on_batch(input_valid[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3348307656756078"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside of the [0, 100] range\n",
    "(np.sum(np.where(image_valid < 0, True, False)) + np.sum(np.where(image_valid > 100, True, False)))/len(image_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08770510222524353"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside of the [-1, 100] range\n",
    "(np.sum(np.where(image_valid < -1, True, False)) + np.sum(np.where(image_valid > 100, True, False)))/len(image_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need 170GB in total\n",
    "batch_size = 2**25\n",
    "\n",
    "for i in range(1 + input_train.shape[0]//batch_size):\n",
    "    if i == 0:\n",
    "        image_train = model_fold_3.predict_on_batch(input_train[i*batch_size:(i+1)*batch_size])\n",
    "    else:\n",
    "        image_train = np.concatenate((image_train, model_fold_3.predict_on_batch(input_train[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1338802594521362"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside of the [0, 100] range\n",
    "(np.sum(np.where(image_train < 0, True, False)) + np.sum(np.where(image_train > 100, True, False)))/len(image_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007492116454793429"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside of the [-1, 100] range\n",
    "(np.sum(np.where(image_train < -1, True, False)) + np.sum(np.where(image_train > 100, True, False)))/len(image_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_all = np.concatenate((image_train, image_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20086376122301144"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside of the [0, 100] range\n",
    "(np.sum(np.where(image_all < 0, True, False)) + np.sum(np.where(image_all > 100, True, False)))/len(image_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03422977825708332"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside of the [-1, 100] range\n",
    "(np.sum(np.where(image_all < -1, True, False)) + np.sum(np.where(image_all > 100, True, False)))/len(image_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
