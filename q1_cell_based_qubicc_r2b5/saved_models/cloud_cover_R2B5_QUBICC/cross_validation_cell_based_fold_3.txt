How to use the model:
model = tensorflow.keras.models.load_model(filename+'.h5')
model.predict(scaled input data)

Input/Output
------------
Input and output variables:
['qv' 'qc' 'qi' 'temp' 'pres' 'u' 'v' 'zg' 'coriolis' 'fr_land' 'clc']
The (order of) input variables:
['qv' 'qc' 'qi' 'temp' 'pres' 'u' 'v' 'zg' 'coriolis' 'fr_land']

Scaling
-------
Standard Scaler mean values:
[ 3.58226388e-03  1.05778655e-05  3.71113335e-06  2.54741565e+02
  5.54564057e+04  4.85465680e+00  5.44230394e-03  6.33356463e+03
 -2.60158522e-06  2.51302457e-01]
Standard Scaler standard deviation:
[4.55045338e-03 4.68918926e-05 1.90061913e-05 2.97537181e+01
 3.07411348e+04 9.20365048e+00 4.92821212e+00 5.62627033e+03
 8.31717774e-05 4.19201613e-01]
=> Apply this standard scaling to (only) the input data before processing.

Preprocessed data
-----------------
/pf/b/b309170/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_QUBICC_R02B05/based_on_var_interpolated_data/cloud_cover_input_qubicc.npy

Model
-----
Training epochs: 30
Weights restored from epoch: 13
Unbounded training loss: 39.6006
Unbounded validation loss: 40.9376
Bounded training loss: 36.1470
Bounded validation loss: 37.4792
