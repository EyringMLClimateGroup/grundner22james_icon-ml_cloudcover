How to use the model:
model = tensorflow.keras.models.load_model(filename+'.h5')
model.predict(scaled input data)

Input/Output
------------
Input and output variables:
['qv' 'qc' 'qi' 'temp' 'pres' 'u' 'v' 'zg' 'coriolis' 'fr_land' 'clc']
The (order of) input variables:
['qv' 'qc' 'qi' 'temp' 'pres' 'u' 'v' 'zg' 'coriolis' 'fr_land']

Scaling
-------
Standard Scaler mean values:
[ 3.59503424e-03  1.07869346e-05  3.71857870e-06  2.54882297e+02
  5.56035638e+04  4.63840425e+00  9.42848802e-03  6.31558084e+03
 -2.87361135e-06  2.50136883e-01]
Standard Scaler standard deviation:
[4.56789067e-03 4.72075347e-05 1.91928682e-05 2.97062248e+01
 3.07715795e+04 9.21599384e+00 5.03164645e+00 5.63475312e+03
 8.31577108e-05 4.18508149e-01]
=> Apply this standard scaling to (only) the input data before processing.

Preprocessed data
-----------------
/pf/b/b309170/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_QUBICC_R02B05/based_on_var_interpolated_data/cloud_cover_input_qubicc.npy

Model
-----
Training epochs: 30
Weights restored from epoch: 21
Unbounded training loss: 33.4026
Unbounded validation loss: 33.7873
Bounded training loss: 29.7239
Bounded validation loss: 30.1106
