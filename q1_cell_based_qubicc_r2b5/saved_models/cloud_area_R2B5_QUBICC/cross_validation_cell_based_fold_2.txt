How to use the model:
model = tensorflow.keras.models.load_model(filename+'.h5')
model.predict(scaled input data)

Input/Output
------------
Input and output variables:
['qv' 'qc' 'qi' 'temp' 'pres' 'u' 'v' 'zg' 'coriolis' 'fr_land' 'cl_area']
The (order of) input variables:
['qv' 'qc' 'qi' 'temp' 'pres' 'u' 'v' 'zg' 'coriolis' 'fr_land']

Scaling
-------
Standard Scaler mean values:
[ 3.60451178e-03  1.06371446e-05  3.73792945e-06  2.54823043e+02
  5.53563125e+04  4.80185201e+00  2.08690253e-02  6.35512546e+03
 -3.51841227e-06  2.50654436e-01]
Standard Scaler standard deviation:
[4.58632933e-03 4.78481291e-05 1.89885666e-05 2.97834677e+01
 3.07440652e+04 9.14137385e+00 4.99623853e+00 5.63263769e+03
 8.30853050e-05 4.18913034e-01]
=> Apply this standard scaling to (only) the input data before processing.

Preprocessed data
-----------------
/pf/b/b309170/my_work/icon-ml_data/cloud_cover_parameterization/grid_cell_based_QUBICC_R02B05/based_on_var_interpolated_data/cloud_cover_input_qubicc.npy

Model
-----
Training epochs: 30
Weights restored from epoch: 5
Unbounded training loss: 88.1429
Unbounded validation loss: 87.9764
Bounded training loss: 81.2143
Bounded validation loss: 80.9610
