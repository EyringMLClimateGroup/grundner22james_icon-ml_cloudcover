{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Narval\n",
    "\n",
    "**This data was not used to train the NNs**\n",
    "\n",
    "Converting the data into npy makes it possible for us to work with it efficiently; originally we require 500GB of RAM which is always difficult to guarantee. We preprocess QUBICC in another ipynb notebook precisely because of this issue.\n",
    "\n",
    "1) We read the data\n",
    "2) Reshape variables so that they have equal dimensionality\n",
    "3) Remove data above 21kms\n",
    "4) Reshape into data samples fit for the NN\n",
    "5) Split into input and output\n",
    "6) Save as npy in float32\n",
    "\n",
    "Note: We neither scale nor split the data into training/validation/test sets. <br>\n",
    "The reason is that i) in order to scale we need the entire dataset but this can only be done in conjunction with the Qubicc dataset. Also for cross-validation different scalings will be necessary based on different subsets of the data, ii) The split into subsets will be done by the cross-validation procedure or not at all when training the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "# import importlib\n",
    "# importlib.reload(my_classes)\n",
    "\n",
    "base_path = '/pf/b/b309170'\n",
    "output_path = base_path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_column_based_QUBICC_R02B05/based_on_var_interpolated_data'\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "sys.path.insert(0, base_path + '/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "# Which days to load\n",
    "days_narval = 'all'\n",
    "\n",
    "from my_classes import load_data\n",
    "\n",
    "VERT_LAYERS = 31\n",
    "\n",
    "# Set output_var to one of {'clc', 'cl_area'}\n",
    "output_var = 'cl_area'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading the data\n",
    "### Input:\n",
    "- fr_land: Fraction of land\n",
    "- zg: Geometric height at full levels (3D)\n",
    "- qv: Specific water vapor content (3D)\n",
    "- qc: Specific cloud water content (3D)\n",
    "- qi: Specific cloud ice content (3D)\n",
    "- temp: Temperature (3D)\n",
    "- pres: Pressure (3D)\n",
    "\n",
    "$186$ $( = 1+24[zf]+26[q_c]+27\\cdot 5$) input nodes\n",
    "\n",
    "### Output:\n",
    "- clc: Cloud Cover\n",
    "\n",
    "$27$ output nodes\n",
    "\n",
    "The data above 21km is capped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cl_area I only need the output as I already have the input\n",
    "# I still need 'qc', 'qi', 'clc' for condensate-free clouds\n",
    "# If I were to use 'cl_area' for condensate-free clouds I would get an estimate \n",
    "# which is slightly different due to coarse-graining\n",
    "\n",
    "order_of_vars_narval = ['qv', 'qc', 'qi', 'temp', 'pres', 'zg', 'fr_land', output_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NARVAL data\n",
    "data_dict = load_data(source='narval', days=days_narval, resolution='R02B05', \n",
    "                             order_of_vars=order_of_vars_narval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_var == 'clc':\n",
    "    # Are there any bad data points\n",
    "    ta_is_0 = np.where(data_dict['temp'] == 0)\n",
    "    for i in range(3):\n",
    "        assert ta_is_0[i].size == 0\n",
    "\n",
    "    del ta_is_0\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting fraction of condensate-free clouds <br>\n",
    "I'll leave them in the training data for the column-based and region-based models. The reason is that we would have to remove quite a lot around the given grid cell. I can do that in the grid-cell based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clouds = 0\n",
    "# count_cond_free_clouds = 0\n",
    "# for i in range(data_dict['clc'].shape[0]):\n",
    "#     for j in range(data_dict['clc'].shape[1]):\n",
    "#         for k in range(data_dict['clc'].shape[2]):\n",
    "#             if (data_dict['clc'][i,j,k] > 0 and data_dict['qc'][i,j,k] + data_dict['qi'][i,j,k] == 0):\n",
    "#                 count_cond_free_clouds += 1\n",
    "#             if (data_dict['clc'][i,j,k] > 0):\n",
    "#                 clouds += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_cond_free_clouds/clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_dict.keys():\n",
    "    print(key, data_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(TIME_STEPS, VERT_LAYERS, HORIZ_FIELDS) = data_dict['clc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Reshaping into nd-arrays of equaling shapes (don't reshape in the vertical)\n",
    "    data_dict['zg'] = np.repeat(np.expand_dims(data_dict['zg'], 0), TIME_STEPS, axis=0)\n",
    "    data_dict['fr_land'] = np.repeat(np.expand_dims(data_dict['fr_land'], 0), TIME_STEPS, axis=0)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One sample should contain a column of information\n",
    "data_dict_reshaped = {}\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    if data_dict[key].shape[1] == VERT_LAYERS:  \n",
    "        # Removing data above 21kms\n",
    "        for i in range(4, VERT_LAYERS):\n",
    "            new_key = '{}{}{:d}'.format(key,'_',(i+17)) # Should start at 21\n",
    "            data_dict_reshaped[new_key] = np.reshape(data_dict[key][:,i,:], -1)\n",
    "    else:\n",
    "        data_dict_reshaped[key] = np.reshape(data_dict[key], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qc_21</th>\n",
       "      <th>qc_22</th>\n",
       "      <th>qc_23</th>\n",
       "      <th>qc_24</th>\n",
       "      <th>qc_25</th>\n",
       "      <th>qc_26</th>\n",
       "      <th>qc_27</th>\n",
       "      <th>qc_28</th>\n",
       "      <th>qc_29</th>\n",
       "      <th>qc_30</th>\n",
       "      <th>...</th>\n",
       "      <th>cl_area_38</th>\n",
       "      <th>cl_area_39</th>\n",
       "      <th>cl_area_40</th>\n",
       "      <th>cl_area_41</th>\n",
       "      <th>cl_area_42</th>\n",
       "      <th>cl_area_43</th>\n",
       "      <th>cl_area_44</th>\n",
       "      <th>cl_area_45</th>\n",
       "      <th>cl_area_46</th>\n",
       "      <th>cl_area_47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.160102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.832987</td>\n",
       "      <td>0.273194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.467355e-08</td>\n",
       "      <td>1.200798e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.338172e-08</td>\n",
       "      <td>1.548238e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qc_21  qc_22         qc_23         qc_24  qc_25  qc_26  qc_27  qc_28  \\\n",
       "0    0.0    0.0  0.000000e+00  0.000000e+00    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0  0.000000e+00  0.000000e+00    0.0    0.0    0.0    0.0   \n",
       "2    0.0    0.0  0.000000e+00  0.000000e+00    0.0    0.0    0.0    0.0   \n",
       "3    0.0    0.0  6.467355e-08  1.200798e-08    0.0    0.0    0.0    0.0   \n",
       "4    0.0    0.0  8.338172e-08  1.548238e-08    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   qc_29  qc_30  ...  cl_area_38  cl_area_39  cl_area_40  cl_area_41  \\\n",
       "0    0.0    0.0  ...         0.0    0.000000    0.000000    0.000000   \n",
       "1    0.0    0.0  ...         0.0    0.003891    0.003891    0.160102   \n",
       "2    0.0    0.0  ...         0.0    1.832987    0.273194    0.000000   \n",
       "3    0.0    0.0  ...         0.0    0.000000    0.000000    0.000000   \n",
       "4    0.0    0.0  ...         0.0    0.000000    0.000000    0.000000   \n",
       "\n",
       "   cl_area_42  cl_area_43  cl_area_44  cl_area_45  cl_area_46  cl_area_47  \n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting dict into a DataFrame-object \n",
    "df = pd.DataFrame.from_dict(data_dict_reshaped)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifies df as well\n",
    "def split_input_output(dataset):\n",
    "    output_df = pd.DataFrame()\n",
    "    for i in range(21, 48):\n",
    "        output_df['cl_area_%d'%i] = dataset['cl_area_%d'%i] # Should start at 21\n",
    "        del dataset['cl_area_%d'%i]\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = split_input_output(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "if output_var == 'clc':\n",
    "    np.save(output_path + '/cloud_cover_input_narval.npy', np.float32(df))\n",
    "    np.save(output_path + '/cloud_cover_output_narval.npy', np.float32(output_df))\n",
    "elif output_var == 'cl_area':\n",
    "    np.save(output_path + '/cloud_area_output_narval.npy', np.float32(output_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "if output_var == 'cl_area':\n",
    "    old_input = np.load(output_path + '/cloud_cover_input_narval.npy')\n",
    "    # If this yields True once then we're done\n",
    "    for i in range(old_input.shape[1]):\n",
    "        print(np.all(old_input[:,i] == df['qi_25']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds113_kernel",
   "language": "python",
   "name": "clouds113_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
