Learning rates from seemingly best to worse: 0.001 > 0.005 > 0.1 > 0.002 > 0.01 > 0.0005 > 0.0001 > 0.00005

[learning_rate=0.00005] 
=======================
Epoch 1/2
918187/918187 - 3688s - loss: 39.8177 - val_loss: 3.1730
Epoch 2/2
918187/918187 - 3587s - loss: 34.8784 - val_loss: 5.0370
Epoch 1/30
918187/918187 - 3622s - loss: 38.7137 - val_loss: 3.1859
Epoch 2/30
918187/918187 - 3568s - loss: 32.1330 - val_loss: 2.2530
Epoch 3/30
918187/918187 - 3528s - loss: 34.4574 - val_loss: 3.2316
Epoch 4/30
918187/918187 - 3569s - loss: 32.1629 - val_loss: 3.0557
Epoch 5/30
918187/918187 - 3521s - loss: 33.8504 - val_loss: 2.1828
Epoch 6/30
918187/918187 - 3573s - loss: 33.6522 - val_loss: 2.3813
Epoch 7/30
918187/918187 - 3563s - loss: 31.6902 - val_loss: 3.0737
Epoch 8/30
918187/918187 - 3559s - loss: 29.8676 - val_loss: 2.6030
Epoch 9/30
918187/918187 - 3535s - loss: 29.9281 - val_loss: 2.4857
Epoch 10/30
918187/918187 - 3550s - loss: 31.0875 - val_loss: 2.4277
Epoch 11/30
918187/918187 - 3538s - loss: 31.6483 - val_loss: 2.7949

=> Training too slow even though validation error seems good. It doesn't seem to be too representative.


[learning_rate=0.0001]
======================
Epoch 1/30
918187/918187 [==============================] - 4770s 5ms/step - loss: 16.4533 - val_loss: 3.3925
Epoch 2/30
918187/918187 [==============================] - 4735s 5ms/step - loss: 12.1110 - val_loss: 6.0744
Epoch 3/30
918187/918187 [==============================] - 4739s 5ms/step - loss: 11.4812 - val_loss: 4.0817
Epoch 4/30
918187/918187 [==============================] - 4696s 5ms/step - loss: 11.2091 - val_loss: 3.6768
Epoch 5/30
918187/918187 [==============================] - 4698s 5ms/step - loss: 10.9599 - val_loss: 2.5459
Epoch 6/30
918187/918187 [==============================] - 4720s 5ms/step - loss: 10.7868 - val_loss: 2.9999
Epoch 7/30
918187/918187 [==============================] - 4689s 5ms/step - loss: 10.6415 - val_loss: 2.7312
Epoch 8/30
918187/918187 [==============================] - 4690s 5ms/step - loss: 10.5537 - val_loss: 3.4967
Epoch 9/30
918187/918187 [==============================] - 4701s 5ms/step - loss: 10.5369 - val_loss: 3.8561
Epoch 10/30
918187/918187 [==============================] - 4686s 5ms/step - loss: 10.3912 - val_loss: 3.0876
Epoch 11/30
918187/918187 [==============================] - 4714s 5ms/step - loss: 10.4095 - val_loss: 3.2498
Epoch 12/30
918187/918187 [==============================] - 4685s 5ms/step - loss: 10.3129 - val_loss: 3.4539
Epoch 13/30
918187/918187 [==============================] - 4679s 5ms/step - loss: 10.3474 - val_loss: 3.7318
Epoch 14/30
918187/918187 [==============================] - 4738s 5ms/step - loss: 10.2585 - val_loss: 3.4275
Epoch 15/30
843652/918187 [==========================>...] - ETA: 2:41 - loss: 10.2139

=> Training too slow even though validation error seems good. It doesn't seem to be too representative.


[learning_rate=0.0005] 
======================
Epoch 1/2
918187/918187 [==============================] - 4856s 5ms/step - loss: 16.4164 - val_loss: 3.5452
Epoch 2/2
918187/918187 [==============================] - 4815s 5ms/step - loss: 12.1448 - val_loss: 4.7448
Epoch 1/30
918187/918187 [==============================] - 4906s 5ms/step - loss: 11.5063 - val_loss: 3.9195
Epoch 2/30
918187/918187 [==============================] - 4851s 5ms/step - loss: 11.1629 - val_loss: 3.8579
Epoch 3/30
918187/918187 [==============================] - 4842s 5ms/step - loss: 10.9445 - val_loss: 3.9989
Epoch 4/30
918187/918187 [==============================] - 4838s 5ms/step - loss: 10.7639 - val_loss: 3.1297
Epoch 5/30
918187/918187 [==============================] - 4876s 5ms/step - loss: 10.6985 - val_loss: 3.0196
Epoch 6/30
918187/918187 [==============================] - 4836s 5ms/step - loss: 10.5737 - val_loss: 3.7984
Epoch 7/30
918187/918187 [==============================] - 4832s 5ms/step - loss: 10.4457 - val_loss: 3.5616
Epoch 8/30
918187/918187 [==============================] - 4862s 5ms/step - loss: 10.3437 - val_loss: 3.7255
Epoch 9/30
918187/918187 [==============================] - 4853s 5ms/step - loss: 10.2895 - val_loss: 3.0745
Epoch 10/30
918187/918187 [==============================] - 4853s 5ms/step - loss: 10.2651 - val_loss: 4.2428
Epoch 11/30
918187/918187 [==============================] - 4864s 5ms/step - loss: 10.2038 - val_loss: 3.3832
Epoch 12/30
918187/918187 [==============================] - 4886s 5ms/step - loss: 10.1713 - val_loss: 3.1069
Epoch 13/30
918187/918187 [==============================] - 4868s 5ms/step - loss: 10.1450 - val_loss: 3.0639
Epoch 14/30
918187/918187 [==============================] - 4840s 5ms/step - loss: 10.1173 - val_loss: 3.3096
Epoch 15/30
918187/918187 [==============================] - 4859s 5ms/step - loss: 10.0966 - val_loss: 3.0202
Epoch 16/30
918187/918187 [==============================] - 4828s 5ms/step - loss: 10.0666 - val_loss: 2.9338
Epoch 17/30
918187/918187 [==============================] - 4855s 5ms/step - loss: 10.0771 - val_loss: 2.6401
Epoch 18/30
918187/918187 [==============================] - 4866s 5ms/step - loss: 10.0739 - val_loss: 2.8634
Epoch 19/30
918187/918187 [==============================] - 4833s 5ms/step - loss: 10.0233 - val_loss: 3.0360
Epoch 20/30
918187/918187 [==============================] - 4868s 5ms/step - loss: 10.0417 - val_loss: 2.9563
Epoch 21/30
918187/918187 [==============================] - 4836s 5ms/step - loss: 10.0092 - val_loss: 2.2770
Epoch 22/30
918187/918187 [==============================] - 4857s 5ms/step - loss: 10.0024 - val_loss: 2.4405
Epoch 23/30
918187/918187 [==============================] - 4834s 5ms/step - loss: 9.9941 - val_loss: 2.7593
Epoch 24/30
918180/918187 [============================>.] - ETA: 0s - loss: 9.9783

=> Training too slow even though validation error seems good. It doesn't seem to be too representative.


[learning_rate=0.001] [random 20% of the data]

Epoch 1/50
183637/183637 - 824s - loss: 12.3638 - val_loss: 7.1172
Epoch 2/50
183637/183637 - 813s - loss: 11.2504 - val_loss: 7.0194
Epoch 3/50
183637/183637 - 815s - loss: 10.4824 - val_loss: 6.9902
Epoch 4/50
183637/183637 - 814s - loss: 9.8967 - val_loss: 6.3263
Epoch 5/50
183637/183637 - 819s - loss: 9.9731 - val_loss: 6.3913
Epoch 6/50
183637/183637 - 817s - loss: 9.9447 - val_loss: 6.5160
Epoch 7/50
183637/183637 - 821s - loss: 9.8402 - val_loss: 6.6903
Epoch 8/50
183637/183637 - 818s - loss: 9.8497 - val_loss: 6.4122
Epoch 9/50
183637/183637 - 816s - loss: 9.6849 - val_loss: 6.9333
Epoch 10/50
183637/183637 - 812s - loss: 9.5206 - val_loss: 7.1139
Epoch 11/50
183637/183637 - 813s - loss: 9.0109 - val_loss: 7.3451
Epoch 12/50
183637/183637 - 812s - loss: 9.3221 - val_loss: 7.5954
Epoch 13/50
183637/183637 - 817s - loss: 9.1228 - val_loss: 7.4952
Epoch 14/50
183637/183637 - 809s - loss: 8.9880 - val_loss: 7.5675
Epoch 15/50
183637/183637 - 807s - loss: 8.8571 - val_loss: 7.4245
Epoch 16/50
183637/183637 - 811s - loss: 8.8253 - val_loss: 7.1309
Epoch 17/50
183637/183637 - 817s - loss: 8.6813 - val_loss: 6.8513
Epoch 18/50
183637/183637 - 816s - loss: 8.7323 - val_loss: 7.2181
Epoch 19/50
183637/183637 - 815s - loss: 8.8950 - val_loss: 6.8436
Epoch 20/50
183637/183637 - 812s - loss: 8.8780 - val_loss: 6.6376
Epoch 21/50
183637/183637 - 809s - loss: 8.7061 - val_loss: 6.8592
Epoch 22/50
183637/183637 - 815s - loss: 8.4044 - val_loss: 6.8360
Epoch 23/50
183637/183637 - 811s - loss: 8.2702 - val_loss: 6.5243
Epoch 24/50
183637/183637 - 814s - loss: 8.3837 - val_loss: 6.4633
Epoch 25/50
183637/183637 - 817s - loss: 8.4336 - val_loss: 6.4171
Epoch 26/50
183637/183637 - 817s - loss: 8.5887 - val_loss: 6.3852
Epoch 27/50
183637/183637 - 819s - loss: 8.2772 - val_loss: 6.2761
Epoch 28/50
183637/183637 - 815s - loss: 7.9902 - val_loss: 6.3453
Epoch 29/50
183637/183637 - 811s - loss: 8.0334 - val_loss: 6.5386
Epoch 30/50
183637/183637 - 822s - loss: 8.1627 - val_loss: 6.4804

=> 8 | 6.5 after 30 epochs (Best results)


[learning_rate=0.002] [random 20% of the data] [slurm-29394014.out]

Epoch 1/50
183637/183637 - 757s - loss: 13.5946 - val_loss: 12.2283
Epoch 2/50
183637/183637 - 742s - loss: 12.3760 - val_loss: 11.5238
Epoch 3/50
183637/183637 - 752s - loss: 12.1133 - val_loss: 11.9145
Epoch 4/50
183637/183637 - 751s - loss: 12.2358 - val_loss: 12.3770
Epoch 5/50
183637/183637 - 748s - loss: 11.9767 - val_loss: 12.8235
Epoch 6/50
183637/183637 - 735s - loss: 11.5789 - val_loss: 12.4735
Epoch 7/50
183637/183637 - 744s - loss: 11.6435 - val_loss: 12.9614
Epoch 8/50
183637/183637 - 738s - loss: 11.4981 - val_loss: 12.9668
Epoch 9/50
183637/183637 - 745s - loss: 11.5430 - val_loss: 13.0032
Epoch 10/50
183637/183637 - 743s - loss: 11.6272 - val_loss: 12.9969
Epoch 11/50
183637/183637 - 744s - loss: 11.4950 - val_loss: 12.9764
Epoch 12/50
183637/183637 - 744s - loss: 11.0699 - val_loss: 13.1366
Epoch 13/50
183637/183637 - 736s - loss: 11.1664 - val_loss: 12.9697
Epoch 14/50
183637/183637 - 743s - loss: 10.9648 - val_loss: 12.8885
Epoch 15/50
183637/183637 - 749s - loss: 11.0415 - val_loss: 12.3969
Epoch 16/50
183637/183637 - 751s - loss: 11.0588 - val_loss: 12.4346
Epoch 17/50
183637/183637 - 748s - loss: 11.1098 - val_loss: 12.2345
Epoch 18/50
183637/183637 - 738s - loss: 11.2081 - val_loss: 12.4445
Epoch 19/50
183637/183637 - 741s - loss: 11.0363 - val_loss: 12.6445
Epoch 20/50
183637/183637 - 744s - loss: 10.7930 - val_loss: 12.9560
Epoch 21/50
183637/183637 - 743s - loss: 10.9059 - val_loss: 12.8131
Epoch 22/50
183637/183637 - 748s - loss: 10.7046 - val_loss: 13.0105
Epoch 23/50
183637/183637 - 755s - loss: 10.7704 - val_loss: 13.2316
Epoch 24/50
183637/183637 - 745s - loss: 10.6238 - val_loss: 13.2263
Epoch 25/50
183637/183637 - 749s - loss: 10.5739 - val_loss: 12.9750
Epoch 26/50
183637/183637 - 736s - loss: 10.6344 - val_loss: 12.9609
Epoch 27/50
183637/183637 - 749s - loss: 10.7288 - val_loss: 13.0642
Epoch 28/50
183637/183637 - 746s - loss: 10.5731 - val_loss: 13.2335
Epoch 29/50
183637/183637 - 751s - loss: 10.5741 - val_loss: 13.1080
Epoch 30/50
183637/183637 - 750s - loss: 10.4327 - val_loss: 12.5024
Epoch 31/50
183637/183637 - 745s - loss: 10.3750 - val_loss: 12.7573
Epoch 32/50
183637/183637 - 744s - loss: 10.4367 - val_loss: 12.4026
Epoch 33/50
183637/183637 - 751s - loss: 10.4124 - val_loss: 12.4783
Epoch 34/50
183637/183637 - 752s - loss: 10.1386 - val_loss: 12.3332
Epoch 35/50
183637/183637 - 743s - loss: 10.1201 - val_loss: 12.2014
Epoch 36/50
183637/183637 - 745s - loss: 10.2870 - val_loss: 12.2295
Epoch 37/50
183637/183637 - 752s - loss: 10.1657 - val_loss: 12.2621
Epoch 38/50
183637/183637 - 740s - loss: 10.3750 - val_loss: 12.3749
Epoch 39/50
183637/183637 - 743s - loss: 10.2436 - val_loss: 12.0313
Epoch 40/50
183637/183637 - 751s - loss: 10.2377 - val_loss: 11.8835
Epoch 41/50
183637/183637 - 742s - loss: 10.2030 - val_loss: 11.6788
Epoch 42/50
183637/183637 - 745s - loss: 10.0858 - val_loss: 11.7444
Epoch 43/50
183637/183637 - 739s - loss: 10.3851 - val_loss: 11.6738
Epoch 44/50
183637/183637 - 741s - loss: 10.4418 - val_loss: 11.4959
Epoch 45/50
183637/183637 - 737s - loss: 10.3226 - val_loss: 11.6252
Epoch 46/50
183637/183637 - 746s - loss: 10.3123 - val_loss: 11.1069
Epoch 47/50
183637/183637 - 750s - loss: 10.2876 - val_loss: 11.2703
Epoch 48/50
183637/183637 - 751s - loss: 10.3224 - val_loss: 10.8999
Epoch 49/50
183637/183637 - 740s - loss: 10.3253 - val_loss: 10.6191
Epoch 50/50
183637/183637 - 746s - loss: 10.1841 - val_loss: 10.7283

=> 10 | 12.5 after 30 epochs


[learning_rate=0.005] [random 20% of the data]

Epoch 1/50
183637/183637 - 732s - loss: 10.9502 - val_loss: 15.6142
Epoch 2/50
183637/183637 - 642s - loss: 9.7445 - val_loss: 12.4443
Epoch 3/50
183637/183637 - 787s - loss: 9.6342 - val_loss: 11.7503
Epoch 4/50
183637/183637 - 810s - loss: 9.5967 - val_loss: 11.3419
Epoch 5/50
183637/183637 - 817s - loss: 9.5830 - val_loss: 11.3365
Epoch 6/50
183637/183637 - 812s - loss: 9.6685 - val_loss: 10.6511
Epoch 7/50
183637/183637 - 806s - loss: 9.2464 - val_loss: 10.5787
Epoch 8/50
183637/183637 - 809s - loss: 9.1812 - val_loss: 9.8700
Epoch 9/50
183637/183637 - 810s - loss: 9.2207 - val_loss: 9.1028
Epoch 10/50
183637/183637 - 810s - loss: 9.5843 - val_loss: 9.1443
Epoch 11/50
183637/183637 - 812s - loss: 9.1157 - val_loss: 9.1664
Epoch 12/50
183637/183637 - 810s - loss: 8.9596 - val_loss: 8.9422
Epoch 13/50
183637/183637 - 813s - loss: 8.8706 - val_loss: 9.0864
Epoch 14/50
183637/183637 - 815s - loss: 8.6347 - val_loss: 9.4246
Epoch 15/50
183637/183637 - 815s - loss: 8.9235 - val_loss: 9.2906
Epoch 16/50
183637/183637 - 808s - loss: 8.8106 - val_loss: 9.5444
Epoch 17/50
183637/183637 - 810s - loss: 8.8119 - val_loss: 9.0843
Epoch 18/50
183637/183637 - 803s - loss: 8.5756 - val_loss: 8.7515
Epoch 19/50
183637/183637 - 814s - loss: 8.5134 - val_loss: 8.6090
Epoch 20/50
183637/183637 - 814s - loss: 8.4880 - val_loss: 8.4379
Epoch 21/50
183637/183637 - 809s - loss: 8.3170 - val_loss: 8.3494
Epoch 22/50
183637/183637 - 810s - loss: 8.1918 - val_loss: 8.4931
Epoch 23/50
183637/183637 - 810s - loss: 8.3219 - val_loss: 8.6941
Epoch 24/50
183637/183637 - 813s - loss: 8.2540 - val_loss: 8.8836
Epoch 25/50
183637/183637 - 812s - loss: 7.8784 - val_loss: 8.2725
Epoch 26/50
183637/183637 - 804s - loss: 8.0217 - val_loss: 8.0233
Epoch 27/50
183637/183637 - 809s - loss: 8.1523 - val_loss: 8.6410
Epoch 28/50
183637/183637 - 814s - loss: 8.0428 - val_loss: 8.7339
Epoch 29/50
183637/183637 - 813s - loss: 8.0827 - val_loss: 8.4088
Epoch 30/50
183637/183637 - 811s - loss: 8.0120 - val_loss: 8.3171
Epoch 31/50
183637/183637 - 807s - loss: 8.0818 - val_loss: 8.1128
Epoch 32/50
183637/183637 - 809s - loss: 7.9360 - val_loss: 9.3634

=> 8 | 8.3 after 30 epochs


[learning_rate=0.01] [random 20% of the data]

Epoch 1/50
183637/183637 - 722s - loss: 7.9171 - val_loss: 8.6206
Epoch 2/50
183637/183637 - 717s - loss: 7.8110 - val_loss: 8.3396
Epoch 3/50
183637/183637 - 712s - loss: 7.8306 - val_loss: 8.4691
Epoch 4/50
183637/183637 - 718s - loss: 7.6692 - val_loss: 8.3561
Epoch 5/50
183637/183637 - 715s - loss: 8.0802 - val_loss: 8.1328
Epoch 6/50
183637/183637 - 716s - loss: 7.6834 - val_loss: 7.9263
Epoch 7/50
183637/183637 - 716s - loss: 7.9309 - val_loss: 7.8658
Epoch 8/50
183637/183637 - 715s - loss: 7.7766 - val_loss: 7.5344
Epoch 9/50
183637/183637 - 721s - loss: 7.6496 - val_loss: 7.4792
Epoch 10/50
183637/183637 - 715s - loss: 7.8282 - val_loss: 7.6029
Epoch 11/50
183637/183637 - 712s - loss: 7.8102 - val_loss: 7.6815
Epoch 12/50
183637/183637 - 713s - loss: 7.7461 - val_loss: 7.7624
Epoch 13/50
183637/183637 - 716s - loss: 7.8401 - val_loss: 7.7964
Epoch 14/50
183637/183637 - 710s - loss: 7.6786 - val_loss: 7.8625
Epoch 15/50
183637/183637 - 721s - loss: 7.8637 - val_loss: 7.5940
Epoch 16/50
183637/183637 - 718s - loss: 7.8120 - val_loss: 7.6749
Epoch 17/50
183637/183637 - 716s - loss: 7.9516 - val_loss: 7.8080
Epoch 18/50
183637/183637 - 718s - loss: 8.1549 - val_loss: 7.7219
Epoch 19/50
183637/183637 - 713s - loss: 8.1956 - val_loss: 7.8126
Epoch 20/50
183637/183637 - 714s - loss: 7.8004 - val_loss: 7.9925
Epoch 21/50
183637/183637 - 719s - loss: 7.8941 - val_loss: 7.8932
Epoch 22/50
183637/183637 - 714s - loss: 8.0503 - val_loss: 7.9518
Epoch 23/50
183637/183637 - 713s - loss: 7.7034 - val_loss: 7.8450

=> No training after first epoch

[learning_rate=0.1] [random 20% of the data] [slurm-29394013.out] 

Epoch 1/50
183637/183637 - 803s - loss: 12.8423 - val_loss: 11.7088
Epoch 2/50
183637/183637 - 776s - loss: 11.2223 - val_loss: 9.8968
Epoch 3/50
183637/183637 - 786s - loss: 10.0125 - val_loss: 9.9950
Epoch 4/50
183637/183637 - 777s - loss: 9.1151 - val_loss: 9.7154
Epoch 5/50
183637/183637 - 784s - loss: 8.5747 - val_loss: 8.9511
Epoch 6/50
183637/183637 - 781s - loss: 9.0766 - val_loss: 8.3027
Epoch 7/50
183637/183637 - 783s - loss: 8.6809 - val_loss: 8.3483
Epoch 8/50
183637/183637 - 783s - loss: 8.4704 - val_loss: 9.0376
Epoch 9/50
183637/183637 - 786s - loss: 8.5210 - val_loss: 9.1358
Epoch 10/50
183637/183637 - 773s - loss: 8.6302 - val_loss: 9.3824
Epoch 11/50
183637/183637 - 775s - loss: 8.2867 - val_loss: 9.2739
Epoch 12/50
183637/183637 - 776s - loss: 7.9462 - val_loss: 9.3471
Epoch 13/50
183637/183637 - 778s - loss: 7.9000 - val_loss: 9.3925
Epoch 14/50
183637/183637 - 779s - loss: 7.8415 - val_loss: 9.5605
Epoch 15/50
183637/183637 - 781s - loss: 8.0907 - val_loss: 9.2056
Epoch 16/50
183637/183637 - 779s - loss: 7.6937 - val_loss: 8.9994
Epoch 17/50
183637/183637 - 777s - loss: 7.5865 - val_loss: 8.6648
Epoch 18/50
183637/183637 - 778s - loss: 7.3558 - val_loss: 9.1029
Epoch 19/50
183637/183637 - 774s - loss: 7.3605 - val_loss: 9.1474
Epoch 20/50
183637/183637 - 783s - loss: 7.3044 - val_loss: 9.5332
Epoch 21/50
183637/183637 - 771s - loss: 7.3159 - val_loss: 9.2115
Epoch 22/50
183637/183637 - 780s - loss: 7.4826 - val_loss: 9.1880
Epoch 23/50
183637/183637 - 773s - loss: 7.4723 - val_loss: 9.3603
Epoch 24/50
183637/183637 - 777s - loss: 7.3770 - val_loss: 9.2375
Epoch 25/50
183637/183637 - 777s - loss: 7.5102 - val_loss: 9.4561
Epoch 26/50
183637/183637 - 778s - loss: 7.4700 - val_loss: 9.6289
Epoch 27/50
183637/183637 - 778s - loss: 7.4841 - val_loss: 9.1037
Epoch 28/50
183637/183637 - 772s - loss: 7.6005 - val_loss: 9.0144
Epoch 29/50
183637/183637 - 775s - loss: 7.3613 - val_loss: 9.0915
Epoch 30/50
183637/183637 - 790s - loss: 7.4593 - val_loss: 9.2989
Epoch 31/50
183637/183637 - 782s - loss: 7.6165 - val_loss: 8.9762
Epoch 32/50
183637/183637 - 774s - loss: 7.5491 - val_loss: 9.1474
Epoch 33/50
183637/183637 - 777s - loss: 7.5400 - val_loss: 9.1287
Epoch 34/50
183637/183637 - 780s - loss: 7.4235 - val_loss: 9.5455
Epoch 35/50
183637/183637 - 783s - loss: 7.6765 - val_loss: 9.1275
Epoch 36/50
183637/183637 - 787s - loss: 7.5261 - val_loss: 9.5722
Epoch 37/50
183637/183637 - 782s - loss: 7.3160 - val_loss: 9.7001
Epoch 38/50
183637/183637 - 777s - loss: 7.4574 - val_loss: 9.5040
Epoch 39/50
183637/183637 - 779s - loss: 7.4076 - val_loss: 9.3735
Epoch 40/50
183637/183637 - 773s - loss: 7.0935 - val_loss: 9.4288
Epoch 41/50
183637/183637 - 786s - loss: 7.3407 - val_loss: 9.3337
Epoch 42/50
183637/183637 - 780s - loss: 7.2281 - val_loss: 9.7706
Epoch 43/50
183637/183637 - 781s - loss: 7.3041 - val_loss: 9.9863
Epoch 44/50
183637/183637 - 778s - loss: 7.0604 - val_loss: 10.0660
Epoch 45/50
183637/183637 - 783s - loss: 7.1006 - val_loss: 9.6529
Epoch 46/50
183637/183637 - 782s - loss: 7.1634 - val_loss: 9.6957
Epoch 47/50
183637/183637 - 778s - loss: 7.3499 - val_loss: 9.2763
Epoch 48/50
183637/183637 - 773s - loss: 7.1750 - val_loss: 9.0168
Epoch 49/50
183637/183637 - 782s - loss: 7.0284 - val_loss: 9.3949
Epoch 50/50
183637/183637 - 773s - loss: 7.2193 - val_loss: 9.3970

=> Validation error never below 9