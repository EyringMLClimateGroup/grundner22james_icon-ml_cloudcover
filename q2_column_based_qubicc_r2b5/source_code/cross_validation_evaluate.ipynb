{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the cross-validation models\n",
    "\n",
    "Throws an error when run inside a slurm job:\n",
    "\n",
    "*QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-b309170'\n",
    "qt.qpa.screen: QXcbConnection: Could not connect to display mlogin103:31.0\n",
    "Could not connect to any X display.*\n",
    "\n",
    "-> This error happens inside save_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "#Import sklearn before tensorflow (static Thread-local storage)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "path = '/pf/b/b309170'\n",
    "sys.path.insert(0, path + '/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "import my_classes\n",
    "from my_classes import write_infofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Won't run on a CPU node\n",
    "try:\n",
    "    # Prevents crashes of the code\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "    # Allow the growth of memory Tensorflow allocates (limits memory usage overall)\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud Cover or Cloud Area?\n",
    "output_var = 'clc' # Set output_var to one of {'clc', 'cl_area'}\n",
    "# QUBICC only or QUBICC+NARVAL training data?\n",
    "qubicc_only = True\n",
    "# Do we evaluate a model trained on all data?\n",
    "all_data_model = False\n",
    "\n",
    "path_base = os.path.join(path, 'workspace_icon-ml/cloud_cover_parameterization/grid_column_based_QUBICC_R02B05')\n",
    "path_data = os.path.join(path, 'my_work/icon-ml_data/cloud_cover_parameterization/grid_column_based_QUBICC_R02B05/based_on_var_interpolated_data')\n",
    "\n",
    "if output_var == 'clc':\n",
    "    full_output_var_name = 'cloud_cover'\n",
    "elif output_var == 'cl_area':\n",
    "    full_output_var_name = 'cloud_area'\n",
    "    \n",
    "if qubicc_only:\n",
    "    output_folder = '%s_R2B5_QUBICC'%full_output_var_name\n",
    "else:\n",
    "    output_folder = '%s_R2B5_QUBICC+NARVAL'%full_output_var_name\n",
    "path_model = os.path.join(path_base, 'saved_models', output_folder)\n",
    "path_figures = os.path.join(path_base, 'figures', output_folder)\n",
    "narval_output_file = '%s_output_narval.npy'%full_output_var_name\n",
    "qubicc_output_file = '%s_output_qubicc.npy'%full_output_var_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1 = 'cross_validation_column_based_fold_1.h5'\n",
    "fold_2 = 'cross_validation_column_based_fold_2.h5'\n",
    "fold_3 = 'cross_validation_column_based_fold_3.h5'\n",
    "\n",
    "model_fold_1 = load_model(os.path.join(path_model, fold_1))\n",
    "model_fold_2 = load_model(os.path.join(path_model, fold_2))\n",
    "model_fold_3 = load_model(os.path.join(path_model, fold_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.concatenate((np.load(path_data + '/cloud_cover_input_narval.npy'), \n",
    "                             np.transpose(np.load(path_data + '/cloud_cover_input_qubicc.npy'))), axis=0)\n",
    "output_data = np.concatenate((np.load(os.path.join(path_data, narval_output_file)), \n",
    "                              np.transpose(np.load(os.path.join(path_data, qubicc_output_file)))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_narval = np.load(os.path.join(path_data, narval_output_file)).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(samples_total, no_of_features) = input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns that were constant in at least one of the training folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_fields = [27, 28, 29, 30, 31, 32, 135, 136, 137]\n",
    "assert no_of_features == 163\n",
    "input_data = np.delete(input_data, remove_fields, axis=1)\n",
    "no_of_features = no_of_features - len(remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define cross-validation folds to recreate training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 91933934  91933935  91933936 ... 120025759 120025760 120025761]\n",
      "[120025762 120025763 120025764 ... 148117587 148117588 148117589]\n",
      "[148117590 148117591 148117592 ... 176209415 176209416 176209417]\n"
     ]
    }
   ],
   "source": [
    "def set_training_validation_folds(samples_total, samples_narval):\n",
    "    training_folds = []\n",
    "    validation_folds = []\n",
    "    two_week_incr = (samples_total-samples_narval)//6\n",
    "\n",
    "    for i in range(3):\n",
    "        # Note that this is a temporal split since time was the first dimension in the original tensor\n",
    "        first_incr = np.arange(samples_narval+two_week_incr*i, samples_narval+two_week_incr*(i+1))\n",
    "        second_incr = np.arange(samples_narval+two_week_incr*(i+3), samples_narval+two_week_incr*(i+4))\n",
    "        \n",
    "        print(second_incr)\n",
    "\n",
    "        validation_folds.append(np.append(first_incr, second_incr))\n",
    "        training_folds.append(np.arange(samples_narval, samples_total))\n",
    "        training_folds[i] = np.setdiff1d(training_folds[i], validation_folds[i])\n",
    "        \n",
    "    return training_folds, validation_folds\n",
    "\n",
    "if qubicc_only:\n",
    "    # We have to skip the NARVAL data if we do qubicc_only\n",
    "    training_folds, validation_folds = set_training_validation_folds(samples_total, samples_narval)\n",
    "else:\n",
    "    training_folds, validation_folds = set_training_validation_folds(samples_total, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data will need to be scaled according to the training folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful functions to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_clc_per_vertical_layer(model, input_data, output_data, batch_size=2**20):\n",
    "    '''\n",
    "        Model prediction and the Ground Truth\n",
    "    '''\n",
    "    # output_var means for first model\n",
    "    clc_data_mean = []\n",
    "    for i in range(27):\n",
    "        clc_data_mean.append(np.mean(output_data[:, i], dtype=np.float64))\n",
    "    # Predicted output_var means\n",
    "#     # The batch predicting makes things faster, however, it can run into oom problems\n",
    "#     # Start with a large batch size and decrease it until it works\n",
    "#     for j in range(3):\n",
    "#         try:\n",
    "#             pred_adj = np.minimum(np.maximum(model.predict(input_valid, batch_size=batch_size//(8**j)), 0), 100)\n",
    "#             break\n",
    "#         except(ResourceExhaustedError):\n",
    "#             K.clear_session()\n",
    "#             gc.collect()\n",
    "#             print('Model predict did not work with a batch size of %d'%(batch_size//(8**j)))\n",
    "\n",
    "    # Curiously it works best if we use predict_on_batch on small subsets of the data instead of predict(..., batch_size=...) \n",
    "    # In future correct to: for i in range(1 + input_data.shape[0]//batch_size):\n",
    "    for i in range(input_data.shape[0]//batch_size): \n",
    "        if i == 0:\n",
    "            a = model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])\n",
    "        else:\n",
    "            a = np.concatenate((a, model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "    pred_adj = np.minimum(np.maximum(a, 0), 100) \n",
    "    \n",
    "    return list(np.mean(pred_adj, axis=0, dtype=np.float64)), clc_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figure(fig_name, fig_title, model_predictions, valid_means=None, all_data_model=False):\n",
    "    '''\n",
    "        Note that this figure truly is a different performance measure than the validation error.\n",
    "        The reason is that the mean can in principle be good even when the model is really bad.\n",
    "        \n",
    "        model_predictions: Array of length 3 or 4, covers predictions from all three folds for a given TL setup\n",
    "        valid_means: Array of length 3 or 4, covers validation means from all three folds for a given TL setup\n",
    "   '''\n",
    "#     assert len(model_biases) == 3\n",
    "    \n",
    "    # Vertical layers\n",
    "    a = np.linspace(5, 31, 27)\n",
    "    fig = plt.figure(figsize=(11,7))\n",
    "    # For model\n",
    "    ax = fig.add_subplot(111, xlabel='Mean %s'%output_var, ylabel='Vertical layer', title=fig_title)\n",
    "    \n",
    "    if all_data_model:    \n",
    "        if not valid_means[0] == valid_means[1] == valid_means[2]:\n",
    "            colors = ['g', 'b', 'r']\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a, colors[i])\n",
    "                if valid_means != None:\n",
    "                    ax.plot(valid_means[i], a, '%s--'%colors[i])\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Fold 1 Truth', 'Model Fold 2 Predictions', 'Fold 2 Truth', \n",
    "                       'Model Fold 3 Predictions', 'Fold 3 Truth', 'Model All Data Predictions', 'Truth'])\n",
    "        else:\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a)\n",
    "            ax.plot(valid_means[0], a, 'black')\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Model Fold 2 Predictions', 'Model Fold 3 Predictions', \n",
    "                       'Model All Data Predictions', 'Truth'])\n",
    "    else:\n",
    "        if not valid_means[0] == valid_means[1] == valid_means[2]:\n",
    "            colors = ['g', 'b', 'r']\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a, colors[i])\n",
    "                if valid_means != None:\n",
    "                    ax.plot(valid_means[i], a, '%s--'%colors[i])\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Fold 1 Truth', 'Model Fold 2 Predictions', 'Fold 2 Truth', \n",
    "                       'Model Fold 3 Predictions', 'Fold 3 Truth'])\n",
    "        else:\n",
    "            for i in range(len(model_predictions)):\n",
    "                ax.plot(model_predictions[i], a)\n",
    "            ax.plot(valid_means[0], a, 'black')\n",
    "            plt.gca().invert_yaxis()\n",
    "            ax.legend(['Model Fold 1 Predictions', 'Model Fold 2 Predictions', 'Model Fold 3 Predictions', \n",
    "                       'Truth'])\n",
    "\n",
    "    fig.savefig(os.path.join(path_figures, fig_name+'.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the models on the data\n",
    "\n",
    "Add training and validation losses to the text files. <br>\n",
    "Print results per vertical layer (respective validation set/NARVAL/QUBICC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = [] ; valid_losses = [] ; valid_means = [] ; valid_model_predictions = [] ;\n",
    "narval_means = [] ; narval_model_predictions = [] ; qubicc_means = [] ; qubicc_model_predictions = [] ;\n",
    "qubicc_month_0 = [] ; qubicc_model_pred_month_0 = [] ; qubicc_month_1 = [] ; qubicc_model_pred_month_1 = [] ;\n",
    "qubicc_month_2 = [] ; qubicc_model_pred_month_2 = [] ;\n",
    "\n",
    "for i in range(3): \n",
    "    filename = 'cross_validation_column_based_fold_%d'%(i+1)\n",
    "    # Choose appropriate model for this fold\n",
    "    if i == 0: model = model_fold_1\n",
    "    if i == 1: model = model_fold_2\n",
    "    if i == 2: model = model_fold_3\n",
    "    \n",
    "    #Standardize according to the fold\n",
    "    scaler.fit(input_data[training_folds[i]])\n",
    "    \n",
    "    #Load the data for the respective fold\n",
    "    input_train = scaler.transform(input_data[training_folds[i]])\n",
    "    input_valid = scaler.transform(input_data[validation_folds[i]])\n",
    "    output_train = output_data[training_folds[i]]\n",
    "    output_valid = output_data[validation_folds[i]]\n",
    "    \n",
    "    ## Training and validation losses\n",
    "    train_loss = model.evaluate(input_train, output_train, verbose=2, batch_size=10**5)\n",
    "    valid_loss = model.evaluate(input_valid, output_valid, verbose=2, batch_size=10**5)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_train, output_train\n",
    "    gc.collect()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "        file.write('Unbounded training loss: %.4f\\n'%(train_loss))\n",
    "        file.write('Unbounded validation loss: %.4f\\n'%(valid_loss))\n",
    "        \n",
    "    ## Compute mean cloud cover per vertical layer\n",
    "    # On the respective validation sets (QUBICC and NARVAL)\n",
    "    try:\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_valid, output_valid)\n",
    "    except(ResourceExhaustedError):\n",
    "        print('Resource Exhausted Qubicc')\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_valid, output_valid, \n",
    "                                                                   batch_size=2**15)\n",
    "    valid_means.append(clc_data_mean)\n",
    "    valid_model_predictions.append(clc_pred_mean)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_valid, output_valid\n",
    "    gc.collect()\n",
    "    \n",
    "    # For NARVAL\n",
    "    input_narval = scaler.transform(input_data[:samples_narval])\n",
    "    output_narval = output_data[:samples_narval]\n",
    "    try:\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_narval, output_narval)\n",
    "    except(ResourceExhaustedError):\n",
    "        print('Resource Exhausted Narval')\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_narval, output_narval, \n",
    "                                                                   batch_size=2**15)\n",
    "    narval_means.append(clc_data_mean)\n",
    "    narval_model_predictions.append(clc_pred_mean)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_narval, output_narval\n",
    "    gc.collect()\n",
    "    \n",
    "    # For QUBICC  \n",
    "    input_qubicc = scaler.transform(input_data[samples_narval:])\n",
    "    output_qubicc = output_data[samples_narval:]\n",
    "    try:\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc)\n",
    "    except(ResourceExhaustedError):\n",
    "        print('Resource Exhausted Qubicc')\n",
    "        clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc, \n",
    "                                                                   batch_size=2**15)\n",
    "    qubicc_means.append(clc_data_mean)\n",
    "    qubicc_model_predictions.append(clc_pred_mean)\n",
    "    \n",
    "    # Clear up some memory\n",
    "    del input_qubicc, output_qubicc\n",
    "    gc.collect()\n",
    "    \n",
    "    # QUBICC months\n",
    "    qubicc_month = (samples_total - samples_narval)//3\n",
    "    for month in range(3):\n",
    "        first_ind = samples_narval + month*qubicc_month\n",
    "        last_ind = samples_narval + (month+1)*qubicc_month\n",
    "        input_qubicc = scaler.transform(input_data[first_ind:last_ind])\n",
    "        output_qubicc = output_data[first_ind:last_ind]\n",
    "        try:\n",
    "            clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc)\n",
    "        except(ResourceExhaustedError):\n",
    "            print('Resource Exhausted Qubicc')\n",
    "            clc_pred_mean, clc_data_mean = mean_clc_per_vertical_layer(model, input_qubicc, output_qubicc, \n",
    "                                                                       batch_size=2**15)\n",
    "        if month==0: \n",
    "            qubicc_month_0.append(clc_data_mean)\n",
    "            qubicc_model_pred_month_0.append(clc_pred_mean)\n",
    "        if month==1:\n",
    "            qubicc_month_1.append(clc_data_mean)\n",
    "            qubicc_model_pred_month_1.append(clc_pred_mean)\n",
    "        if month==2:\n",
    "            qubicc_month_2.append(clc_data_mean)\n",
    "            qubicc_model_pred_month_2.append(clc_pred_mean)\n",
    "\n",
    "    # Clear up some memory\n",
    "    del input_qubicc, output_qubicc\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot results\n",
    "save_figure('cross_validation_validation_means', 'Column-based models on the respective validation sets', \n",
    "            valid_model_predictions, valid_means, all_data_model)\n",
    "save_figure('cross_validation_narval', 'Column-based models on the NARVAL data', \n",
    "            narval_model_predictions, narval_means, all_data_model)\n",
    "save_figure('cross_validation_qubicc', 'Column-based models on the QUBICC data', \n",
    "            qubicc_model_predictions, qubicc_means, all_data_model)\n",
    "# Qubicc months (I checked below that the order is hc2, then hc3, then hc4.)\n",
    "save_figure('cross_validation_qubicc_hc2', 'Column-based models on the QUBICC data, November 2004', \n",
    "            qubicc_model_pred_month_0, qubicc_month_0, all_data_model)\n",
    "save_figure('cross_validation_qubicc_hc3', 'Column-based models on the QUBICC data, April 2005', \n",
    "            qubicc_model_pred_month_1, qubicc_month_1, all_data_model)\n",
    "save_figure('cross_validation_qubicc_hc4', 'Column-based models on the QUBICC data, November 2005', \n",
    "            qubicc_model_pred_month_2, qubicc_month_2, all_data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we want to reproduce the plots without running everything again:\n",
    "with open(os.path.join(path_figures, 'values_for_figures.txt'), 'w') as file:\n",
    "    file.write('On validation sets\\n')\n",
    "    file.write(str(valid_means))\n",
    "    file.write(str(valid_model_predictions))\n",
    "    file.write('\\n\\nNARVAL data\\n')\n",
    "    file.write(str(narval_means))\n",
    "    file.write(str(narval_model_predictions))\n",
    "    file.write('\\n\\nQubicc data\\n')\n",
    "    file.write(str(qubicc_means))\n",
    "    file.write(str(qubicc_model_predictions))\n",
    "    file.write('\\n\\nQubicc data, November 2004\\n')\n",
    "    file.write(str(qubicc_month_0))\n",
    "    file.write(str(qubicc_model_pred_month_0))\n",
    "    file.write('\\n\\nQubicc data, April 2005\\n')\n",
    "    file.write(str(qubicc_month_1))\n",
    "    file.write(str(qubicc_model_pred_month_1))\n",
    "    file.write('\\n\\nQubicc data, November 2005\\n')\n",
    "    file.write(str(qubicc_month_2))\n",
    "    file.write(str(qubicc_model_pred_month_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The QUBICC data is loaded in the order that I would expect (hc2, then hc3, then hc4)\n",
    "\n",
    "path = '/pf/b/b309170/my_work/QUBICC/data_var_vertinterp_R02B05/'\n",
    "resolution = 'R02B05'\n",
    "\n",
    "# Order of experiments\n",
    "DS = xr.open_mfdataset(path+'hus/*'+resolution+'.nc', combine='by_coords')\n",
    "print(DS.time[0*len(DS.time)//3])\n",
    "print(DS.time[1*len(DS.time)//3])\n",
    "print(DS.time[2*len(DS.time)//3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute bounded losses\n",
    "\n",
    "We also save the scaling parameters for the fold-based models as we haven't done that yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes long!\n",
    "def compute_bounded_loss(model, input_data, output_data, batch_size=2**20):\n",
    "    for i in range(1 + input_data.shape[0]//batch_size): \n",
    "        if i == 0:\n",
    "            a = model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])\n",
    "        else:\n",
    "            a = np.concatenate((a, model.predict_on_batch(input_data[i*batch_size:(i+1)*batch_size])), axis=0)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "    pred_adj = np.minimum(np.maximum(a, 0), 100)\n",
    "    \n",
    "    # Mean Squared Error\n",
    "    return np.mean((pred_adj - output_data)**2, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "seed = 10\n",
    "\n",
    "for i in range(3): # for i in range(3): \n",
    "    filename = 'cross_validation_column_based_fold_%d'%(i+1)\n",
    "    # Choose appropriate model for this fold\n",
    "    if i == 0: model = model_fold_1\n",
    "    if i == 1: model = model_fold_2\n",
    "    if i == 2: model = model_fold_3\n",
    "        \n",
    "    #Standardize according to the fold\n",
    "    scaler.fit(input_data[training_folds[i]])\n",
    "    \n",
    "#     # We save the scaling parameters in a file [only once]\n",
    "#     seed_i = int(str(seed) + str(i))\n",
    "#     with open(path_model+'/scaler_%d.txt'%seed_i, 'a') as file:\n",
    "#         file.write('Standard Scaler mean values:\\n')\n",
    "#         file.write(str(scaler.mean_))\n",
    "#         file.write('\\nStandard Scaler standard deviation:\\n')\n",
    "#         file.write(str(np.sqrt(scaler.var_)))\n",
    "        \n",
    "#     # Define remove_fields\n",
    "#     remove_fields = [27, 28, 29, 30, 31, 32, 135, 136, 137]\n",
    "\n",
    "#     # Taken from preprocessing_narval\n",
    "#     input_variables = []\n",
    "#     variables = ['qv', 'qc', 'qi', 'temp', 'pres', 'zg']\n",
    "#     for el in variables:\n",
    "#         for i in range(21, 48):\n",
    "#             input_variables.append(el+'_%d'%i)\n",
    "#     input_variables.append('fr_land')\n",
    "\n",
    "#     in_and_out_variables = input_variables.copy()\n",
    "#     variables = [output_var]\n",
    "#     for el in variables:\n",
    "#         for i in range(21, 48):\n",
    "#             in_and_out_variables.append(el+'_%d'%i)\n",
    "        \n",
    "#     in_and_out_variables = np.delete(in_and_out_variables, remove_fields)\n",
    "#     input_variables = np.delete(input_variables, remove_fields)\n",
    "\n",
    "#     # Write the accompanying info-file [only once]\n",
    "#     with open(os.path.join(path_model, filename + '.txt'), 'a') as file:\n",
    "#         write_infofile(file, str(in_and_out_variables), str(input_variables), path_model, path_data, seed_i)\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    #Load the data for the respective fold\n",
    "    input_train = scaler.transform(input_data[training_folds[i]])\n",
    "    input_valid = scaler.transform(input_data[validation_folds[i]])\n",
    "    output_train = output_data[training_folds[i]]\n",
    "    output_valid = output_data[validation_folds[i]]\n",
    "    \n",
    "    train_loss = compute_bounded_loss(model, input_train, output_train, batch_size=2**17)\n",
    "    valid_loss = compute_bounded_loss(model, input_valid, output_valid, batch_size=2**17)\n",
    "        \n",
    "    with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "        file.write('Bounded training loss: %.4f\\n'%(train_loss))\n",
    "        file.write('Bounded validation loss: %.4f\\n'%(valid_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds113_kernel",
   "language": "python",
   "name": "clouds113_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
