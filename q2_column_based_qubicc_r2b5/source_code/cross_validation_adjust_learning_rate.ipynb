{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to figure out the best learning rate for a batch size of 128**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran with 800GB (750GB should also be fine)\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "#Import sklearn before tensorflow (static Thread-local storage)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "t0 = time.time()\n",
    "path = '/pf/b/b309170'\n",
    "path_figures = path + '/workspace_icon-ml/cloud_cover_parameterization/grid_column_based_QUBICC_R02B05/figures'\n",
    "path_model = path + '/workspace_icon-ml/cloud_cover_parameterization/grid_column_based_QUBICC_R02B05/saved_models'\n",
    "path_data = path + '/my_work/icon-ml_data/cloud_cover_parameterization/grid_column_based_QUBICC_R02B05/based_on_var_interpolated_data'\n",
    "\n",
    "# Add path with my_classes to sys.path\n",
    "sys.path.insert(0, path + '/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "\n",
    "# Reloading custom file to incorporate changes dynamically\n",
    "import importlib\n",
    "import my_classes\n",
    "importlib.reload(my_classes)\n",
    "\n",
    "from my_classes import read_mean_and_std\n",
    "from my_classes import TimeOut\n",
    "\n",
    "# Minutes per fold\n",
    "# timeout = 710 ####\n",
    "timeout = 100 ##\n",
    "\n",
    "# For logging purposes\n",
    "days = 'all_days'\n",
    "\n",
    "# Maximum amount of epochs for each model\n",
    "epochs = 50\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# For store_mean_model_biases\n",
    "VERT_LAYERS = 31\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_visible_devices(gpus[3], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents crashes of the code\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Allow the growth of memory Tensorflow allocates (limits memory usage overall)\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_narval = np.load(path_data + '/cloud_cover_input_narval.npy')\n",
    "# input_qubicc = np.transpose(np.load(path_data + '/cloud_cover_input_qubicc.npy'))\n",
    "# output_narval = np.load(path_data + '/cloud_cover_output_narval.npy')\n",
    "# output_qubicc = np.transpose(np.load(path_data + '/cloud_cover_output_qubicc.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = np.concatenate(input_narval, input_qubicc)\n",
    "# output_data = np.concatenate(output_narval, output_qubicc)\n",
    "\n",
    "input_data = np.concatenate((np.load(path_data + '/cloud_cover_input_narval.npy'), \n",
    "                             np.load(path_data + '/cloud_cover_input_qubicc.npy')), axis=0)\n",
    "output_data = np.concatenate((np.load(path_data + '/cloud_cover_output_narval.npy'), \n",
    "                              np.load(path_data + '/cloud_cover_output_qubicc.npy')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176291940, 163)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(samples_total, no_of_features) = input_data.shape\n",
    "(samples_total, no_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Temporal cross-validation*\n",
    "\n",
    "Split into 2-weeks increments (when working with 3 months of data). It's 25 day increments with 5 months of data. <br>\n",
    "1.: Validate on increments 1 and 4 <br>\n",
    "2.: Validate on increments 2 and 5 <br>\n",
    "3.: Validate on increments 3 and 6\n",
    "\n",
    "--> 2/3 training data, 1/3 validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folds = []\n",
    "validation_folds = []\n",
    "two_week_incr = samples_total//6\n",
    "\n",
    "for i in range(3):\n",
    "    # Note that this is a temporal split since time was the first dimension in the original tensor\n",
    "    first_incr = np.arange(samples_total//6*i, samples_total//6*(i+1))\n",
    "    second_incr = np.arange(samples_total//6*(i+3), samples_total//6*(i+4))\n",
    "\n",
    "    validation_folds.append(np.append(first_incr, second_incr))\n",
    "    training_folds.append(np.arange(samples_total))\n",
    "    training_folds[i] = np.delete(training_folds[i], validation_folds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that are constant in at least one of the training folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# This takes a bit of time\n",
    "remove_fields = []\n",
    "std_0 = np.std(input_data[training_folds[0]], axis=0)\n",
    "std_1 = np.std(input_data[training_folds[1]], axis=0)\n",
    "std_2 = np.std(input_data[training_folds[2]], axis=0)\n",
    "for i in range(no_of_features):\n",
    "    if std_0[i] == 0 or std_1[i] == 0 or std_2[i] == 0:\n",
    "        print(i)\n",
    "        remove_fields.append(i)\n",
    "\n",
    "# These features correspond to qc_4, qc_5, qc_6, qc_7, qc_8, qc_9, zg_4, zg_5, zg_6\n",
    "# remove_fields = [27, 28, 29, 30, 31, 32, 135, 136, 137]\n",
    "assert no_of_features == 163\n",
    "input_data = np.delete(input_data, remove_fields, axis=1)\n",
    "no_of_features = no_of_features - len(remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Useful functions to plot results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_mean_model_biases(input_valid, output_valid):\n",
    "    '''\n",
    "        Model prediction minus Ground Truth\n",
    "    '''\n",
    "    # Cloud cover means for first model\n",
    "    clc_data_mean = []\n",
    "    for i in range(VERT_LAYERS-4):\n",
    "        clc_data_mean.append(np.mean(output_valid[:, i]))\n",
    "    # Predicted cloud cover means\n",
    "    pred_adj = np.minimum(np.maximum(model.predict(input_valid, batch_size=10**5), 0), 100)\n",
    "    return (np.mean(pred_adj, axis=0) - clc_data_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figure(fig_name, model_biases):\n",
    "    '''\n",
    "        Note that this figure truly is a different performance measure than the validation error.\n",
    "        The reason is that the mean can in principle be good even when the model is really bad.\n",
    "        \n",
    "        model_bias: Array of length 3, covers biases from all three folds for a given TL setup\n",
    "    '''\n",
    "#     assert len(model_biases) == 3\n",
    "    \n",
    "    # Vertical layers\n",
    "    a = np.linspace(5, 31, 27)\n",
    "    fig = plt.figure(figsize=(7,4))\n",
    "    # For model\n",
    "    ax = fig.add_subplot(111, xlabel='Mean Cloud Cover', ylabel='Vertical layer', \n",
    "                           title='Cloud cover bias of the transfer-learned model on the validation set')\n",
    "    for i in range(len(model_biases)):\n",
    "        ax.plot(model_biases[i], a)\n",
    "    ax.plot(0*a, a, 'g--')\n",
    "    # ax_1.plot(clc_data_mean, a)\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.legend(['Fold 1', 'Fold 2', 'Fold 3'])\n",
    "    fig.savefig(os.path.join(path_figures, fig_name+'.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function for the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function for the last layer\n",
    "def my_act_fct(x):\n",
    "    return K.minimum(K.maximum(x, 0), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(256, activation='relu', input_dim = no_of_features),\n",
    "                tf.keras.layers.Dense(256, activation='relu'),\n",
    "                tf.keras.layers.Dense(27, activation=my_act_fct, dtype='float32'),\n",
    "            ],\n",
    "            name=\"column_based_model\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepping down on the ladder of complexity\n",
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        super(CustomModel, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    # Call accepts only tf.tensors\n",
    "    def call(self, x):\n",
    "        return self.model(x)  \n",
    "    \n",
    "    # Compile with XLA (throws an error)\n",
    "    # @tf.function(experimental_compile=True)\n",
    "#     @tf.function\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x,y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.loss_fn(y, y_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    # Without the test step, our model would yield 0 in every kind of evaluation outside training itself\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_pred = self(x, training=False)\n",
    "        # Updates the metrics tracking the loss\n",
    "        loss = self.loss_fn(y, y_pred)\n",
    "        # Update the metrics.\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {'loss': loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, set batchsize to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize according to the fold\n",
    "i = 0\n",
    "scaler.fit(input_data[training_folds[i],:])\n",
    "\n",
    "#Load the data for the respective fold and convert it to tf data\n",
    "input_train = scaler.transform(input_data[training_folds[i],:])    \n",
    "# Use a batchsize of 64 or 128\n",
    "train_ds = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(input_train), \n",
    "                            tf.data.Dataset.from_tensor_slices(output_data[training_folds[i]]))) \\\n",
    "            .batch(batch_size=128, drop_remainder=True).prefetch(1)\n",
    "\n",
    "# Possibly better to use .apply(tf.data.experimental.copy_to_device(\"/gpu:0\")) before prefetch\n",
    "\n",
    "input_valid = scaler.transform(input_data[validation_folds[i],:])\n",
    "\n",
    "output_train = output_data[training_folds[i],:]\n",
    "output_valid = output_data[validation_folds[i],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Testing different learning rates\n",
    "How about we take a random subset of the data. We assume a high spatio-temporal correlation between data samples anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_subset(df, df_out, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    test_set_size = int(len(df)*test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return df[test_indices], df_out[test_indices]\n",
    "    \n",
    "input_train_subset, output_train_subset = take_subset(input_train, output_train, 0.2)\n",
    "input_valid_subset, output_valid_subset = take_subset(input_valid, output_valid, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_subset = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(input_train_subset), \n",
    "                            tf.data.Dataset.from_tensor_slices(output_train_subset))) \\\n",
    "            .batch(batch_size=128, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "918187/918187 - 3714s - loss: 47.8648 - val_loss: 2.7655\n",
      "Epoch 2/2\n",
      "918187/918187 - 3667s - loss: 38.2740 - val_loss: 4.2590\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate=0.002\n",
    "\n",
    "model = CustomModel(model_structure)\n",
    "\n",
    "#Feed the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss_fn=tf.keras.losses.MeanSquaredError()\n",
    ")\n",
    "\n",
    "# Batch size is specified by the tf dataset\n",
    "history = model.fit(train_ds_subset, epochs=50, verbose=2,\n",
    "                    validation_data=(input_valid_subset, output_valid_subset)) ##\n",
    "#     history = model.fit(train_ds, epochs=epochs, validation_data=valid_ds, callbacks=[time_callback])\n",
    "\n",
    "# #Save the output\n",
    "# train_loss = model.evaluate(input_train, output_train, verbose=2, batch_size=2000)\n",
    "# valid_loss = model.evaluate(input_valid, output_valid, verbose=2, batch_size=1000)\n",
    "# (train_loss, valid_loss)\n",
    "\n",
    "# with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "#         file.write('Results from the %d-th fold\\n'%(i+1))\n",
    "#         file.write('Training loss: %.4f\\n'%(train_loss))\n",
    "#         file.write('Validation loss: %.4f\\n'%(valid_loss))\n",
    "#         file.write('Training epochs: %d\\n'%(len(history.history['val_loss'])))\n",
    "#         file.write('Weights restored from epoch: %d\\n\\n'%(1+np.argmin(history.history['val_loss'])))\n",
    "# model_bias.append(store_mean_model_biases(input_valid, output_valid))\n",
    "\n",
    "# # Save bias plot\n",
    "# save_figure(fig_name='cross_validation_results_%s'%days, model_biases=model_bias)\n",
    "\n",
    "#Plotting the training progress\n",
    "if len(history.history['loss']) > len(history.history['val_loss']):\n",
    "    del history.history['loss'][-1]\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.savefig(os.path.join(path_figures, \n",
    "                         'test_learning_rate_%.4f.pdf'%(learning_rate)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.00005\n",
    "\n",
    "model = CustomModel(model_structure)\n",
    "\n",
    "#Feed the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss_fn=tf.keras.losses.MeanSquaredError()\n",
    ")\n",
    "\n",
    "# Batch size is specified by the tf dataset\n",
    "history = model.fit(train_ds, epochs=30, verbose=2,\n",
    "                    validation_data=(input_valid, output_valid))\n",
    "#     history = model.fit(train_ds, epochs=epochs, validation_data=valid_ds, callbacks=[time_callback])\n",
    "\n",
    "# #Save the output\n",
    "# train_loss = model.evaluate(input_train, output_train, verbose=2, batch_size=2000)\n",
    "# valid_loss = model.evaluate(input_valid, output_valid, verbose=2, batch_size=1000)\n",
    "# (train_loss, valid_loss)\n",
    "\n",
    "# with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "#         file.write('Results from the %d-th fold\\n'%(i+1))\n",
    "#         file.write('Training loss: %.4f\\n'%(train_loss))\n",
    "#         file.write('Validation loss: %.4f\\n'%(valid_loss))\n",
    "#         file.write('Training epochs: %d\\n'%(len(history.history['val_loss'])))\n",
    "#         file.write('Weights restored from epoch: %d\\n\\n'%(1+np.argmin(history.history['val_loss'])))\n",
    "# model_bias.append(store_mean_model_biases(input_valid, output_valid))\n",
    "\n",
    "# # Save bias plot\n",
    "# save_figure(fig_name='cross_validation_results_%s'%days, model_biases=model_bias)\n",
    "\n",
    "#Plotting the training progress\n",
    "if len(history.history['loss']) > len(history.history['val_loss']):\n",
    "    del history.history['loss'][-1]\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Number of epochs')\n",
    "# plt.savefig(os.path.join(path_figures, \n",
    "#                          'cross_validation_column_based_training_%s_fold_%d.pdf'%(days,i)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "\n",
    "model = CustomModel(model_structure)\n",
    "\n",
    "#Feed the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss_fn=tf.keras.losses.MeanSquaredError()\n",
    ")\n",
    "\n",
    "# Batch size is specified by the tf dataset\n",
    "history = model.fit(train_ds, epochs=30, verbose=2,\n",
    "                    validation_data=(input_valid, output_valid))\n",
    "#     history = model.fit(train_ds, epochs=epochs, validation_data=valid_ds, callbacks=[time_callback])\n",
    "\n",
    "# #Save the output\n",
    "# train_loss = model.evaluate(input_train, output_train, verbose=2, batch_size=2000)\n",
    "# valid_loss = model.evaluate(input_valid, output_valid, verbose=2, batch_size=1000)\n",
    "# (train_loss, valid_loss)\n",
    "\n",
    "# with open(os.path.join(path_model, filename+'.txt'), 'a') as file:\n",
    "#         file.write('Results from the %d-th fold\\n'%(i+1))\n",
    "#         file.write('Training loss: %.4f\\n'%(train_loss))\n",
    "#         file.write('Validation loss: %.4f\\n'%(valid_loss))\n",
    "#         file.write('Training epochs: %d\\n'%(len(history.history['val_loss'])))\n",
    "#         file.write('Weights restored from epoch: %d\\n\\n'%(1+np.argmin(history.history['val_loss'])))\n",
    "# model_bias.append(store_mean_model_biases(input_valid, output_valid))\n",
    "\n",
    "# # Save bias plot\n",
    "# save_figure(fig_name='cross_validation_results_%s'%days, model_biases=model_bias)\n",
    "\n",
    "#Plotting the training progress\n",
    "if len(history.history['loss']) > len(history.history['val_loss']):\n",
    "    del history.history['loss'][-1]\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Number of epochs')\n",
    "# plt.savefig(os.path.join(path_figures, \n",
    "#                          'cross_validation_column_based_training_%s_fold_%d.pdf'%(days,i)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds113_kernel",
   "language": "python",
   "name": "clouds113_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
