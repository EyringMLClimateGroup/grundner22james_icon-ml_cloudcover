{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical interpolation\n",
    "\n",
    "Applied to horizontally coarse-grained data\n",
    "\n",
    "**Why is linear interpolation insufficient?** <br>\n",
    "Assume z_ifc_highres = \\[0,1,2,3\\] and z_ifc_lowres = \\[0, 3\\]. <br>\n",
    "Assume clc_highres = \\[0, 100, 0\\] (is defined on full levels). After linear interpolation to the full level at a height of 1.5 we get clc_lowres = \\[100\\].\n",
    "\n",
    "Now what we want is actually clc_lowres = \\[33.33\\] as an average/integral over the high-res grid cells. <br>\n",
    "Note that for instance for z_ifc_highres = \\[0,1,2\\] and z_ifc_lowres = \\[0, 2\\], clc_highres = \\[0, 100\\] we'd get clc_lowres = \\[50\\] for both methods.\n",
    "\n",
    "Let $\\mathcal{G}$ be an arbitrary low-res grid cell with z(upper half level) $ = z_u$ and z(lower half level) $ =  z_l$.\n",
    "\n",
    "Our goal is to compute $x(\\mathcal{G}) = \\frac{1}{z_u-z_l}\\int_{z_l}^{z_u} \\hat{x}$\n",
    "\n",
    "as the coarse-grained variable $x(\\mathcal{G})$. We integrate over the high-res variables $\\hat{x}$. <br>\n",
    "Let $\\{\\mathcal{H}_i\\}_{i=1}^n$ be the high-res grid cells, where $z_u \\geq \\hat{z}^i_l \\geq z_l$ or $z_u \\geq \\hat{z}^i_u \\geq z_l$. Here $\\hat{z}^i_l$ and $\\hat{z}^i_u$ is the lower/upper half level of $\\mathcal{H}_i$.\n",
    "Then $\\int_{z_u}^{z_l} \\hat{x} = \\sum_{i=1}^n \\hat{x}(\\mathcal{H}_i) (min(z_u, \\hat{z}^i_u) - max(z_l, \\hat{z}^i_l))$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load the data we want to interpolate vertically (Define the path, load all high-res and low-res half levels)\n",
    "# 2) Compute the coarse-grained versions.\n",
    "# 3) Save the output as a netcdf-file.\n",
    "\n",
    "# Note: Be careful with NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clc_R02B04_NARVALI_2013120800_cloud_DOM01_0029.nc\n"
     ]
    }
   ],
   "source": [
    "# Define all paths\n",
    "narval_path = '/pf/b/b309170/my_work/NARVAL'\n",
    "clc_path = os.path.join(narval_path, 'data/clc')\n",
    "output_path = os.path.join(narval_path, 'data_var_vertinterp/clc')\n",
    "zg_lowres_path = os.path.join(narval_path, 'data_var_vertinterp/zg')\n",
    "zg_highres_path = os.path.join(narval_path, 'data/z_ifc')\n",
    "\n",
    "# Which file to load\n",
    "input_file = os.listdir(clc_path)[0]\n",
    "print(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1699"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(clc_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files (ds_zh_lr = ds_zhalf_lowres)\n",
    "ds = xr.open_dataset(os.path.join(clc_path, input_file))\n",
    "ds_zh_lr = xr.open_dataset(os.path.join(zg_lowres_path, 'zghalf_icon-a_capped.nc'))\n",
    "ds_zh_hr = xr.open_dataset(os.path.join(zg_highres_path, 'z_ifc_R02B04_NARVALI_fg_DOM01.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 75, 20480)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract values\n",
    "clc = ds.clc.values\n",
    "zh_lr = ds_zh_lr.zghalf.values\n",
    "zh_hr = ds_zh_hr.z_ifc.values\n",
    "clc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract not-nan entries (clc_n = clc_notnan)\n",
    "not_nan = ~np.isnan(clc[0,74,:])\n",
    "clc_n = clc[:,:,not_nan]\n",
    "zh_lr_n = zh_lr[:,not_nan]\n",
    "zh_hr_n = zh_hr[:,not_nan]\n",
    "# print(zh_lr_n.shape)\n",
    "# print(zh_hr_n.shape)\n",
    "# clc_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306\n"
     ]
    }
   ],
   "source": [
    "# Modify the ndarray. Desired output shape: (1, 31, 1306). (clc_out = clc, vertically interpolated)\n",
    "clc_out = np.full((1, 31, 1306), np.nan)\n",
    "\n",
    "# Pseuodocode:\n",
    "# For every horizontal field i: <-- Maybe we can slice over the horizontal fields\n",
    "# For every layer j:\n",
    "# Set z_u=zh_lr_n[j, i] and z_l=zh_lr_n[j+1, i] <-- Define z_u and z_l, as encompassing layer j\n",
    "# Collect all k with z_l <= zh_hr_n[k,i] <= z_u <-- Get all high-res half-level in between z_l and z_u\n",
    "# sum += (np.minimum(z_u, zh_hr_n[k,i]) - np.maximum(zh_hr_n[k+1,i], z_l))*clc[0, k, i] over all k\n",
    "# clc_out[0, j, k] = sum/(z_u - z_l)\n",
    "\n",
    "# Pretty fast implementation:\n",
    "for j in range(1):\n",
    "    z_u = zh_lr_n[j, :]\n",
    "    z_l = zh_lr_n[j+1, :]\n",
    "    weights = np.maximum(np.minimum(z_u, zh_hr_n[:-1]) - np.maximum(zh_hr_n[1:], z_l), 0)\n",
    "    \n",
    "#     Equivalent to clc_out[0,j,:] = np.diagonal(weights.T @ clc_n[0])/(z_u - z_l), only much faster:\n",
    "    clc_out[0,j,:] = np.einsum('ij,ji->i', weights.T, clc_n[0])/(z_u - z_l)\n",
    "    \n",
    "    print(len((z_u - z_l)))\n",
    "    \n",
    "    # If the low-dim grid extends farther than the high-dim grid, we reinsert nans:\n",
    "    should_be_nan = np.where(np.abs((z_u - z_l) - np.sum(weights, axis = 0)) >= 0.5)\n",
    "    clc_out[0,j,should_be_nan] = np.full(len(should_be_nan), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it back in\n",
    "clc_new = np.full((1, 31, 20480), np.nan)\n",
    "clc_new[:,:,not_nan] = clc_out\n",
    "clc_new_da = xr.DataArray(clc_new, coords={'time':ds.time, 'lon':ds.clon, 'lat':ds.clat, 'height':ds.height[:31]}, \n",
    "                          dims=['time', 'height', 'cell'], name='clc') \n",
    "\n",
    "# Save it in a new file\n",
    "output_file = 'int_var_' + input_file\n",
    "clc_new_da.to_netcdf(os.path.join(output_path, output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING\n",
    "As a first test I compared the means, max/means with the linearly interpolated data to see if they are close. <br>\n",
    "As a second test I compare the vertically interpolated cloud cover for an arbitrary data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372.3834956168473"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arbitrary data point\n",
    "k = 24\n",
    "l = 700\n",
    "\n",
    "z_u = zh_lr_n[k, l] #1674.72\n",
    "z_l = zh_lr_n[k+1, l] #1302.34\n",
    "np.where(zh_hr_n[:, l] <= z_u) #60 and above\n",
    "np.where(zh_hr_n[:, l] >= z_l) #61 and below\n",
    "zh_hr_n[59, l] #1784.95\n",
    "zh_hr_n[60, l] #1615.85\n",
    "zh_hr_n[61, l] #1454.5\n",
    "zh_hr_n[62, l] #1300.94\n",
    "zh_hr_n[60, l] - zh_hr_n[61, l] #161.35\n",
    "zh_hr_n[61, l] - z_l #152.15\n",
    "z_u - zh_hr_n[60, l] #58.87\n",
    "clc_n[0, 59, l] #5.35\n",
    "clc_n[0, 60, l] #4.72\n",
    "clc_n[0, 61, l] #4.85\n",
    "\n",
    "z_u-z_l #372.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(clc_out[0,k,l]-(58.87*5.35+161.35*4.715+152.15*4.85)/372.3835) < 1e-2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds113_kernel",
   "language": "python",
   "name": "clouds113_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
